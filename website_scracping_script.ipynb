{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "246e7be2",
      "metadata": {},
      "source": [
        "# Collect Data by Scraping using Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a697931",
      "metadata": {
        "id": "9a697931"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import bs4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3feecee",
      "metadata": {},
      "source": [
        "## Selenium setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b4ca2d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "driver_path = r'C:\\Program Files (x86)\\chromedriver-win64\\chromedriver.exe'\n",
        "\n",
        "def create_driver():\n",
        "    options = Options()\n",
        "    options.add_argument(\"--start-maximized\")  # Start the browser maximized\n",
        "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
        "    return driver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ea4914",
      "metadata": {},
      "source": [
        "# Scraping Data from Jobsdb Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c5b078",
      "metadata": {
        "id": "27c5b078"
      },
      "outputs": [],
      "source": [
        "# Define the base URL and the page URL\n",
        "base_url = 'https://th.jobsdb.com'\n",
        "search_data = '/data-jobs'\n",
        "sec_page_url = '?page=2'\n",
        "\n",
        "# Fetch the webpage content\n",
        "page1 = requests.get(urljoin(base_url, search_data))\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(page1.content, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8958675d",
      "metadata": {
        "id": "8958675d"
      },
      "outputs": [],
      "source": [
        "box = soup.find('div',{'class':'_1decxdv0 _110qf3s4y _110qf3s4w'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238d64a7",
      "metadata": {
        "id": "238d64a7"
      },
      "outputs": [],
      "source": [
        "company_name = soup.find('a', {'data-automation': 'jobCompany'})\n",
        "position = soup.find('a', {'data-automation':'jobTitle'})\n",
        "location = soup.find('a', {'data-automation': 'jobLocation'})\n",
        "industry = soup.find('a',{'data-automation':'jobClassification'})\n",
        "date = soup.find('span',{'data-automation':'jobListingDate'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4aba37",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4371d03f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4371d03f",
        "outputId": "ca683a47-6aa1-4766-bded-a874dee31553"
      },
      "outputs": [],
      "source": [
        "company_name.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b025d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "40b025d9",
        "outputId": "acc3c84a-2699-4c66-969b-2f7b492023ad"
      },
      "outputs": [],
      "source": [
        "position.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d6eda8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "47d6eda8",
        "outputId": "55677ee4-a60e-4857-fa0f-bb3d0ad9b024"
      },
      "outputs": [],
      "source": [
        "location.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f66d7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "61f66d7f",
        "outputId": "82062bad-a69e-4503-a4f6-ffff2c7743f7"
      },
      "outputs": [],
      "source": [
        "industry.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94593386",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "94593386",
        "outputId": "3abbbe99-8301-47a2-c78c-31cc23683cb2"
      },
      "outputs": [],
      "source": [
        "date.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d89348d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d89348d",
        "outputId": "9b335cd1-8180-4ac8-8b41-2c5bde58f962"
      },
      "outputs": [],
      "source": [
        "print(company_name.text)\n",
        "print(position.text)\n",
        "print(location.text)\n",
        "print(industry.text)\n",
        "print(date.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4048dba7",
      "metadata": {
        "id": "4048dba7"
      },
      "outputs": [],
      "source": [
        "company_name_list = []\n",
        "position_list = []\n",
        "location_list = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddca0070",
      "metadata": {
        "id": "ddca0070"
      },
      "source": [
        "## Scrap one page to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e045f4f3",
      "metadata": {
        "id": "e045f4f3"
      },
      "outputs": [],
      "source": [
        "# Extract job titles\n",
        "job_title_elements = soup.find_all('a', {'data-automation':'jobTitle'})\n",
        "job_titles = [div.get_text(strip=True) for div in job_title_elements]\n",
        "\n",
        "# Extract company names\n",
        "company_name_elements = soup.find_all('a', {'data-automation': 'jobCompany'})\n",
        "company_names = [a.get_text(strip=True) for a in company_name_elements]\n",
        "\n",
        "# Extract Locations\n",
        "location_elements = soup.find_all('a', {'data-automation': 'jobLocation'})\n",
        "location = [a.get_text(strip=True) for a in location_elements]\n",
        "\n",
        "# Extract industry\n",
        "industry_elements = soup.find_all('a',{'data-automation':'jobClassification'})\n",
        "industry = [a.get_text(strip=True) for a in industry_elements]\n",
        "\n",
        "# Extract time\n",
        "time_elements = soup.find_all('span',{'data-automation':'jobListingDate'})\n",
        "time = [a.get_text(strip=True) for a in time_elements]\n",
        "\n",
        "# Combine job titles and company names into a list of tuples\n",
        "data = list(zip(job_titles, company_names, location, industry,time))\n",
        "\n",
        "# Create DataFrame\n",
        "data_jobs = pd.DataFrame(data, columns=['job_title', 'company_name','location','industry','time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bf4ba1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "41bf4ba1",
        "outputId": "557dc4b8-ba6f-4512-8660-badc727afc1b"
      },
      "outputs": [],
      "source": [
        "data_jobs.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa488f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1aa488f5",
        "outputId": "5552c08c-d019-4c1c-9417-99176d921d95"
      },
      "outputs": [],
      "source": [
        "all_jobs = []\n",
        "\n",
        "page_number = 1\n",
        "previous_content = \"\"\n",
        "\n",
        "while True:\n",
        "    url = f\"https://th.jobsdb.com/data-jobs?page={page_number}\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to retrieve page\")\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract job titles\n",
        "    job_title_elements = soup.find_all('a', {'data-automation':'jobTitle'})\n",
        "    job_titles = [div.get_text(strip=True) for div in job_title_elements]\n",
        "\n",
        "    # Extract company names\n",
        "    company_name_elements = soup.find_all('a', {'data-automation': 'jobCompany'})\n",
        "    company_names = [a.get_text(strip=True) for a in company_name_elements]\n",
        "\n",
        "    # Extract locations\n",
        "    location_elements = soup.find_all('a', {'data-automation': 'jobLocation'})\n",
        "    locations = [a.get_text(strip=True) for a in location_elements]\n",
        "\n",
        "    # Extract industry\n",
        "    industry_elements = soup.find_all('a',{'data-automation':'jobClassification'})\n",
        "    industries = [a.get_text(strip=True) for a in industry_elements]\n",
        "\n",
        "    # Extract time (job posting date)\n",
        "    time_elements = soup.find_all('span',{'data-automation':'jobListingDate'})\n",
        "    times = [a.get_text(strip=True) for a in time_elements]\n",
        "\n",
        "    # Check if extraction was successful\n",
        "    if len(job_titles) == 0 or len(company_names) == 0 or len(locations) == 0 or len(industries) == 0 or len(times) == 0:\n",
        "        print(f\"No new jobs found on page {page_number}, stopping.\")\n",
        "        break\n",
        "        \n",
        "    page_data = list(zip(job_titles, company_names, locations, industries, times))\n",
        "    all_jobs.extend(page_data)\n",
        "\n",
        "    # Compare content to determine if the page is the same\n",
        "    current_content = \"\".join(job_titles)\n",
        "    if current_content == previous_content:\n",
        "        print(f\"No new content found on page {page_number}, stopping the loop.\")\n",
        "        break\n",
        "\n",
        "    # Success Message\n",
        "    print(f\"Successfully scraped page {page_number}\")\n",
        "\n",
        "    previous_content = current_content\n",
        "    page_number += 1\n",
        "\n",
        "# Scraped dataframe name 'jobsdb_data'\n",
        "jobsdb_data = pd.DataFrame(all_jobs, columns=['job_title', 'company_name', 'location', 'industry', 'time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd5311f",
      "metadata": {
        "id": "1fd5311f",
        "outputId": "d053d018-17de-4914-999b-6c030d5fd877"
      },
      "outputs": [],
      "source": [
        "jobsdb_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425dac07",
      "metadata": {
        "id": "425dac07",
        "outputId": "fbb59079-2d89-4aed-b3f3-5647ca49aa65"
      },
      "outputs": [],
      "source": [
        "jobsdb_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca214cd",
      "metadata": {
        "id": "5ca214cd",
        "outputId": "4136bbb6-f92b-4cb8-ebfa-ad556f4ad33d"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['company_name'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2cd669",
      "metadata": {
        "id": "9d2cd669",
        "outputId": "02dd7c68-e1ed-4c3d-d675-8499d035974a"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['location'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f85326",
      "metadata": {
        "id": "81f85326",
        "outputId": "de0d6c80-0053-41f7-80da-65b83a1e909b"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['location'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676b963c",
      "metadata": {
        "id": "676b963c",
        "outputId": "751e8db0-8505-46d1-ffa9-13da85c7cf97"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['location'].unique().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c82d16",
      "metadata": {
        "id": "81c82d16"
      },
      "source": [
        "## Jobtopgun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "27be6372",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobtopgun_data_1st = 'https://www.jobtopgun.com/en/jobs?keywords=data'\n",
        "jobtopgun_data_morepages = '&page=2'\n",
        "jobtopgun_data_secondp = jobtopgun_data_1st + jobtopgun_data_morepages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "86445d43",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Navigating to jobtopgun 'data' search page number: 1\n",
            "Scraped data for job [1]: {'job_title': 'Data Analysis', 'company_name': 'PA&CA RECRUITMENT CO.,LTD.', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/246/14334', 'posted_time': 'Today', 'experience': '2 - 5 Year', 'salary': '2 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': '25,000 - 40,000 baht/month', 'responsibility': 'PT24082111\\n\\nType of Business: Trading & warehouse of press tools, mould die\\nSalary Range: 25,000 - 35,000 Baht.\\n\\nJob Description:\\n\\n- Collecting data from various sources to generate quickly and accuracy data, and visualize to making predictions and recommendations.\\n- Streamlining data collection methods to create automated and easy-to-use ', 'requirements': \"Requirements\\n- Thai Nationality, Male/Female, age 24-32 years old.\\n- Bachelor's degree in any related field.\\n- Have Experience 2 years in Data Analyst in Industrial, E-commerce, Business to Business\\n- Able to use Microsoft Excel, Power Query, SQL, BI, Data Management, Python\\n- Good command in English (Toeic 700 up)\\n- Working hour: Monday-Friday, 09:00-18:00\\n- Salary plus other allowances.\\n\\nLocation: Bangna, Bangkok\", 'welfare_and_benefits': 'Welfare and Benefits\\nFull Attendane\\nProvident Fund\\nFuel/transportation fees\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nAnnual bonus'}\n",
            "Scraped data for job [2]: {'job_title': 'Data Analyst', 'company_name': 'SGS (Thailand) Limited', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/4387/1555', 'posted_time': 'Today', 'experience': '3 - 5 Year', 'salary': '3 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': '• To complete data quality check and manage correction upon supervision of all users.\\n• Support all users as superuser to respond information and problem and summary monthly problem report.\\n• Refresh training for all users twice a year and update to all users in case of any major changes of KN application within 1 week and minor changes within 2 weeks\\n• Find tool to accommodate all users for productivity of work process.\\n• To monthly monitor global projects concerned (Everest Project and other relates) within time frame and report to management.\\n• Monitor all development project, test result’s feedback in timeframe to global technical team.\\n• Monitor and handle other assigned projects.\\n• Monitor Report; Operation Report, BRC Report, Surveillance Report, CRM report twice a month including feedback to all concerned parties and coordinate to initiate corrective action.', 'requirements': 'Requirements\\n• Bachelor’s degree in Science Statistic only\\n• Minimum 3 years’ experience in data analyst or related experience, including proficiency with analytical software or equivalent related.\\n• Demonstrated knowledge of and skill in MS. Excel, Power BI, and database applications.\\n• Proficiency in statistics, data analysis, and research methods.\\n• Knowledge of and skills in adaptability, decision making, serviced mind, interpersonal relations, problem solving and project management.', 'welfare_and_benefits': \"Welfare and Benefits\\nDental insurance\\nGratuity\\nLife insurance\\nTransportation allowance\\nTravel allowance\\nProvident Fund\\nStaff training and development\\nAccommodation allowance (in other provinces)\\nScholarship/ education allowance\\nMarriage gift\\nRecreational allowance\\nค่าใช้จ่ายในการเดินทาง\\nWork from home\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nสิทธิการเบิกค่าทันตกรรม\\nEmployee's uniform\\nFuneral payment support\\nAnnual trip or party\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [3]: {'job_title': 'เจ้าหน้าที่ควบคุมระบบบริหารคุณภาพและข้อมูลอาวุโส', 'company_name': 'Amnuay Silpa School', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/9956/60', 'posted_time': 'Today', 'experience': '2 - 10 Year', 'salary': '2 - 10 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Depend on qualifications and experience', 'responsibility': 'สนับสนุนในการเตรียมเอกสารที่เกี่ยวข้องกับการตรวจสอบหรือรองรับมาตรฐานต่าง ๆ\\nเตรียมความพร้อมของระบบคุณภาพของหน่วยงานในการตรวจฯ ในแง่ต่าง ๆ เช่น บุคคลผู้รับการตรวจ พื้นที่ตรวจ ระบบงาน ระบบเอกสาร และข้อมูล\\nติดต่อ ประสานงานการรับตรวจฯ จากภายในและภายนอกหน่วยงาน รวมถึงผู้รับการตรวจต่าง ๆ ของหน่วยงาน และผู้ตรวจตามระบบมาตรฐานต่าง ๆ\\nสแกน อัพโหลด และจัดเก็บเอกสารตามขั้นตอนของโรงเรียน\\nบริหารจัดการเอกสาร กำหนดสิทธิ์การเข้าถึงเอกสาร และช่องทางการแสดงเอกสารที่กำหนด\\nสนับสนุนเกี่ยวกับการร้องขอเอกสารที่จำเป็นจากหน่วยงานต่าง ๆ โดยดำเนินการตามคู่มือที่โรงเรียนกำหนด\\nรวบรวมและลงทะเบียนเอกสารทางเทคนิคที่จำเป็นเกี่ยวกับการป้องกันความเสี่ยงในการดำเนินกิจการของโรงเรียน เช่น เอกสารเกี่ยวกับความปลอดภัยของนักเรียน ผู้ปกครอง ครู และบุคลากร เช่น แบบแปลนโรงเรียน แผนเผชิญเหตุฉุกเฉิน เป็นต้น\\nตรวจสอบเอกสารและนำเสนอ เพื่อให้มีการปรับปรุง เปลี่ยนแปลง เพิ่มเนื้อหาหรือข้อความในเอกสารให้เป็นปัจจุบัน ตามระยะและความจำเป็น เพื่อควบคุมคุณภาพของเอกสาร\\nสร้างและบริหารจัดการช่องทางการสื่อสารเอกสารที่เกี่ยวข้องกับระบบการบริหารคุณภาพ ไปยังครูและบุคลากรภานในโรงเรียน เพื่อสามารถใช้งานได้\\nทบทวนและติดตามความเบี่ยงเบนของระบบงาน และระบบเอกสารจากมาตรฐานต่าง ๆ ที่ได้ออกแบบไว้ และ/หรือ ความเบี่ยงเบนจากแผนฯ ที่ได้วางไว้ (CAR)\\nกำกับและติดตามการดำเนินงานให้เป็นไปตามระบบประกันคุณภาพตามที่หน่วยงานกำหนดไว้\\nติดตามความคืบหน้าในการดำเนินสนองตอบต่อการแก้ไข ป้องกัน (CAR) หรือดำเนินการตามที่ได้เสนอต่อผู้ตรวจ หรือตามที่ผู้ตรวจได้เสนอผ่านความเห็นชอบแล้ว\\nรวบรวมข้อมูล และจัดทำรายงานด้านคุณภาพ และด้านความเสี่ยงในรูปแบบต่าง ๆ เพื่อรายงานต่อผู้บริหารหน่วยงาน และหน่วยงานภายนอกอื่น ๆ ตามมาตรฐานที่กำหนด', 'requirements': 'Requirements\\nจบการศึกษาในระดับปริญญาทุกสาขา\\nประสบการณ์การทำงานด้านความคุมจัดเก็บเอกสารอย่างน้อย 2 ปี\\nหากมีประสบการณ์ด้าน ISO จะพิจารณาเป็นพิเศษ\\nมีความละเอียดรอบคอบ และรับผิดชอบสูง\\nมีความสามารถในการประสานงาน และสื่อสารเป็นอย่างดี\\nมีความน่าเชื่อถือ สามารถรักษาความลับข้อมูลของโรงเรียน\\nมีความสามารถในการบริหารเอกสาร\\nสามารถใช้ Software ที่เกี่ยวกับงานเอกสาร\\nสามารถสื่อสารภาษาอังกฤษได้\\nมีความใส่ใจต่อเนื้อหาและรายละเอียด', 'welfare_and_benefits': 'Welfare and Benefits\\nLife insurance\\nMedical insurance\\nProvident Fund\\nStaff training and development\\nOvertime\\nค่าทุนการศึกษาบุตร\\n5-day work week\\nHealth insurance\\nAccident Insurance\\nOrdination leave\\nFuneral payment support\\nAttendance bonus or other special compensation\\nPerformance/results-based bonus'}\n",
            "Scraped data for job [4]: {'job_title': 'Data Engineer', 'company_name': 'K Stone Corporation Co., Ltd.', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/19114/95', 'posted_time': 'Today', 'experience': '3 - 5 Year', 'salary': '3 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Depend on qualifications and experience', 'responsibility': 'Be a strong advocate for a culture of process and data quality across the teams.\\nDesign, build, administer and scale data processing pipelines (batch/streaming) from structured/semi-structure/unstructured types of data sources (CSV, JSON, Parquet, tables, Kafka, etc.)\\nImprove scalability, stability, accuracy, speed and efficiency of current data systems.\\nResponsible for design, building, testing and deployment of new libraries, frameworks for core systems with the high standard of quality.\\nWork cross-functional teams of functional analyst, project manager, other engineers as well as work closely with the data science and product team in an agile way (or project base in some cases) on requirements and deliverable\\nEnsure SLA and provide the greatest experience for users by collaborating closely with the Data Operations team.\\nEnsure compliance with data governance and security policies.', 'requirements': 'Requirements\\nStrong experience in Big data development\\nExtensive experience in the automated software and data pipeline development and deployment flow (CI/CD)\\nHands-on experience in data modeling and creating algorithms that turn data into optimal, practical, and valuable information.\\nStrong coding ability in these types of programming languages; Apache Spark, Python/PySpark, SQL\\nGood understanding of the Data Management concept\\nKnowledge of other data and analytics tools, such as key-value data stores, in-memory data stores, real-time analytics databases, etc.\\nKnowledge of the Azure cloud computing service\\nExperience in working with Azure Databricks\\nExperience and know-how in working with banking data\\nKnowledge of the Scala programming language', 'welfare_and_benefits': 'Welfare and Benefits\\nStaff training and development\\nOvertime\\n5-day work week\\nSocial security\\nHealth insurance\\nAnnual trip or party'}\n",
            "Scraped data for job [5]: {'job_title': 'Business Analyst/Data Analyst', 'company_name': 'SPS Medical Co., Ltd', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/20756/27', 'posted_time': 'Today', 'experience': '0 - 5 Year', 'salary': '0 - 5 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': '1. ทำงานสัมพันธ์กับทีมงานในองค์กรตลอดจนผู้มีส่วนเกี่ยวข้องอื่นๆ เพื่อเก็บรวบรวมความต้องการของ User \\n2. วิเคราะห์และศึกษาความเป็นไปได้\\n3. วางแผนการดำเนินงานโครงการพัฒนาระบบตามขั้นตอนของวงจรการพัฒนาระบบสารสนเทศ\\n4. พัฒนา Application และ Support การใช้งานของ User\\n5. พัฒนาโปรแกรม SAP และ Support การใช้งาน SAP รวมถึงปรับปรุง Program ให้ตอบโจทย์การใช้งานของ User\\n6. วิเคราะห์การทำงานและออกแบบโปรแกรมเพื่อให้ตอบโจทย์การทำงานร่วมกับทีม\\n7. ทดสอบโปรแกรมที่พัฒนาร่วมกับทีม และ User\\n8. วิเคราะห์ข้อมูลสำหรับจัดทำรายงานต่าง ๆให้กับผู้บริหาร เพื่อให้ผู้บริหารตัดสินใจในการดำเนินงานต่าง ๆ\\n9. มีส่วนร่วมในการวิเคราะห์ข้อมูลที่เกี่ยวข้องกับโปรเจคต่าง ๆ เพื่อพัฒนาองค์กร\\n10. ศึกษา รวบรวม และทำความเข้าใจในรายละเอียดของ requirements รวมถึงผลกระทบกับธุรกิจของบริษัท (Business Impact)\\n11. วางแผนงานต่างๆ เพื่อให้ระบบได้พัฒนาขึ้นใหม่ถูกนำมาใช้แทนระบบเดิมโดยให้มีความยุ่งยากน้อยที่สุด\\n12. งานอื่นๆ ที่ได้รับมอบหมาย', 'requirements': 'Requirements\\nคุณสมบัติ\\n- ปริญญาตรีขึ้นไป สาขา วิทยาศาสตร์คอมพิวเตอร์, วิศวกรรม ,คณิตศาสตร์, Physics หรือสาขาที่เกี่ยวข้อง\\n- มีความรู้ด้าน Database และการเขียนโปรแกรมในภาษาใดๆก็ได้\\n- มีความรู้ด้านการออกแบบโปรแกรม\\n- แก้ปัญหาเฉพาะหน้าได้ดี มีความคิดเป็นระบบ\\n- ไม่จำเป็นต้องมีประสบการณ์ทำงาน\\n- หากมีประสบการณ์การเขียน ABAP จะพิจารณาเป็นพิเศษ', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nStaff training and development\\nMarriage gift\\nOrdination gift\\nซื้อยาราคาพนักงาน\\nSocial security\\nOrdination leave\\nสัมมนา\\nEmployee's uniform\\nFuneral payment support\\nAnnual bonus\"}\n",
            "Scraped data for job [6]: {'job_title': 'Data Scientist', 'company_name': 'K Stone Corporation Co., Ltd.', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/19114/92', 'posted_time': 'Today', 'experience': '2 - 5 Year', 'salary': '2 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Depend on qualifications and experience', 'responsibility': \"Collaborate with various stakeholders to understand business objectives and challenges.\\nTranslate business problems into well-defined data science solutions with measurable objectives and deliverables.\\nApply data analysis, statistical modeling, and machine learning techniques on large and complex tabular data to draw insights with actionable recommendations.\\nWork with business and engineering teams to implement end-to-end processes from model development to testing, validation, deployment, and lifecycle support.\\nResearch, study, and develop new tools and frameworks to enhance data science capabilities and drive customers' data mindset and strategy.\\nExhibit self-initiative do explore data analysis and formulate hypotheses to understand data.\\nDefine performance and data drift metrics to support the product team in determining when to retrain and tune statistical models.\\nWrite comprehensive documents at each step to ensure that other team members can reuse the knowledge.\\nAssist quality assurance (QA) team with UAT testing (if required)\\nCreate or update metadata (Business, Technical, Dataset) in accordance with standard specified by Data Governance and project team. This includes writing attribute business name and business definition.\\nIdentify Critical Data Element (CDE) for data quality monitoring purposes. Create and review data quality rules with Data Quality team.\\nDerive business implication and/or actionable recommendations from the findings.\", 'requirements': 'Requirements\\nA Bachelor’s degree in computer science, software engineering, or another related field.\\n2 years+ of Data Science or similar role.', 'welfare_and_benefits': 'Welfare and Benefits\\nStaff training and development\\nOvertime\\n5-day work week\\nSocial security\\nHealth insurance\\nAnnual trip or party'}\n",
            "Scraped data for job [7]: {'job_title': 'Data Analyst', 'company_name': 'K Stone Corporation Co., Ltd.', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/19114/93', 'posted_time': 'Today', 'experience': '2 - 5 Year', 'salary': '2 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Depend on qualifications and experience', 'responsibility': 'Understand requirements and business use cases from internal and external customers in order to design a data product or analytics solution that meet business objectives.\\nFrom there, select appropriate statistics tools, measures, and methodology. This could also include identifying new or secondary data source that could enhance the analysis.\\nTransform business requirements and designs into technical specification and other required documentation (such as BRS) for BI Engineer, Data Scientist, and other technical teams in order to develop and implement a solution. This task involves performing Exploratory Data Analysis (EDA), list required data sources, identifying transformation logic, applying appropriate data cleansing and data standardization rules according to the project architecture or data model design.\\nProcess data with standard tools such as SQL and Python and manipulate data with analysis and visualize tools such as Power BI to explore data, find trends, make inferences or prediction, or find any insights.\\nCreate or update metadata (Business, Technical, Dataset) in accordance with standard specified by Data Governance and project team.\\nThis includes writing attribute business name and business definition.\\nIdentify Critical Data Element (CDE) for data quality monitoring purposes.\\nCreate and review data quality rules with Data Quality team.', 'requirements': 'Requirements\\nA bachelor’s degree in computer science, software engineering, or another related field.\\n2 years+ of Data Analyst or similar role.', 'welfare_and_benefits': 'Welfare and Benefits\\nStaff training and development\\nOvertime\\n5-day work week\\nSocial security\\nHealth insurance\\nAnnual trip or party'}\n",
            "Scraped data for job [8]: {'job_title': 'Data Engineer (Insurance Broker)', 'company_name': 'Ngern Tid Lor Public Company Limited', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/21417/550', 'posted_time': 'Today', 'experience': '3 - 7 Year', 'salary': '3 - 7 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'พัฒนาและปรับปรุงระบบ Coding ให้มีประสิทธภาพโดยใช้ SQL\\nออกแบบ Data Flow ให้มีประสิทธิภาพ\\nMonitor ข้อมูลและตรวจสอบความถูกต้องของ Data เพื่อให้สามารถใช้งานได้อย่างมีประสิทธิภาพ\\nประสานงานกับ user เพื่อรับ requirement และหาแนวทางร่วมกันในแต่ละ Project\\nพัฒนาระบบ Data ต่างๆ เพื่อให้มีประสิทธิภาพดียิ่งขึ้น\\nDesign report ต่างๆเพื่อให้ user สามารถใช้ข้อมูลได้', 'requirements': 'Requirements\\nจบปริญญาตรีขึ้นไปในสาขา Data Analytics, Statistics, Mathematics, Operations Research, Engineering หรือสาขาอื่นๆทีเ่กี่ยวข้อง\\nประสบการณ์อย่างน้อย 3 ปีขึ้นไปในการทำ Data Visualization, Report, Flow Chart\\nสามารถแก้ไขปัญหาเฉพาะหน้าได้ และรับความกดดันได้ดี\\nมีทักษะในการประสานงาน และการติดต่อสื่อสาร\\nมีทักษาในการใช้ SQL, Tableau, Power BI และ MS Excel ได้เป็นอย่างดี', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nStaff training and development\\nMarriage gift\\n5-day work week\\nทุนการศึกษา\\nประกันชีวิต\\nSocial security\\nHealth insurance\\nAccident Insurance\\nOrdination leave\\nสิทธิการเบิกค่าทันตกรรม\\nEmployee's uniform\\nPerformance/results-based bonus\\nโบนัสประจำปี\"}\n",
            "Scraped data for job [9]: {'job_title': 'Data Analyst', 'company_name': 'บริษัท เริ่มใหม่ จำกัด', 'industry': 'Retail/Wholesale', 'job_url': 'https://www.jobtopgun.com/en/job/248818/51', 'posted_time': 'Retail/Wholesale', 'experience': '1 - 5 Year', 'salary': '1 - 5 Year', 'education': \"Bachelor's Degree\", 'location': '20,000 - 50,000 baht/month', 'responsibility': '- รวบรวมและวิเคราะห์ข้อมูล สถิติ คู่แข่ง เพื่อจัดทำแผนการขายให้สอดคล้องกับข้อมูล\\n- วิเคราะห์ช่องทางและคู่แข่งทางการตลาด\\n- จัดทำ Report ในรูปแบบ Dashboard หรือ Visualize ที่สามารถสื่อสารให้เข้าใจได้โดยง่ายและชัดเจน\\n- จัดทำแผน และพัฒนาระบบฐานข้อมูลและรายงาน เพื่อใช้ในการวิเคราะห์ ติดตามผลการปฏิบัติงานได้อย่างมีประสิทธิภาพ\\n- ร่วมวางแผน พัฒนา และปรับปรุงการทำการตลาดขององค์กร\\n- บริหารการยิงโฆษณาออนไลน์ ในช่องทางต่างๆได้\\n- ประสานงานกับแผนกอื่นๆ เพื่อให้ได้ผลลัพธ์ตามที่ได้วางไว้\\n- มีความเข้าใจในธุรกิจ และวิเคราะห์ข้อมูลเพื่อตอบโจทย์ในทางธุรกิจได้', 'requirements': 'Requirements\\n• ไม่จำกัดเพศ\\n• อายุ 23 - 35 ปี\\n• มีประสบการณ์ในตำแหน่งงาน 1 - 5 ปี\\n• มีประสบการณ์ในสายงาน Data Analyst Management\\n• มีทักษะในการสื่อสารและความเข้าใจในงาน\\n• สามารถทำงานเป็นทีมได้\\n• มีทักษะด้านคณิตศาสตร์ และตัวเลข ในระดับดี\\n• เข้าใจเรื่องสถิติ มีประสบการณ์ในการสรุปผล เช่น Excel, Power BI\\n• เข้าใจฐานข้อมูล เช่น SQL Server, Oracle และ SAP\\n• เข้าใจเรื่องสคริปต์และเว็บไซต์ เช่น json, xml, java script, html5\\n• เข้าใจกระบวนการ ETL และการใช้เครื่องมืออย่าง SSIS, Power Query\\n• สามารถใช้งานเครื่องมือในการสร้างรายงาน สร้างDashboardเช่น Power BI, Tableau , Qlik\\n• เข้าใจเครื่องมือการตลาดดิจิทอล เช่น Google Analytics, Google Tag Manager', 'welfare_and_benefits': 'Welfare and Benefits\\nStaff training and development\\n5-day work week\\nSocial security\\nHealth insurance\\nOrdination leave\\nAttendance bonus or other special compensation'}\n",
            "Scraped data for job [10]: {'job_title': 'Process Optimization & Data Analyst Lead (Manager Level)', 'company_name': 'ECCO (Thailand) Co., Ltd', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/27408/161', 'posted_time': 'Today', 'experience': '5 - 10 Year', 'salary': '5 - 10 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Job Summary:\\nThe Process Optimization & Data Analyst Lead is responsible for leading initiatives that optimize product costing processes and enhance operational efficiency through data-driven decision-making.\\nThis role involves analyzing business processes, identifying areas for improvement, and implementing data analysis reports and dashboards approved by the Product Costing & Operational Excellence Director to drive continuous improvement throughout the entire product costing process. The Lead will work closely with cross-functional teams to ensure that process enhancements align with organizational goals and objectives.\\nAdditionally, this role involves supervising the integrity of master data, updating costing principles in line with group requirements and business needs, and serving as a PLM (Product Lifecycle Management) super user.\\nThe Process Optimization & Data Analyst Lead role requires strong analytical and problem-solving skills to support the full range of costing business analysis.\\nKey responsibilities include:\\n• Lead Process Improvement Initiatives : Manage and oversee the implementation of process improvement projects, ensuring they are completed on time and within scope\\n• Data Analysis and Reporting : Analyze data to identify trends, inefficiencies, and opportunities for process optimization; generate comprehensive reports to support decision-making\\n• Master Data Management and Costing Principles Update : Supervise the integrity of master data, update costing principles in alignment with group requirement and business needs, and serve as a super user for the PLM system\\n• Continuous Improvement : Drive a culture of continuous improvement by promoting best practices, training team members, and implementing feedback loops\\n• Stakeholder Collaboration : Work closely with internal stakeholders to align process improvements with business objectives and ensure seamless integration of changes\\n• Documentation, Compliance and Conduct Ad Hoc Evaluations : Maintain accurate documentation of processes, changes, and outcomes, ensuring compliance with industry standards and company policies', 'requirements': 'Requirements\\n- Master degree in Engineering/ Statistic/ Science/ Economics \\n- 5 to 10 years of experience in Data Analysis or Product Costing Improvement, process optimization\\n- Fluent in English\\n- Able to work at Ayutthaya province', 'welfare_and_benefits': \"Welfare and Benefits\\nLong Service Award\\nProvident Fund\\nStaff training and development\\nFuel/transportation fees\\nค่าอาหาร วันละ 20 บาท\\nTelephone bill allowance\\nตรวจสุขภาพประจำปี\\n5-day work week\\nประกันชีวิต\\nประกันชีวิต และ ประกันอุบัติเหตุ\\nประกันสังคม\\nSocial security\\nHealth insurance\\nประกันสุขภาพ\\nรองเท้า ปีละ 2 คู่\\nวันหยุดวันลาต่าง ๆ\\nสหกรณ์ออมทรัพย์\\nสิทธิการเบิกค่าทันตกรรม\\nFuneral payment support\\nเงินช่วยเหลืออื่นๆ ตามอายุงาน\\nAnnual trip or party\\nPerformance/results-based bonus\\nAnnual bonus of 3 month(s)\\nโบนัสประจำปี (based on employee's performance) สูงสุด 90 วัน\"}\n",
            "Scraped data for job [11]: {'job_title': 'IT Senior Data Engineer', 'company_name': 'Magnecomp Precision Technology Public Company Limited', 'industry': 'Today', 'job_url': 'https://www.jobtopgun.com/en/job/19886/878', 'posted_time': 'Today', 'experience': '2 - 4 Year', 'salary': '2 - 4 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': \"JOB SUMMARY:\\n\\nThe Data Engineer is responsible for designing, developing, and maintaining data pipelines and infrastructure to support the organization's data needs. This role involves working closely with data scientists, analysts, and other stakeholders to ensure the availability, reliability, and performance of data systems. The ideal candidate possesses strong technical skills in data processing, database management, and data architecture.\\n\\nRESPONSIBILITIES:\\n\\nUtilize data analytics tools such as Apache Spark, Apache NiFi, and Apache Kafka to analyze large datasets and extract valuable insights.\\nAssist in data preparation and data streaming tasks using technologies like Apache Flink and Apache Kafka.\\nManage and monitor Kubernetes clusters to ensure optimal performance and availability of data engineering applications.\\nContribute to the management and maintenance of data lakes and data lake houses, ensuring data integrity, security, and accessibility.\\nCollaborate with cross-functional teams to develop and deploy SQL and Python-based data engineering solutions.\", 'requirements': 'Requirements\\nEducation Required: Bachelor’s degree in computer science, Information Technology, or a related field.\\n\\nSkill Required:\\n\\nPrevious experience or coursework in data engineering, data analytics, or a related field.\\nStrong analytical and problem-solving skills with a keen attention to detail.\\nExcellent communication and collaboration abilities, with a desire to work in a team-oriented environment.\\nAbility to learn and adapt to new technologies and tools quickly.\\nProficiency in data analytics tools such as Apache Spark, Apache NiFi, and Apache Kafka.\\nKnowledge of data preparation and data streaming technologies, including Apache Flink and Apache Kafka.\\nExperience with Kubernetes management and monitoring tools.\\nUnderstanding of data lake and data lake house concepts and management practices.\\nStrong programming skills in SQL and Python languages for data manipulation and analysis.\\nExperience: 2-4 years.', 'welfare_and_benefits': \"Welfare and Benefits\\nAnnual Bonus\\nAnnual Perfect Attendance\\nDental Allowance\\nFree shuttle bus / Van\\nMedical Allowance\\nTravel Allowance\\nProvident Fund\\nStaff training and development\\nOvertime\\nMarriage gift\\nTelephone bill allowance\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nEmployee's uniform\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [12]: {'job_title': 'IT Associate Data Engineer', 'company_name': 'Magnecomp Precision Technology Public Company Limited', 'industry': 'Yesterday', 'job_url': 'https://www.jobtopgun.com/en/job/19886/879', 'posted_time': 'Yesterday', 'experience': '1 - 3 Year', 'salary': '1 - 3 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': 'JOB SUMMARY:\\n\\nUnder general supervision, the Associate Data Engineer will contribute to the development and maintenance of data pipelines and infrastructure. Responsible for monitoring ETL processes, ensuring data quality, and supporting data requests for a range of stakeholders. Ideal for data-oriented individuals passionate about extracting value from data on a collaborative team.\\n\\nRESPONSIBILITIES:\\n\\nThe Associate Data Engineer is responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data, building analytical solutions, and administering systems to deliver information to the health system.\\nApplies knowledge of relational database skills including SQL knowledge and ability to create queries and stored procedures.\\nCreate, document, and communicate the integration approach of all the components of the solution.\\nEvaluate data quality and interpret results in a clear, concise manner.\\nBuilds data models, data marts and extracts to support Data Science and other internal customers.', 'requirements': \"Requirements\\nEducation Required: Bachelor’s degree or equivalent experience.\\n\\nSkill Required:\\n\\nProgramming in C#, Python, R\\nKnowledge of C# or Java\\nFamiliarity with Lakehouse architecture\\nExperience: 1-3 years.\\n\\n1 - 3+ years of experience in a role querying, analyzing data, and/or data modeling/architecture.\\n1 - 3+ years of experience with developing and maintaining ETL / data pipeline (e.g., Microsoft SSIS, NIFI).\\nWorking experience in Relational databases or Hadoop with strong understanding of SQL or HQL\\nExperience using SQL for data extraction, manipulation, and reporting.\\nKnowledge of relational database skills including SQL knowledge and the ability to create queries and stored procedures.\\nExperience with report writing and data visualization tools such as: Microsoft Power BI, Tableau, Crystal Reports, SSRS, etc.\\n1+ years hands-on experience building and deploying data pipelines.\\n1+ years' experience using Python and any ETL tool.\", 'welfare_and_benefits': \"Welfare and Benefits\\nAnnual Bonus\\nAnnual Perfect Attendance\\nDental Allowance\\nFree shuttle bus / Van\\nMedical Allowance\\nTravel Allowance\\nProvident Fund\\nStaff training and development\\nOvertime\\nMarriage gift\\nTelephone bill allowance\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nEmployee's uniform\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [13]: {'job_title': 'Engineering Data Officer', 'company_name': 'ISUZU Technical Center of Asia Co., Ltd.', 'industry': 'Automobile & Parts, Machinery', 'job_url': 'https://www.jobtopgun.com/en/job/1126/115', 'posted_time': 'Automobile & Parts, Machinery', 'experience': '0 - 3 Year', 'salary': '0 - 3 Year', 'education': 'Certificate of Vocational Education or Diploma of Vocational Education', 'location': '12,000 - 20,000 baht/month', 'responsibility': 'Input and verify engineering data including drawing and part lists\\nUpdate and maintain specified data under superior supervision\\nDrawing standard checking\\nHelp in data analysis and report generation\\nWork with engineers and stakeholders for data accuracy\\nSupport activity of company about 5S, Compliance, ISO9001', 'requirements': 'Requirements\\nDiploma or equivalent; degree related to mechanical drawing or information management preferred.\\nExperience in data entry and documentation controlling are preferable.\\nAttention to detail and accuracy.\\nProficiency in Microsoft Excel and drawing.\\nStrong communication skill.\\nBe able to communicate in English in basic level.', 'welfare_and_benefits': \"Welfare and Benefits\\nCommuting or Accommodation Allowance\\nMeal Allowance\\nStaff training and development\\nOvertime\\nFuel/transportation fees\\n5-day work week\\nประกันกลุ่ม\\nSocial security\\nHealth insurance\\nFlexible working hours\\nOrdination leave\\nEmployee's uniform\\nAnnual trip or party\\nAnnual bonus\"}\n",
            "Scraped data for job [14]: {'job_title': 'Data Engineer (MES)', 'company_name': 'TPV Technology (Thailand) Co., Ltd.', 'industry': 'Yesterday', 'job_url': 'https://www.jobtopgun.com/en/job/245793/75', 'posted_time': 'Yesterday', 'experience': '1 - 3 Year', 'salary': '1 - 3 Year', 'education': \"Bachelor's Degree or Higher\", 'location': '20,000 - 30,000 baht/month', 'responsibility': '1. Training SFIS system to line workers\\n2. SFIS system problem handling, feedback and record in production process, and follow up the improvement situation.\\n3. SFIS and MES system maintain  ', 'requirements': \"Requirements\\n1. Bachelor's degree in IT, Electrical\\n2. Have knowledge about Oracle.\\n3.  Good command of English communication and writing  \", 'welfare_and_benefits': \"Welfare and Benefits\\nStaff training and development\\nOvertime\\nค่าใช้จ่ายสำหรับที่อยู่อาศัย\\n5-day work week\\nบริการรถรับส่งพนักงาน\\nSocial security\\nHealth insurance\\nOrdination leave\\nEmployee's uniform\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [15]: {'job_title': 'Data Center Operation-Shift Lead (Samut Prakan)', 'company_name': 'Gulf Energy Development Public Company Limited', 'industry': 'Yesterday', 'job_url': 'https://www.jobtopgun.com/en/job/17668/946', 'posted_time': 'Yesterday', 'experience': '8 - 9 Year', 'salary': '8 - 9 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'On duty and take responsibility when absence DC operation manager\\nQuality assurance of Technician work performed along with associated documentation\\nMaintenance of supply and tool inventory used by MEP system\\nManagement and reporting of Technician hours worked\\nEnsure compliance of policies and procedures by Technicians\\nMentoring and leadership on data center floor for technicians\\nSupport of construction, research, and development activity\\nGood understanding of electrical and mechanical systems that may be employed in a data center environment. This may include electrical feeders, transformers, generators, switchgear, UPS systems, DC power systems, ATS/STS units, PDU units, air handling units, cooling towers, and fire suppression systems\\nMust be familiar with safety requirements and OSHA regulations governing a multi-megawatt facility\\nInterpret wiring diagrams, schematics, and electrical drawings', 'requirements': 'Requirements\\nFamiliar with Microsoft Suite, BMS, EPMS, CPMS and CMMS\\nTravel may be requested by GSA\\nThe data center is a 24 hour/7 day operation\\nExcellent verbal, written, and interpersonal communication skills\\nAbility to express ideas clearly, concisely and effectively with contractors installing, performing maintenance or upgrade work on systems installed in the data center environment\\nAbility to analyze and make suggestions for problem resolution\\nSolve problems with good initiative and sound judgment\\nMake decisions independently with minimal guidance\\nCreativity, problem solving skills, negotiation and systematic thinking\\nFluent in English both written and verbal (Minimum 500 TOEIC score)\\nGoal–Oriented, Unity, Learning, Flexible', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\n5-day work week\\nHealth insurance\\nEmployee's uniform\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [16]: {'job_title': 'วิศวกรจัดการข้อมูลผลิตภัณฑ์', 'company_name': 'Rockworth Public Co., Ltd.', 'industry': 'Furniture', 'job_url': 'https://www.jobtopgun.com/en/job/4153/221', 'posted_time': 'Furniture', 'experience': '0 - 1 Year', 'salary': '0 - 1 Year', 'education': 'Diploma of Vocational Education or higher', 'location': '18,000 - 25,000 baht/month', 'responsibility': '1. ปฏิบัติงานให้สอดคล้องกับนโยบายและข้อกำหนด ระบบ ISO9001\\n2. ปฏิบัติการร่วมกับทีมในการจัดทำเอกสาร Installation Manual และ Animation\\n3. ปฏิบัติการ Export Drawing เพื่อใช้ในงานสนับสนุนการขาย\\n4. ตรวจสอบแบบและเอกสารเกี่ยวกับทาง Engineer (Drawing)\\n5. จัดทำเอกสารในส่วนของการจัดซื้อวัสดุและชิ้นส่วนผลิตภัณฑ์\\n6. รวบรวมไฟล์ชิ้นส่วนมาตรฐานในการทำแบบผลิตภัณฑ์\\n7. ปฏิบัติการร่วมกับทีมในการทำ จัดทำเอกสาร Packing', 'requirements': 'Requirements\\nเพศหญิง อายุระหว่าง 22-30 ปี\\nวุฒิ ปวส. ขึ้นไป สาขาครุศาสตร์เขียนแบบเครื่องกล หรือสาขาที่เกี่ยวข้อง\\nสามารถใช้ Microsoft Office (Excel) , AutoCAD , Solidwork ได้ในระดับดี\\nมีประสบการณ์ การออกแบบผลิตภัณฑ์เชิงวิศวกรรม จะได้รับการพิจารณาเป็นพิเศษ\\nยินดีรับนักศึกษาจบใหม่\\nปฏิบัติงาน วันจันทร์-เสาร์ เวลา 08.00 - 17.00 น.', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nStaff training and development\\nOvertime\\nMarriage gift\\nOrdination gift\\nทุนการศึกษาบุตร\\nSocial security\\nAccident Insurance\\nOrdination leave\\nสวัสดิการเยี่ยมไข้\\nสหกรณ์ออมทรัพย์\\nEmployee's uniform\\nFuneral payment support\\nAnnual trip or party\\nAttendance bonus or other special compensation\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [17]: {'job_title': 'Data Analyst (Production engineer Division)', 'company_name': 'Sony Device Technology (Thailand) Co.,Ltd', 'industry': 'Electronic', 'job_url': 'https://www.jobtopgun.com/en/job/28575/193', 'posted_time': 'Electronic', 'experience': '0 - 2 Year', 'salary': '0 - 2 Year', 'education': \"Bachelor's Degree\", 'location': 'Depend on qualifications and experience', 'responsibility': 'Job Description:\\nAs a Data Analyst in the Production Engineer Division, you will play a crucial role in transforming raw data into actionable insights to enhance manufacturing processes and efficiency. You will be responsible for data collection, preparation, and analysis, as well as predictive modeling to proactively address production challenges. You will also collaborate with developers to provide the necessary data and APIs to support application development that optimizes manufacturing operations.\\n\\nData Collection & Preparation: Partner across teams to gather high-quality data. Clean and prepare this data meticulously for analysis.\\nDataAnalysis & Insights: Use statistical methods to uncover patterns and trends in the data. Create clear visualizations to communicate findings.\\nPredictive Modeling: Build and implement systems using rule-based logic and machine learning to predict and solve problems proactively.\\nData & API Support: Work with developers to provide data and APIs that enable the development of applications that improve manufacturing.', 'requirements': \"Requirements\\nBachelor's degree in Computer Engineering, Computer Science, Data Science, or a related field. New graduates are encouraged to apply.\\nStrong proficiency in data analysis tools and programming languages (e.g., Python, R, SQL).\\nFamiliarity with data visualization, statistics, and machine learning is a plus.\\nExceptional analytical and problem-solving skills.\\nExcellent communication and collaboration abilities.\\nExcellent written and verbal communication skills in English, with a TOEIC score preferred.\\nA genuine interest in electronics manufacturing and technology.\\nPreferred Qualifications (Advantageous):\\nExperience with machine learning and predictive modeling techniques.\\nProficiency in advanced data visualization tools (e.g., Tableau, Power BI).\\nKnowledge of electronics manufacturing processes and technologies.\\nExperience in API development or working with developers to integrate data systems.\", 'welfare_and_benefits': \"Welfare and Benefits\\nDiscount for Sony products\\nJLPT Certificate Allowance\\nTOEIC Score Allowance\\nProvident Fund\\nStaff training and development\\nOvertime\\nFuel/transportation fees\\nMarriage gift\\nOrdination gift\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nOrdination leave\\nEmployee's uniform\\nFuneral payment support\\nAnnual trip or party\\nAttendance bonus or other special compensation\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [18]: {'job_title': 'เจ้าหน้าที่วิเคราะห์ข้อมูล', 'company_name': 'F - Plus Co., Ltd.', 'industry': 'Beverages/Food/Restaurant', 'job_url': 'https://www.jobtopgun.com/en/job/21518/173', 'posted_time': 'Beverages/Food/Restaurant', 'experience': '2 - 3 Year', 'salary': '2 - 3 Year', 'education': \"Bachelor's Degree or Higher\", 'location': '30,000 - 40,000 baht/month', 'responsibility': 'จัดทำ Template สำหรับการนำเสนอข้อมูลให้เหมาะสมกับการใช้วิเคราะห์\\nรวบรวมข้อมูลด้านต่าง ๆ ที่ได้รับมอบหมายได้อย่างถูกต้องและครบถ้วน\\nทำการสรุปข้อมูลต่าง ๆ และจัดทำขึ้นเป็นไฟล์ Presentation ผ่าน PowerPoint หรือ Template อื่นๆ\\nสามารถวิเคราะห์แนวโน้มหรือผลลัพธ์ที่พบจากข้อมูลที่สรุปมาได้\\nอื่นๆ ตามที่ได้รับมอบหมายจากผู้บังคับบัญชา', 'requirements': 'Requirements\\nเพศชาย-หญิง อายุ 26-28 ปี \\nวุฒิการศึกษา ปริญาตรี สาขาเศรษฐศาสตร์ /สถิติประยุกต์ / สาขาทางคอมพิวเตอร์ธุรกิจ หรือสาขาที่เกี่ยวข้อง\\nมีประสบการณ์ด้านข้อมูลสถิติ หรือบริหารสินค้าในธุรกิจ FMCG อย่างน้อย 2-3 ปี \\nสามารถใช้โปรแกรม Power BI, Google Drive, Google Doc, Google Sheet, Data Studio ได้ดี\\nสามารถ พูด อ่าน เขียน ภาษอังกฤษได้ดี ', 'welfare_and_benefits': \"Welfare and Benefits\\nAccommodation allowance\\nAnnual health check up\\nAnnual income raise\\nAnnual vacation 6-12 days\\nCare package for illness/childbirth\\nComplementary company uniforms\\nFuneral support for employee/family members\\nGood employee awards\\nHealth insurance (IPD/OPD)\\nIn-house and public training\\nLife and accident insurance\\nMedical support for employee's family members\\nPublic holidays (align with labor law)\\nScholarships for employee's children\\nShift perdiem\\nProvident Fund\\nการฝึกอบรมภายใน-ภายนอก\\nStaff training and development\\nOvertime\\nAccommodation allowance (in other provinces)\\nScholarship/ education allowance\\nFuel/transportation fees\\nMarriage gift\\nค่ารักษาพยาบาลบุคคลในครอบครัว\\nOrdination gift\\nPer diem\\nVehicle depreciation allowance\\nTelephone bill allowance\\nตรวจสุขภาพประจำปี (ฟรี)\\n5-day work week\\nประกันชีวิต,ประกันอุบติเหตุ,ประกันสุขภาพ (IPD/OPD)\\nSocial security\\nHealth insurance\\nAccident Insurance\\nปรับเงินประจำปี\\nOrdination leave\\nวันลากิจได้รับค่าจ้าง 6 วันต่อปี\\nEmployee's uniform\\nเงินช่วยเหลือกรณีพนักงาน/บุคคลในครอบครัวเสียชีวิต\\nFuneral payment support\\nAnnual trip or party\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [19]: {'job_title': 'A Data Protection Officer (DPO)', 'company_name': 'Sri Trang Agro-Industry Public Co., Ltd.', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/4084/505', 'posted_time': '04/09/2024', 'experience': '1 - 3 Year', 'salary': '1 - 3 Year', 'education': \"Master's Degree\", 'location': 'Negotiable', 'responsibility': \"1. Ensure Compliance: Monitor and ensure the organization's compliance with data protection laws, regulations, and policies. 2. Advisory Role: Act as an advisor to the organization and its employees on matters related to data protection and privacy. 3. Risk Assessment: Conduct risk assessments to identify and evaluate data protection risks associated with the processing of personal data. 4. Policy Development: Develop and implement data protection policies, procedures, and guidelines to ensure adherence to legal requirements and best practices. 5. Training and Awareness: Provide training to staff on data protection laws, policies, and procedures to raise awareness and ensure compliance at all levels. 6. Incident Response: Develop and oversee procedures for responding to data breaches or incidents involving the unauthorized access or disclosure of personal data. 7. Monitoring and Auditing: Regularly monitor data processing activities and conduct audits to ensure compliance and identify areas for improvement. 8. Communication with Authorities: Serve as the point of contact for data protection authorities and cooperate with them as required. 9. Data Subject Rights: Manage and facilitate data subject rights requests, ensuring timely responses and adherence to individual privacy rights. 10. Vendor Management: Assess and monitor the data protection practices of third-party vendors and service providers to ensure compliance with data protection requirements.\", 'requirements': \"Requirements\\nBachelor's or Master's degree in law, information technology, or a related field.\\nIn-depth knowledge of data protection laws and regulations, especially Personal Data Protection Act.\\nProfessional certifications in data protection (e.g., CIPP/E, CEPAS DPO) (if any)\\nStrong communication and interpersonal skills.\\nAnalytical mindset with the ability to assess risks and propose solutions.\\nExperience in privacy impact assessments and managing data protection incidents.\\nKnowledge of IT security and data management practices (if any)\\nAbility to work independently and collaboratively with various departments.\", 'welfare_and_benefits': \"Welfare and Benefits\\nMedical insurance\\nProvident Fund\\nStaff training and development\\nAccommodation allowance (in other provinces)\\nFuel/transportation fees\\nPer diem\\nVehicle depreciation allowance\\nTelephone bill allowance\\nค่าใช้จ่ายในการเดินทาง\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nประกันอุบัติเหตุ\\nสวัสดิการบ้านพัก (ประจำโรงงาน) กลุ่มงาน ยางธรรมชาติ (STA)\\nEmployee's uniform\\nFuneral payment support\\nAnnual trip or party\\nAnnual bonus\"}\n",
            "Scraped data for job [20]: {'job_title': 'Data Governance and Data Analytic Specialist', 'company_name': 'Isuzu Motors (Thailand) Co.,Ltd.', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/1309/274', 'posted_time': '04/09/2024', 'experience': '10 - 20 Year', 'salary': '10 - 20 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Key Responsibilities\\n• Management and promote the task of Data Analytic & Business Intelligent (BI) in business department\\n• Create the policy of Data Utilization and promote Digital transformation\\n• Project manager in work scope.\\n• Build Digital team, Coaching and transfer knowledge\\n• Track and evaluate the effectiveness of data utilization and digital tools management.\\n• Promote Data governance and big data management', 'requirements': 'Requirements\\nProfile & Qualifications Required\\n• Age preferably 40 and up\\n• Bachelor’s degree in Data science, Data engineer, Com science, Information management, Information technology or Business administration in Data field\\n• Good in English communication (Have TOEIC score more than 550 up will be advantage)\\n• Special knowledge required are RPG, Advance excel, Power BI, Power query, Python, to perform in-depth analysis data, identifying trends, Patterns, and insights\\n• Have skill Data Management Tools, Data Governance Framework or Data quality management and Continuous learning will be advantage\\n• Have experience in Business data analysis', 'welfare_and_benefits': \"Welfare and Benefits\\nAnnual leave maximum 14 days\\nAnnual trip allowance\\nBonus (variable bonus - pay twice / year)\\nCompany bus service (around Chachoengsao area)\\nCompany uniform (3 sets / year)\\nEmployee’s children education allowance\\nFree shuttle bus\\nGroup Insurance\\nJapanese and English education allowance\\nLife insurance\\nMedical treatment allowance For employee For spouse and children\\nMonday – Friday and some Saturday\\nRegular working time: 07.30 – 16.30\\nTotal working day: 250 days / year\\nProvident Fund\\nStaff training and development\\nOvertime\\n5-day work week\\nSocial security\\nEmployee's uniform\\nAnnual trip or party\\nAnnual bonus\"}\n",
            "Scraped data for job [21]: {'job_title': 'Data analysis officer', 'company_name': 'Isuzu Motors (Thailand) Co.,Ltd.', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/1309/273', 'posted_time': '04/09/2024', 'experience': '0 - 3 Year', 'salary': '0 - 3 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': 'Key Responsibilities\\n• Data analysis\\n- Analyze data from various sources to identify trends, patterns and insights\\n- Develop and implement data models and algorithms to support business decisions\\n• System analysis\\n- Evaluate existing systems and process to identify area for improvement\\n• Testing and Validation\\n- Test and validate data models, System enhancements, and new features to ensure accuracy and reliability\\n- Troubleshoot and resolve issues related to data and system functionality', 'requirements': 'Requirements\\nProfile & Qualifications Required\\n• Age preferably 22 - 25 years old.\\n• Bachelor’s degree in Data science, Data engineer, Com science, Information management, Information technology or Business administration in Data field\\n• Good in English communication (Have TOEIC score more than 400 up will be advantage)\\n• Special knowledge required are RPG, Advance excel, Power BI, Power query, Python, to perform in', 'welfare_and_benefits': \"Welfare and Benefits\\nAnnual leave maximum 14 days\\nAnnual trip allowance\\nBonus (variable bonus - pay twice / year)\\nCompany bus service (around Chachoengsao area)\\nCompany uniform (3 sets / year)\\nEmployee’s children education allowance\\nFree shuttle bus\\nGroup Insurance\\nJapanese and English education allowance\\nLife insurance\\nMedical treatment allowance For employee For spouse and children\\nMonday – Friday and some Saturday\\nRegular working time: 07.30 – 16.30\\nTotal working day: 250 days / year\\nProvident Fund\\nStaff training and development\\nOvertime\\n5-day work week\\nSocial security\\nEmployee's uniform\\nAnnual trip or party\\nAnnual bonus\"}\n",
            "Scraped data for job [22]: {'job_title': 'เจ้าหน้าที่ Data Support / Data Mining', 'company_name': 'Advice IT Infinite PCL', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/20196/92', 'posted_time': '04/09/2024', 'experience': '1 Year', 'salary': '1 Year', 'education': \"Bachelor's Degree\", 'location': '18,000 - 20,000 baht/month + Commission', 'responsibility': '- Maintenance ดูแลฐานข้อมูล\\n- Validate ตรวจสอบความถูกต้อง\\n- ตรวจและแก้ไขตาม Requirement Job\\n- Monitor ดูแลระบบ\\n- ทำข้อมูลสรุปรายงาน\\n- Backup สำรองข้อมูล\\n- จัดการทรัพยากร Database', 'requirements': 'Requirements\\n- ไม่จำกัดเพศ อายุ 22-30 ปี\\n- วุฒิการศึกษาปริญญาตรี สาขาวิศวกรรม/วิทยาศาสตร์คอมพิวเตอร์, เทคโนโลยีสารสนเทศ และสาขาอื่นๆที่เกี่ยวข้อง\\n- สามารถใช้โปรแกรม Microsoft Office ได้ดี\\n- มีความรู้เกี่ยวกับระบบฐานข้อมูลเช่น Mysql , SQL Server , Postgre หรืออื่น ๆ\\n- มีความรู้เกี่ยวกับ SQL Language', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nStaff training and development\\nFuel/transportation fees\\nMarriage gift\\nPer diem\\nSocial security\\nHealth insurance\\nEmployee's uniform\\nFuneral payment support\\nAttendance bonus or other special compensation\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [23]: {'job_title': 'Data Engineer', 'company_name': 'Advice IT Infinite PCL', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/20196/94', 'posted_time': '04/09/2024', 'experience': '1 - 3 Year', 'salary': '1 - 3 Year', 'education': \"Bachelor's Degree\", 'location': '18,000 - 20,000 baht/month + Commission', 'responsibility': '- ออกแบบ สร้าง ดูแลระบบการจัดเก็บข้อมูล การประมวลผลข้อมูล และการวิเคราะห์ข้อมูล\\n- ควบคุมคุณภาพของข้อมูล การเชื่อมต่อระบบและพื้นที่การจัดเก็บข้อมูล\\n- ทำ ETL (Extract, Transform, Load) \\n- พัฒนาและบำรุงระบบเครื่องมือที่เกี่ยวข้องกับการจัดการข้อมูลอย่างต่อเนื่อง ', 'requirements': 'Requirements\\n- ไม่จำกัดเพศ อายุ 23 - 30 ปี\\n- วุฒิการศึกษาปริญญาตรี สาขาวิศวกรรม/วิทยาศาสตร์คอมพิวเตอร์, เทคโนโลยีสารสนเทศ และสาขาอื่นๆที่เกี่ยวข้อง\\n- สามารถใช้โปรแกรม Microsoft Office ได้ดี\\n- มีความรู้เกี่ยวกับระบบฐานข้อมูลเช่น Mysql , SQL Server , Postgre หรืออื่น ๆ\\n- มีความรู้เกี่ยวกับ SQL Language', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nStaff training and development\\nFuel/transportation fees\\nMarriage gift\\nPer diem\\nSocial security\\nHealth insurance\\nEmployee's uniform\\nFuneral payment support\\nAttendance bonus or other special compensation\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Failed to scrape data for job [24]: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"job-details\"]/div[2]/section[4]\"}\n",
            "  (Session info: chrome=128.0.6613.115); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655FBEFD7]\n",
            "\t(No symbol) [0x00007FF655FBF22C]\n",
            "\t(No symbol) [0x00007FF6560097F7]\n",
            "\t(No symbol) [0x00007FF655FE672F]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Scraped data for job [25]: {'job_title': 'Data Analyst', 'company_name': 'Ngern Tid Lor Public Company Limited', 'industry': 'Financial/Banking/Securities, I.T. - Software/Telecommunication, Insurance', 'job_url': 'https://www.jobtopgun.com/en/job/21417/587', 'posted_time': 'Financial/Banking/Securities, I.T. - Software/Telecommunication, Insurance', 'experience': '2 - 5 Year', 'salary': '2 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Develop and implement databases, data analytics and strategies that optimize statistical efficiency and quality.\\nInterpret data , analyze results using statistical techniques.\\nProvide solid segmentation analysis to facilitate business decision making and portfolio management', 'requirements': 'Requirements\\nStrong in analytical and interpersonal.\\nUsing database tools or statistic tools for conduct analysis.\\nExperience in SQL , Data Analyst, Power BI, Tableau, Excel, Python or Mysql Database will be advantage.', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nStaff training and development\\nScholarship/ education allowance\\nMarriage gift\\n5-day work week\\nทุนการศึกษา\\nประกันชีวิต\\nSocial security\\nHealth insurance\\nAccident Insurance\\nOrdination leave\\nสิทธิการเบิกค่าทันตกรรม\\nEmployee's uniform\\nAnnual trip or party\\nPerformance/results-based bonus\\nAnnual bonus\"}\n",
            "Scraped data for job [26]: {'job_title': 'Data Engineer', 'company_name': 'Kiatnakin Phatra Financial Group', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/5440/391', 'posted_time': '04/09/2024', 'experience': '1 - 5 Year', 'salary': '1 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Role and Responsibilities \\n· Create and maintain optimal data pipeline architecture.\\n· Build the infrastructure required for optimal extraction, transformation, and loading of data from\\na wide variety of data sources using SQL and Databricks technologies.\\n· Work with stakeholders including the executive, product, data, and design teams to assist with\\ndata-related technical issues and support their data infrastructure needs.\\n· Build analytics tools that utilize the data pipeline to provide actionable insights into customer\\nacquisition, operational efficiency, and other key business performance metrics.\\n· Assemble large, complex data sets that meet functional and non-functional business\\nrequirements.\\n· Monitor and maintain reliability of big data platform and related tools.\\n· Collaborate with cross-functional teams to deliver the data features and products.\\n· Control and automate the deployment process of data API, job, and data pipeline on the\\nplatform.', 'requirements': 'Requirements\\nQualifications \\n· 5 years of experience in building and optimizing ‘big data’ data pipelines, architectures, and\\ndata sets.\\n· Advanced working SQL knowledge and experience working with relational databases, query\\nauthoring (SQL) and working familiarity with various databases.', 'welfare_and_benefits': \"Welfare and Benefits\\nBirthday Leave\\nDental insurance (สิทธิการเบิกค่าทันตกรรม)\\nLife insurance (ประกันชีวิต)\\nMedical insurance\\nProvident Fund\\nWork from home\\n5-day work week\\nSocial security\\nHealth insurance\\nEmployee's uniform\\nFuneral payment support\\nAnnual bonus\"}\n",
            "Scraped data for job [27]: {'job_title': 'เจ้าหน้าที่อาวุโสวิเคราะห์ข้อมูล', 'company_name': 'Thailand Privilege Card Co., Ltd.', 'industry': 'Travel', 'job_url': 'https://www.jobtopgun.com/en/job/22999/137', 'posted_time': 'Travel', 'experience': '1 - 8 Year', 'salary': '1 - 8 Year', 'education': \"Bachelor's Degree or Higher\", 'location': '30,000 - 80,000 baht/month', 'responsibility': '1. จัดทำรายงานสรุปข้อมูลด้านการลงทุนรายเดือน รายไตรมาส และรายปี\\n2. จัดทำรายงานสรุปผลตอบแทนดอกเบี้ยรับและเงินลงทุนของบริษัท รายเดือน รายไตรมาส รายปี และ ประมาณการล่วงหน้า 3-5 ปี\\n3. จัดทำรายงานผลการดำเนินงานของบริษัท รายเดือน รายไตรมาส รายปี\\n4. จัดทำประมาณการทางการเงิน Financial Forecast, Cashflow Projection Feasibility study\\n5. วิเคราะห์ข้อมูลทางการเงิน: วิเคราะห์ งบการเงิน เช่น งบดุล งบกำไรขาดทุน และงบกระแสเงินสด รวมทั้งรายงานทางการเงินอื่นๆ เพื่อประเมินสถานะทางการเงินของบริษัท\\n6. ศึกษาและวิเคราะห์แนวโน้มด้านการเงินและการลงทุน: วิเคราะห์แนวโน้มตลาดโดยรวมและสภาวะเศรษฐกิจเพื่อคาดการณ์ความเป็นไปได้ของการลงทุนและแนวโน้มในอนาคตทั้งระยะสั้นและ ระยะยาว\\n7. จัดทำรายงานและข้อเสนอแนะโดยรายงานการวิเคราะห์และเสนอแนะแนวทางการลงทุน หรือการตัดสินใจทางการเงินและการลงทุนเสนอผู้บริหารโดยนำเสนอข้อมูลสนับสนุนและผลการวิเคราะห์ เพื่อประกอบการตัดสินใจ\\n8. ติดตามและประเมินผล: ตรวจสอบผลการดำเนินงานด้านการเงินและการลงทุน รวมทั้งเสนอแนะแนวทางการปรับ\\n9. กลยุทธ์ให้สอดคล้องกับแผนงานของบริษัทฯ\\n10. ทำการศึกษาเปรียบเทียบผลการดำเนินงานและการลงทุนของบริษัทฯเพื่อวิเคราะห์จุดแข็ง จุดอ่อน โอกาสและอุปสรรค\\n(S.W.O.T: Strength, Weakness, Opportunities, Threat)\\n11. วางแผนและประมาณการ: การวางแผนงบประมาณด้านการเงิน และการลงทุนเพื่อให้บรรลุเป้าหมายของบริษัทฯ\\n12. ติดตามข่าวสารและการเปลี่ยนแปลงทางด้านการเงินและเศรษฐกิจประกอบการวิเคราะห์โดยรายงานข้อมูลที่อาจส่งผลกระทบต่อบริษัทฯทั้งเชิงบวกและเชิงลบ\\n13. สนับสนุนงานอื่น ๆ ตามที่ได้รับมอบหมาย เพื่อให้หน่วยงานและบริษัท ไทยแลนด์ พริวิเลจ คาร์ด จำกัดบรรลุภารกิจที่กำหนดไว้', 'requirements': 'Requirements\\n• ได้รับปริญญาตรีหรือคุณวุฒิอย่างอื่นที่เทียบได้ในระดับเดียวกัน ในสาขาวิชาใด สาขาวิชาหนึ่ง ทางการเงิน บัญชี บริหารธุรกิจ เศรษฐศาสตร์ และมีประสบการณ์ในด้านงานการเงิน การบัญชี การลงทุน การบริหารสินทรัพย์ อย่างน้อย 5 ปี \\n• ทักษะด้านโปรแกรมคอมพิวเตอร์ ในระดับดี\\n• มีความรู้ด้านเทคโนโลยีสารสนเทศใหม่ \\n• สามารถวางแผนและแก้ไขการดำเนินงาน\\n• สามารถบริหารโครงการได้อย่างมีประสิทธิภาพ\\n• สามารถทำงานภายใต้ความกดดันได้เป็นอย่างดี\\n• มีความใฝ่รู้และเรียนรู้ตลอดเวลา\\n• มีทักษะภาษาอังกฤษในการติดต่อสื่อสารในระดับดี\\n• สามารถปรับเข้ากับวัฒนธรรมขององค์กรได้\\n• สามารถประสานงานระหว่างบริษัทกับบริษัทในเครือ (หมายถึง บริษัทแม่) ได้เป็นอย่างดี\\n• อื่น ๆ เพิ่มเติมตามที่บริษัท ไทยแลนด์ พริวิเลจ คาร์ด จำกัด ประกาศตามตำแหน่งงาน', 'welfare_and_benefits': 'Welfare and Benefits\\nProvident Fund\\n5-day work week\\nประกันชีวิต\\nHealth insurance\\nสิทธิการเบิกค่าทันตกรรม\\nPerformance/results-based bonus'}\n",
            "Scraped data for job [28]: {'job_title': 'เจ้าหน้าที่วิเคราะห์ข้อมูล', 'company_name': 'Better World Green Public Co.,Ltd', 'industry': 'Business Service', 'job_url': 'https://www.jobtopgun.com/en/job/20134/89', 'posted_time': 'Business Service', 'experience': '0 - 3 Year', 'salary': '0 - 3 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': '1.รวบรวมข้อมูลการดำเนินงานขนส่งต่างๆที่ได้รับมาวิเคราะห์\\n2.วิเคราะห์ข้อมูลและปัญหาต่างๆของบริษัทและลูกค้า\\n3.จัดทำข้อมูลเพื่อวิเคราะห์ส่งต่อผู้บริหาร\\n4.วิเคราะห์ข้อมูลการขนส่ง และต้นทุนต่างๆ', 'requirements': 'Requirements\\n- เพศหญิง อายุ 22-35 ปี\\n- วุฒิการศึกษาปริญญาตรี สาขาโลจิสติกส์ การจัดการ หรือสาขาอื่นๆที่เกี่ยวข้อง\\n- ยินดีรับเด็กจบใหม่ไม่มีประการณ์\\n- มีทักษะในการใช้ภาษาอังกฤษ จะพิจารณาเป็นพิเศษ\\n- สามารถใช้โปรแกรม Microsoft office ได้เป็นอย่างดีมาก\\n- สามารถเดินทางไปต่างจังหวัดได้\\n- ทำงานวันจันทร์ – เสาร์ *หยุดสลับเสาร์*', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\nกองทุนเงินทดแทน\\nStaff training and development\\nMarriage gift\\nPer diem\\nตรวจสุขภาพประจำปี\\nSocial security\\nAccident Insurance\\nปรับเงินเดือนประจำปี\\nOrdination leave\\nEmployee's uniform\\nเงินช่วยเหลือพนักงาน (งานแต่ง,งานบวช,คลอดบุตร หรือเงินช่วยเหลืองานศพ(บิดา,มารดา,ภรรยา,บุตร และตัวลูกจ้าง)\\nAttendance bonus or other special compensation\\nAnnual bonus\"}\n",
            "Scraped data for job [29]: {'job_title': 'พนักงานตรวจสอบข้อมูล (ภาษาญี่ปุ่น)', 'company_name': 'Masterpiece group (Thailand) Co.,Ltd.', 'industry': '04/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/255019/12', 'posted_time': '04/09/2024', 'experience': '0 - 2 Year', 'salary': '0 - 2 Year', 'education': \"Bachelor's Degree\", 'location': '18,000 - 25,000 baht/month', 'responsibility': '①\\u3000Data Check (Japanese)\\nเนื้อหางาน ：本人確認：ตรวจสอบข้อมูลต่างๆ ที่คนญี่ปุ่นกรอกข้อมูลในระบบส่งเข้ามา เช่น ทะะเบียนบ้าน ใบขับขี่ ของคนญี่ปุ่นว่าพิมพ์เข้ามาในระบบถูกต้องหรือไม่ ฯลฯ\\nรับสมัคร : พนักงานประจำ \\nระดับภาษาญี่ปุ่น ：N3～N1\\nเวลาทำงาน : ระหว่างเวลา 07.00 น.～ (ทำงาน 8 ชม. พัก 1 ชม. / วัน)\\nวันทำงาน : ตามที่บริษัทกำหนด (ต้องการคนที่ทำวันเสาร์-อาทิตย์ หรือวันหยุดนักขัตฤกษ์ได้)\\nเงินเดือน : 17,000～บาท (ผ่านโปร 3 เดือน จะมีการปรับเงินเดือนให้ตามรอบปรับและการพิจารณา)\\n\\n②\\u3000Data Check (Japanese)\\nเนื้อหางาน ：記事チェック：ตรวจสอบประโยค บทความ สื่อทาง SNS ฯลฯ ที่เป็นภาษาญี่ปุ่น\\nรับสมัคร : พนักงานประจำ จำนวน 2 ตำแหน่ง\\nระดับภาษาญี่ปุ่น ：N2～N1\\nเวลาทำงาน : กะดึก 18.00 น. - 07.00 น. (ทำงาน 12 ชม. พัก 1 ชม. / วัน)\\nวันทำงาน : ตามที่บริษัทกำหนด (ต้องการคนที่ทำวันเสาร์-อาทิตย์ หรือวันหยุดนักขัตฤกษ์ได้)\\nเงินเดือน : 20,000～25,000 บาท (ผ่านโปร 3 เดือน จะมีการปรับเงินเดือนให้ตามรอบปรับและการพิจารณา)\\n※ ต้องการคนที่สามารถใช้ภาษาญี่ปุ่นได้อย่างคล่องแคล่ว\\nโดยเฉพาะการอ่านประโยคภาษาญี่ปุ่น และเข้าใจความหมายได้อย่างรวดเร็วและถูกต้อง\\n\\n③\\u3000Data Check (Japanese)\\nเนื้อหางาน ：企業キャンセル：ตรวจสอบข้อมูลการแจ้งยกเลิกการนัดสัมภาษณ์ และส่งข้อความยืนยันกลับทางอีเมล\\nรับสมัคร : พนักงานประจำ จำนวน 4 ตำแหน่ง\\nระดับภาษาญี่ปุ่น ：N3～N1\\nเวลาทำงาน : ระหว่างเวลา 07.00 น.～ (ทำงาน 8 ชม. พัก 1 ชม. / วัน)\\nวันทำงาน : ตามที่บริษัทกำหนด (ต้องการคนที่ทำวันเสาร์-อาทิตย์ หรือวันหยุดนักขัตฤกษ์ได้)\\nเงินเดือน : 17,000～25,000 บาท (ผ่านโปร 3 เดือน จะมีการปรับเงินเดือนให้ตามรอบปรับและการพิจารณา)\\n※ ต้องการคนที่สามารถอ่านและเข้าใจประโยคภาษาญี่ปุ่นได้อย่างถูกต้องและรวดเร็ว\\nรวมไปถึงทักษะการเขียนภาษาญี่ปุ่น เนื่องจากงานตัวนี้ต้องใช้อีเมลในการสื่อสารด้วย', 'requirements': 'Requirements\\n1. JLPT N3~\\n2. สามารถเข้าใจ วิเคราะห์ข้อความภาษาญี่ปุ่นได้\\n3. มีความสามารถในทักษะภาษาญี่ปุ่นเป็นอย่างดี\\n4. ไม่จำเป็นต้องมีประสบการณ์ ยินดีรับนักศึกษาจบใหม่', 'welfare_and_benefits': 'Welfare and Benefits\\nOvertime\\nFuel/transportation fees\\nตรวจสุขภาพประจำปี\\n5-day work week\\nSocial security\\nพักร้อน\\nAttendance bonus or other special compensation\\nPerformance/results-based bonus'}\n",
            "Scraped data for job [30]: {'job_title': 'Data Management', 'company_name': 'Thai Smile Bus Co.,Ltd.', 'industry': 'Transportation/Logistic', 'job_url': 'https://www.jobtopgun.com/en/job/252263/16', 'posted_time': 'Transportation/Logistic', 'experience': '0 - 5 Year', 'salary': '0 - 5 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': 'ทำหน้าที่ออกแบบระบบ Database ให้เหมาะสมกับการใช้งานขององค์การ\\nดูแลระบบฐานข้อมูล รับผิดชอบการพัฒนาโปรแกรมที่เชื่อมโยงฐานข้อมูลต่างๆ ประสานงานเพื่อวิเคราะห์แก้ปัญหา\\nดูแลระบบ Development และ Preproduction Query ข้อมูลเพื่อใช้วิเคราะห์ / ดูแลจัดการฐานข้อมูลที่จัดเก็บที่อยู่เบื้องหลังและการเรียกใช้ข้อมูลของผู้ใช้ที่อยู่เบื้องหน้า\\nบำรุงรักษา ประสิทธิภาพการทำงาน ความถูกต้องสมบูรณ์และรักษาความปลอดภัยของฐานข้อมูล มีส่วนร่วมในการวางแผลการจัดเก็บข้อมูล การพัฒนาโปรแกรมประยุกต์และการแก้ไขปัญหาต่างๆ ที่เกิดขึ้น\\nวางรูแปบบจัดการและทดสอบแผนการสำรองและการกู้คืนข้อมูล ตรวจสอบเนื้องที่สำหรับจัดเก็จการสำรองข้อมูล ขั้นตอนการสำรองข้อมูลและการกู้คืนข้อมูล สามารถทำงานได้อย่างถูกต้อง', 'requirements': 'Requirements\\nอายุไม่เกิน 30 ปี\\nระดับการศึกษาปริญญาตรี สาขาคอมพิวเตอร์, เทคโนโลยีสารสนเทศ หรือสาขาอื่นที่เกียวข้อง', 'welfare_and_benefits': 'Welfare and Benefits\\nชุดยูนิฟอร์ม\\n5-day work week\\nSocial security\\nAccident Insurance\\nประกันอุบัติเหตุแบบกลุ่ม\\nPerformance/results-based bonus\\nใช้บริการการเดินทางด้วยรถเมล์ไฟฟ้า/เรือไฟฟ้า ฟรี!!'}\n",
            "Failed to handle element a[31]: Message: \n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655FBEFD7]\n",
            "\t(No symbol) [0x00007FF655FBF22C]\n",
            "\t(No symbol) [0x00007FF6560097F7]\n",
            "\t(No symbol) [0x00007FF655FE672F]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Navigating to jobtopgun 'data' search page number: 2\n",
            "Scraped data for job [1]: {'job_title': 'Data Analysis', 'company_name': 'Casa Rocca Co.,Ltd', 'industry': 'Construction/Furnishings, Packaging, Trading/Import/Export, Graphic Design', 'job_url': 'https://www.jobtopgun.com/en/job/1882/42', 'posted_time': 'Construction/Furnishings, Packaging, Trading/Import/Export, Graphic Design', 'experience': '2 - 5 Year', 'salary': '2 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': '25,000 - 30,000 baht/month', 'responsibility': '- Update and develop product information for all systems and inform all relevant stakeholders.\\n- Develop, experiment with, and improve new products to ensure that quality and specifications meet the required standards prior to launch.\\n- Conduct research and analysis on competitors, market trends, usage and customer feedback to effectively meet objectives.\\n- Measure, analyze, and report on the performance of product information and sales on a regular basis.\\n- Assist with product information and work closely with the sales team to ensure all product information is completely correct.\\n- Oversee and record product information for all sales materials.\\n- Collaborate closely with both internal and external stakeholders to achieve team targets.\\n- Undertake other assignments from the director to achieve team targets.', 'requirements': \"Requirements\\n- Minimum 3 years of experience in product development, product management, or related field.\\n- Bachelor's degree in Materials Engineer, Civil Engineer,Industrial Engineering, or related field.\\n- Working experience from construction material and Zoho will be an advantage.\\n- Highly proficient in Excel, Google Sheets, Power BI, and SQL, with strong presentation skills.\\n- Creative thinking and problem-solving skills, with a keen eye for detail.\\n- Strong organizational and time management skills, with the ability to prioritize tasks and meet deadlines.\\n- Ability to collect data, analysis, and interpret it into a profitability marketing plan.\\n- Ability to work independently and collaboratively in a fast-paced, high-pressure environment.\\n- Ability to gain a deep understanding of new knowledge and company products.\", 'welfare_and_benefits': 'Welfare and Benefits\\nกองทุนทดแทน\\nStaff training and development\\nค่าทันตกรรม\\n5-day work week\\nSocial security\\nHealth insurance\\nAccident Insurance\\nวันลา ได้มากกว่ากฎหมายกำหนด\\nวันหยุดประเพณี อย่างน้อย 15 วัน\\nวันหยุดพักผ่อนประจำปี 8-12 วัน\\nส่วนลดค่าอาหารและเครื่องดื่มของบรฺิษัทในเครือ\\nFuneral payment support\\nAnnual trip or party\\nPerformance/results-based bonus'}\n",
            "Scraped data for job [2]: {'job_title': 'Data Analyst (Management trainee contract 1 year)', 'company_name': 'Mattel Bangkok Limited', 'industry': 'Toy', 'job_url': 'https://www.jobtopgun.com/en/job/4718/331', 'posted_time': 'Toy', 'experience': '0 - 2 Year', 'salary': '0 - 2 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': \"We are seeking a skilled Data Analyst to join our team to oversee the implementation and support of our company's request application system. This role involves designing, coding, and maintaining efficient solutions while providing ongoing support for operational processes. The ideal candidate will have a strong background in system design, user acceptance testing (UAT), and operational support.\\nResponsibility:\\nImplementation and support of the company's request application system.\\nParticipate in system design, writing, and implementing efficient code.\\nConduct and facilitate UAT and augment test scenarios to successfully test solutions implement and monitor operational processes and provide ongoing operational support.\\nMaintaining and upgrading existing systems.\\nCollaborates with requester on system design decisions, user experience, complex issue resolution, and process design.\", 'requirements': \"Requirements\\nQualification:\\nBachelor's degree in IT, Computer Science, or equivalent.\\nWork experience may be considered in in in of education qualifications.\\nWorking in user requirement analysis and software development\\nExperience with Microsoh Power Platform - Power Bu/Automate.\\nExperience or working familiarity with C#, .NET Core, Web APIs, SQL, React, Angular, and SVN.\\nKnowledge of CH, .NET Core, and Database design is preferred.\\nComputer skills in the Microsoft Office program.\\nGood communication skills - both written and verbal in English & Thai.\\nPossess strong technical knowledge of NET-based framework with MVC architectures, and hands-on\\nExperience in programming languages such as ASP.NET, C#, VB.NET, HTML, XML, Java, JavaScript, REST API, and MS SQL database.\\nWelfare and Benefits:\\nContract 1 year.\\n5 Working day Monday to Friday (7.30 am. – 4.30 pm.)\\nIT Equipment support (PC / Laptop / Headset)\\nOvertime\\nMeal allowance\\nSocial security\\nTraining and suminar\\nAnnual trip or party\\nSmart Point\\nทำงานที่นิคมอุตสาหกรรมบางปู เขตส่งออก ใกล้รถไฟฟ้า BTS สายสีเขียว สถานีเคหะฯ\\nมีรถรับส่งเส้นทางหลักสายสุขุมวิท บางนา แพรกษา เทพารักษ์ ศรีนครินทร์ กิ่งแก้ว \", 'welfare_and_benefits': 'Welfare and Benefits\\nMeal allowance\\nSmart Point\\nStaff training and development\\nOvertime\\n5-day work week\\nSocial security\\nAnnual trip or party'}\n",
            "Scraped data for job [3]: {'job_title': 'Senior Data Analyst (สังกัดปัญญธารา)', 'company_name': 'CP ALL PUBLIC COMPANY LIMITED (General)', 'industry': '03/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/83/1676', 'posted_time': '03/09/2024', 'experience': '4 - 8 Year', 'salary': '4 - 8 Year', 'education': \"Bachelor's Degree\", 'location': 'Negotiable', 'responsibility': 'ความรับผิดชอบหลัก\\n1. รวบรวมและกำหนด Data Sources จากหลายแหล่งข้อมูล โดยใช้ Data Analysis Tool Power BI\\n2. ออกแบบ จัดทำ Data Visualization สร้าง Report Dashboard/Automated Dashboard\\n3. ออกแบบ และนำเสนอ Solution ทางด้าน BI ให้ตอบโจทย์กลยุทธ์ขององค์กรได้อย่างเหมาะสม\\n4. วิเคราะห์และสรุปผลเชิงลึก เพื่อหา Insight จากข้อมูลและระบุแนวโน้มที่เกิดขึ้นได้ เพื่อใช้ในการตัดสินใจเชิงกลยุทธ์ได้\\n5. นำเสนอผลการวิเคราะห์ข้อมูล ให้กับผู้บริหาร และผู้เกี่ยวข้อง', 'requirements': 'Requirements\\nคุณสมบัติ\\nอายุ 28 ปี ขึ้นไป\\nปริญญาตรีหรือโท สาขา เทคโนโลยีสารสนเทศ, วิทยาการคอมพิวเตอร์ ,วิศวกรรมคอมพิวเตอร์ ,เศรษฐศาสตร์ , สถิติ หรือสาขาอื่นๆ ที่เกี่ยวข้อง\\nสามารถใช้โปรแกรม Microsoft Excel อยู่ในระดับดี - ดีมาก\\nมีประสบการณ์ตั้งแต่ 0 - 5 ปี ในด้านวิเคราะห์สถิติ, วิเคราะห์ข้อมูล, บริหารข้อมูล, การนำเสนอข้อมูล รายงานผล และด้านอื่นๆ ที่เกี่ยวข้อง\\nหากมีความรู้ด้านภาษา SQL, Python และการใช้โปรแกรม Power BI จะพิจารณาเป็นพิเศษ\\nสถานที่ปฏิบัติงาน : อาคาร The Tara แจ้งวัฒนะ (ปากเกร็ด นนทบุรี)', 'welfare_and_benefits': 'Welfare and Benefits\\nProvident Fund\\n5-day work week\\nSocial security\\nปรับเงินประจำปี\\nโบนัสปีละ 4 ครั้ง'}\n",
            "Scraped data for job [4]: {'job_title': 'Data Analyst', 'company_name': 'CP ALL PUBLIC COMPANY LIMITED (General)', 'industry': '03/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/83/1650', 'posted_time': '03/09/2024', 'experience': '0 - 5 Year', 'salary': '0 - 5 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'วิเคราะห์ข้อมูล ยอดขาย กำไร หรือข้อมูลอื่น ๆ ที่ได้รับมอบหมาย\\nออกแบบและจัดทำฐานข้อมูลต่าง ๆ พร้อมปรับปรุง Update ฐานข้อมูลให้ถูกต้องเป็นปัจจุบัน\\nเฝ้าระวัง ตรวจสอบ และสังเกตข้อมูลที่ได้รับมอบหมายในทุกมิติ เช่น ยอดขาย, กำไร, จำนวนลูกค้า, ปริมาณสินค้า, ค่าใช้จ่าย เป็นต้น เพื่อสนับสนุนให้ยอดขายเติบโต ตามเป้าหมายสายงาน หรือที่องค์กรตั้งไว้\\nประเมินผลและติดตามผล รายสัปดาห์ / รายเดือน / รายไตรมาส / รายปี จัดการข้อมูลพร้อมรายงานผล', 'requirements': 'Requirements\\nอายุ 22-30 ปี\\nปริญญาตรี คณะวิทยาศาสตร์ สาขา สถิติ, สถิติประยุกต์, คณิตศาสตร์ หรือสาขาอื่นๆ ที่เกี่ยวข้อง\\nสามารถใช้โปรแกรม Microsoft Excel อยู่ในระดับดี - ดีมาก\\nมีประสบการณ์ตั้งแต่ 0 - 5 ปี ในด้านวิเคราะห์สถิติ, วิเคราะห์ข้อมูล, บริหารข้อมูล, การนำเสนอข้อมูล รายงานผล และด้านอื่นๆ ที่เกี่ยวข้อง\\nหากมีความรู้ด้านภาษา SQL, Python และการใช้โปรแกรม Power BI จะพิจารณาเป็นพิเศษ\\nสถานที่ปฏิบัติงาน : อาคาร The Tara แจ้งวัฒนะ (ปากเกร็ด นนทบุรี)', 'welfare_and_benefits': 'Welfare and Benefits\\nProvident Fund\\nSocial security\\nปรับเงินประจำปี\\nโบนัสปีละ 4 ครั้ง'}\n",
            "Scraped data for job [5]: {'job_title': 'Data Engineer', 'company_name': 'Roojai Co.,Ltd.', 'industry': 'Insurance', 'job_url': 'https://www.jobtopgun.com/en/job/24170/189', 'posted_time': 'Insurance', 'experience': '1 - 7 Year', 'salary': '1 - 7 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Responsibilities\\nWe are seeking a detail-oriented and proactive Data Engineer to join our team. As a Data Engineer, you will play a crucial role in leveraging data to drive sales strategies, optimize operational efficiency, and enhance customer satisfaction. You will manage and handle all the ETL required to sync with insurer and partners to ensure that product on Kumka website is always updated as well as improve the process between Kumka and partners. You will work closely with cross-functional teams to collect, process, analyze, and visualize data, ultimately empowering decision-making and fueling business growth.\\nJob Duties\\nDesign and implement data pipelines for collecting, processing, and transferring data.\\nDevelop ETL (Extract, Transform, Load) processes to ensure data accuracy and consistency.\\nCollaborate with internal department within Kumka as well as group office to understand data requirements and develop solutions to achieve the target outcome.\\nWork with Kumka partners to ensure smooth data transfer.\\nEnsure data is organized, structured, and accessible for analytics and reporting.\\nIntegrate data from various sources, including APIs, databases, and external systems.\\nTransform and cleanse data to meet business needs.\\nDocument data pipeline architectures, processes, and workflows.\\nMonitor data pipelines and infrastructure for anomalies and errors.\\nCommunicate technical concepts and data insights to non-technical team members.\\nAssist any ad-hoc projects. ', 'requirements': 'Requirements\\nRequirements\\nBachelor’s degree in data science, Statistics, Computer Science or similar.\\nAdvanced MS Office skills, with distinct Excel. SQL expertise\\nExperience with ETL tools and techniques for data integration and transformation.\\nExperience with SQL server or another database language.\\nExperience in data analysis and visualization tools such as Tableau, MS Power BI, QLIK, etc.\\nSome experience with Salesforce and AWS would be a big advantage.\\nExcellent problem-solving and analytical abilities.\\nGood communications both verbal and written in English.\\nPREFERRED SKILLS/EXPERIENCE: Project management, Problem-solving, and critical thinking attitude. Find problems and come up with solutions.', 'welfare_and_benefits': \"Welfare and Benefits\\nAnnual leave 12Days Plus business leave 3 Days\\nBonus\\nDental insurance (สิทธิการเบิกค่าทันตกรรม)\\nLife insurance (ประกันชีวิต)\\nMedical insurance\\nProvident Fund\\nStaff training and development\\nตรวจสุขภาพประจำปี\\n5-day work week\\nประกันชีวิต\\nSocial security\\nHealth insurance\\nประกันสุขภาพสำหรับคู่สมรสและบุตร\\nAccident Insurance\\nปรับเงินเดือนประจำปี\\nพักร้อน 12 วัน + ลากิจ 3 วัน\\nอบรมสัมนา\\nEmployee's uniform\\nFuneral payment support\\nAnnual trip or party\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [6]: {'job_title': 'Security Manager (Data Center)', 'company_name': 'Gulf Energy Development Public Company Limited', 'industry': '02/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/17668/925', 'posted_time': '02/09/2024', 'experience': '8 - 9 Year', 'salary': '8 - 9 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Security Screening: Conduct security screening of personnel, visitors, and vehicles entering data center facilities. Perform bag checks, metal detection, and other screening procedures to prevent the introduction of unauthorized items or contraband\\nIncident Reporting and Documentation: Document security incidents, breaches, and near misses. Prepare detailed incident reports, including timelines, actions taken, and lessons learned. Maintain accurate records of security incidents and related documentation\\nCollaboration and Coordination: Collaborate with internal stakeholders, including operations teams, IT staff, and management, to address security concerns and requirements. Coordinate with external security agencies, law enforcement, and emergency responders as needed\\nSecurity Policy Development: Assist in the development and implementation of security policies, procedures, and guidelines specific to data center operations. Ensure alignment with industry standards, regulatory requirements, and best practices\\nRisk Assessment and Mitigation: Conduct security risk assessments and vulnerability assessments to identify potential security risks and weaknesses. Develop mitigation strategies and controls to address identified risks and enhance security posture\\nSurveillance and Monitoring: Operate and monitor surveillance systems, including CCTV cameras, alarms, and motion sensors, to detect security breaches and anomalies. Conduct regular surveillance rounds to ensure the integrity and security of data center facilities\\nSecurity Incident Response: Respond promptly to security incidents, alarms, and emergencies. Investigate security breaches, unauthorized access attempts, and suspicious activities. Implement appropriate security protocols and procedures to mitigate risks and minimize impact\\nPhysical Security: Ensure the physical security of data center infrastructure, equipment, and assets. Conduct regular inspections and audits of physical security controls, such as locks, barriers, and fencing. Implement measures to protect against theft, vandalism, and sabotage', 'requirements': 'Requirements\\nAt least 3 year experience in Security related audits\\nUnderstanding of local security law\\nMinimum 2 year experience in contract management\\nMaintain/Planning Opex/Capex Budgeting (AOP)\\nAbility to read Archi drawing/Structural Drawing\\nReport on physical security strategy and metrics (KPI)\\nAdded advantage for Personnel with Military/Police Background\\nCreativity, problem solving skills, negotiation and systematic thinking\\nFluent in English both written and verbal (Minimum 500 TOEIC score)\\nGoal-Oriented, Unity, Learning, Flexible', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\n5-day work week\\nHealth insurance\\nEmployee's uniform\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [7]: {'job_title': 'Manager - Data Center NOC (Samut Prakan)', 'company_name': 'Gulf Energy Development Public Company Limited', 'industry': 'Petroleum/Energy/Mining', 'job_url': 'https://www.jobtopgun.com/en/job/17668/944', 'posted_time': 'Petroleum/Energy/Mining', 'experience': '8 - 10 Year', 'salary': '8 - 10 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Manage NOC operations, ensuring compliance with ISO, ISMS, and ITIL standards\\nOversee shift operations, including scheduling NOC team members to meet operational demands\\nMaintain operational integrity and handle incident management to ensure consistent service delivery\\nAnalyze KPIs and statistics to identify areas for service improvement\\nServe as an escalation contact for NOC operations\\nConduct performance evaluations and implement disciplinary action when necessary\\nDevelop and implement policies and procedures to enhance efficiency and customer service\\nDefine performance metrics and provide operational documentation to management\\nPlan and implement operations continuity strategies, including training programs\\nSupervise environmental controls in data halls to meet standards and address issues promptly\\nManage alarm monitoring systems and coordinate responses with relevant teams\\nMaintain and develop GSA Opsware systems, including ECMS, CPMS, EPMS, and CMMS\\nMonitor performance of GSA applications and services\\nConduct quality assurance audits to minimize downtime and improve response times\\nGenerate SLA and other reports as requested by clients\\nPrepare colocation usage reports to support finance department needs', 'requirements': 'Requirements\\nRequired to work a flexible schedule according to business needs/events (to include, but not limited to nights and weekends and/or shift rotation)\\nEfficiently interact with computing systems\\nEfficiently interact with GSA OpsWare such as ECMS, CPMS, EPMS, CMMS and tenanat portal\\nAbility to navigate and effectively utilize ticketing systems\\nExcellent oral and written communication and interpersonal skills\\nDisplay strong organizational skills\\nWell versed with various network circuit types, configurations, and physical deployment of the circuits\\nComputer literate with an emphasis on Microsoft Office Suite\\nDemonstrated knowledge of various network topologies and troubleshooting practices\\nExperience with equipment terminal access applications (Ex.: CRT, Putty, SSH)\\nExperience with network monitoring software applications\\nCreativity, problem solving skills, negotiation and systematic thinking\\nFluent in English both written and verbal (Minimum 500 TOEIC score)\\nGoal–Oriented, Unity, Learning, Flexible', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\n5-day work week\\nHealth insurance\\nEmployee's uniform\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [8]: {'job_title': 'Data Center Operations-Shift (Samut Prakan) (New Graduate are welcome)', 'company_name': 'Gulf Energy Development Public Company Limited', 'industry': '02/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/17668/929', 'posted_time': '02/09/2024', 'experience': '5 - 7 Year', 'salary': '5 - 7 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Provide day to day installation, maintenance, and repair of all facilities in the data center\\n24x7 shift work responsibility when qualified and designated\\nProvide requested reporting and documentation\\nSupport of facility, development, and construction teams\\nPerform tasks as assigned by DC operation manager\\nRespond to customer requests, power, cooling, and facility audits\\nFirst tier investigate any power, communication, or cooling anomalies\\nAttend assigned meetings and training\\nAssist in ensuring customer compliance with GSA Acceptance Usage Policy (AUP)\\nProvide technical safeguard when needed', 'requirements': 'Requirements\\nMust be familiar with safety requirements and OSHA regulations or Thailand safety regulations\\nBasic understanding of electrical and mechanical systems that may be employed in a data center environment. This may include electrical feeders, transformers, generators, switchgear, UPS systems, DC power systems, ATS/STS units, PDU units, air handling units, cooling towers, and fire suppression systems\\nFamiliar with Interpret wiring diagrams, schematics, and electrical drawings\\nAbility to express ideas clearly, concisely, and effectively with contractors performing maintenance or upgrades on systems installed in the data center environment\\nExcellent verbal, written, and interpersonal communication skills\\nAbility to analyze and make suggestions for problem resolution\\nSolve problems with good initiative and sound judgment\\nCreativity, problem solving skills, negotiation and systematic thinking\\nFluent in English both written and verbal (Minimum 500 TOEIC score)\\nGoal–Oriented, Unity, Learning, Flexible', 'welfare_and_benefits': \"Welfare and Benefits\\nProvident Fund\\n5-day work week\\nHealth insurance\\nEmployee's uniform\\nPerformance/results-based bonus\"}\n",
            "Scraped data for job [9]: {'job_title': 'เจ้าหน้าที่คีย์ข้อมูล', 'company_name': 'Sevenfive Distributor Co.,Ltd.', 'industry': 'Retail/Wholesale', 'job_url': 'https://www.jobtopgun.com/en/job/20217/153', 'posted_time': 'Retail/Wholesale', 'experience': '1 Year', 'salary': '1 Year', 'education': 'Certificate of Vocational Education or Diploma of Vocational Education', 'location': 'Depend on qualifications and experience', 'responsibility': '1. คีย์ข้อมูลลงโปรแกรมต่างๆ\\n2. ทำรายงาน Excel ส่งผู้บังคับบัญชาตามที่ได้รับมอบหมาย\\n3. งานอื่นๆ ตามที่ได้รับมอบหมาย', 'requirements': 'Requirements\\n1. ชาย/หญิง อายุตั้งแต่ 20 ปี ขึ้นไป\\n2. จบการศึกษาระดับ ม.6 /  ปวช. ขึ้นไป\\n3. มีความรับผิดชอบต่อหน้าที่ ตรงต่อเวลา ละเอียดรอบคอบ คล่องตัว \\n4. มีไหวพริบสามารถทำงานหลายอย่างได้ในเวลาเดียวกัน\\n5. พิมพ์ดีด ไทย-อังกฤษ ได้คล่อง\\n6. ใช้โปรแกรม Excel ได้เป็นอย่างดี *พิจารณาเป็นพิเศษ*\\n7. ทำงานจันทร์ - เสาร์', 'welfare_and_benefits': 'Welfare and Benefits\\nStaff training and development\\nตรวจสุขภาพประจำปี\\nSocial security\\nปรับค่าจ้างประจำปี\\nวันหยุดพักร้อน (6-10 วัน)\\nวันหยุดพิเศษวันคล้ายวันเกิด\\nส่วนลดซื้อสินค้าของบริษัท\\nเงินช่วยเหลือกรณีต่างๆ (สมรส, คลอดบุตร, อุปสมบท, เยี่ยมไข้, ฌาปนกิจ)\\nAttendance bonus or other special compensation\\nAnnual bonus'}\n",
            "Scraped data for job [10]: {'job_title': 'Data Engineer', 'company_name': 'Ocean Life Insurance Public Company Limited', 'industry': '02/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/4400/719', 'posted_time': '02/09/2024', 'experience': '5 - 10 Year', 'salary': '5 - 10 Year', 'education': \"Master's Degree\", 'location': 'Negotiable', 'responsibility': '', 'requirements': 'Requirements\\n• ทักษะด้าน SQL ขันสูง และการทำงานกับหลากหลาย Databases\\n• ทักษะและความรู้ Cloud Platform (Amazon AWS, Microsoft Azure หรือ Google Cloud Platform)\\n• ทักษะด้าน ETL/ELT Tool และ Scripts\\n• ทักษะด้านการเขียนโปรแกรม (object-oriented/object function scripting languages eg., Python, Java, C++, Scala, etc.)\\n• ทักษะในการวิเคราะห ข์ันสูง วางแผนการปฏิบัติงาน และการสื่อสารที่ดี\\n• ประสบการณ์ทางด้านการพัฒนา Data Pipeline หรือโครงการด้าน Data Analytic ไม่น้อยกว่า 5 ปี\\n• ประสบการณ์ทางด้านการออกแบบ Data Model และ/หรือ Enterprise Data Model\\n• ประสบการณ์ทางด้านการ Visualize Data หรือการพัฒนา Dashboard / Graph\\n• มีความสามารถในการใชภาษาอังกฤษ คอมพิวเตอร์และโปรแกรมพื้นฐาน', 'welfare_and_benefits': 'Welfare and Benefits\\nDental insurance\\nLife insurance\\nProvident Fund\\nกองทุนสำรองเลี้ยงชีพ\\nการประกันชีวิตกลุ่ม\\nMarriage gift\\nค่ารักษาพยาบาล OPD , IPD\\nค่ารักษาพยาบาล และ ค่าทันตกรรม\\nค่าใช้จ่ายปฏิบัติงานภายนอก\\n5-day work week\\nประกันชีวิต\\nSocial security\\nHealth insurance\\nAccident Insurance\\nOrdination leave\\nวันหยุดพักผ่อนประจำปี\\nสวัสดิการประกันชีวิตกลุ่ม\\nสิทธิการเบิกค่าทันตกรรม\\nเงินช่วยเหลือด้านอื่น ๆ\\nเงินรางวัล ( โบนัสประจำปี )\\nPerformance/results-based bonus\\nAnnual bonus'}\n",
            "Scraped data for job [11]: {'job_title': 'HR Data Analysis and System Supervisor', 'company_name': 'Ngern Tid Lor Public Company Limited', 'industry': '02/09/2024', 'job_url': 'https://www.jobtopgun.com/en/job/21417/869', 'posted_time': '02/09/2024', 'experience': '4 - 12 Year', 'salary': '4 - 12 Year', 'education': \"Bachelor's Degree or Higher\", 'location': 'Negotiable', 'responsibility': 'Data Analytic & Reporting: จัดทำรายงานหรือวิเคราะห์ข้อมูลด้านบริหารทรัพยากรบุคคล\\nData Engineer: ออกแบบและวางระบบการจัดเก็บข้อมูล เพื่อนำไปใช้สำหรับการวิเคราะห์และจัดทำฐานข้อมูลที่เกี่ยวข้อง\\nPeople Data Management: บริหารจัดการข้อมูลด้านทรัพยากรบุคคลให้เป็นปัจจุบันและพร้อมใช้งาน\\nSystem Management & Maintenance: เป็นที่ปรึกษาการแก้ไขปัญหาระบบเบื้องต้น และประสานงานกับทีม IT ที่เกี่ยวข้องเพื่อการป้องกันการเกิดซ้ำในอนาคต', 'requirements': 'Requirements\\n- สามารถใช้โปรแกรมด้านการวิเคราะห์ข้อมูล เช่น Advance Excel/Power BI/ Tableau หรือโปรแกรมอื่นๆ ที่ใกล้เคียงได้\\n- มีประสบการณ์ด้านการจัดการข้อมูลหรือระบบสารสนเทศในการทำงานอย่างน้อย 4 ปี\\nหากสามารถใช้ HR system/Oracle/Success factor/Workday จะได้รับการพิจารณาเป็นพิเศษ\\n- มีทักษะในการแก้ไขปัญหาเฉพาะหน้าได้เป็นอย่างดี', 'welfare_and_benefits': 'Welfare and Benefits\\nLife insurance\\nPerformance bonus\\nProvident Fund\\nStaff training and development\\n5-day work week\\nประกันชีวิต\\nSocial security\\nHealth insurance\\nฝึกอบรมพนักงาน\\nสิทธิการเบิกค่าทันตกรรม\\nPerformance/results-based bonus\\nโบนัสประจำปี'}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[83], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m salary \u001b[38;5;241m=\u001b[39m driver_jobtopgun\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob-details\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[2]/section[1]/div/div[2]/span\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     42\u001b[0m education \u001b[38;5;241m=\u001b[39m driver_jobtopgun\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob-details\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[2]/section[1]/div/div[4]/span\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 43\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[43mdriver_jobtopgun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//*[@id=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjob-details\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]/div[2]/section[1]/div/div[5]/span\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[0;32m     44\u001b[0m responsibility \u001b[38;5;241m=\u001b[39m driver_jobtopgun\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob-details\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[2]/section[2]/div\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     45\u001b[0m requirements \u001b[38;5;241m=\u001b[39m driver_jobtopgun\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob-details\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[2]/section[3]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webelement.py:90\u001b[0m, in \u001b[0;36mWebElement.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The text of the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\_request_methods.py:136\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    133\u001b[0m     urlopen_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m body\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_url_methods:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    145\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m    146\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\_request_methods.py:183\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fields:\n\u001b[0;32m    181\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m urlencode(fields)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:768\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# Request a connection from the queue.\u001b[39;00m\n\u001b[0;32m    767\u001b[0m     timeout_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_timeout(timeout)\n\u001b[1;32m--> 768\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     conn\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;241m=\u001b[39m timeout_obj\u001b[38;5;241m.\u001b[39mconnect_timeout  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;66;03m# Is this a closed/new connection that requires CONNECT tunnelling?\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:290\u001b[0m, in \u001b[0;36mHTTPConnectionPool._get_conn\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Oh well, we'll create a new connection then\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# If this is a persistent connection, check if it got disconnected\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mis_connection_dropped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    291\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResetting dropped connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost)\n\u001b[0;32m    292\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\connection.py:20\u001b[0m, in \u001b[0;36mis_connection_dropped\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_connection_dropped\u001b[39m(conn: BaseHTTPConnection) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:  \u001b[38;5;66;03m# Platform-specific\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Returns True if the connection is dropped and should be closed.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    :param conn: :class:`urllib3.connection.HTTPConnection` object.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_connected\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:260\u001b[0m, in \u001b[0;36mHTTPConnection.is_connected\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait_for_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\wait.py:117\u001b[0m, in \u001b[0;36mwait_for_read\u001b[1;34m(sock, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_read\u001b[39m(sock: socket\u001b[38;5;241m.\u001b[39msocket, timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Waits for reading to be available on a given socket.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Returns True if the socket is readable, or False if the timeout expired.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwait_for_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\wait.py:53\u001b[0m, in \u001b[0;36mselect_wait_for_socket\u001b[1;34m(sock, read, write, timeout)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# When doing a non-blocking connect, most systems signal success by\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# marking the socket writable. Windows, though, signals success by marked\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# it as \"exceptional\". We paper over the difference by checking the write\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# sockets for both conditions. (The stdlib selectors module does the same\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# thing.)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m fn \u001b[38;5;241m=\u001b[39m partial(select\u001b[38;5;241m.\u001b[39mselect, rcheck, wcheck, wcheck)\n\u001b[1;32m---> 53\u001b[0m rready, wready, xready \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(rready \u001b[38;5;129;01mor\u001b[39;00m wready \u001b[38;5;129;01mor\u001b[39;00m xready)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "driver_jobtopgun = webdriver.Chrome()  \n",
        "jobtopgun_jobs_data = []\n",
        "\n",
        "# Starting page number\n",
        "page_number = 1\n",
        "\n",
        "while True:\n",
        "    # Construct URL with the current page number\n",
        "    url = f'https://www.jobtopgun.com/en/jobs?keywords=data&page={page_number}'\n",
        "    print(f\"Navigating to jobtopgun 'data' search page number: {page_number}\")\n",
        "    \n",
        "    try:\n",
        "        # Navigate to the webpage\n",
        "        driver_jobtopgun.get(url)\n",
        "        wait = WebDriverWait(driver_jobtopgun, 10)\n",
        "        original_window = driver_jobtopgun.current_window_handle  # Hold Current windows\n",
        "\n",
        "        jobtopgun_data_firstpage = []\n",
        "        i = 1  # Start with the first job listing\n",
        "\n",
        "        while True:\n",
        "            xpath = f'//*[@id=\"scrollable-job-cards-container\"]/a[{i}]/div[1]'\n",
        "            try:\n",
        "                # Wait for the element to be clickable\n",
        "                element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
        "                element.click()\n",
        "\n",
        "                # Wait for the new window/tab to open and switch to it\n",
        "                wait.until(EC.number_of_windows_to_be(2))\n",
        "                new_window = [window for window in driver_jobtopgun.window_handles if window != original_window][0]\n",
        "                driver_jobtopgun.switch_to.window(new_window)\n",
        "\n",
        "                # Scrape data from the job detail page\n",
        "                try:\n",
        "                    # Details to scrape data\n",
        "                    job_title = driver_jobtopgun.find_element(By.XPATH, '//h1[@class=\"font-medium text-sub-primary text-lg\"]').text\n",
        "                    company_name = driver_jobtopgun.find_element(By.XPATH, '//span[@class=\"flex-1 font-medium text-lg\"]').text\n",
        "                    industry = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[1]/div/div[1]/div[1]/section/div[1]/span').text\n",
        "                    posted_time = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[1]/div/div[1]/div[1]/section/div/span').text\n",
        "                    experience = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[2]/span').text\n",
        "                    salary = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[2]/span').text\n",
        "                    education = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[4]/span').text\n",
        "                    location = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[5]/span').text\n",
        "                    responsibility = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[2]/div').text\n",
        "                    requirements = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[3]').text\n",
        "                    welfare_and_benefits = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[4]').text\n",
        "                    \n",
        "                    job_info = {\n",
        "                        \"job_title\": job_title,\n",
        "                        \"company_name\": company_name,\n",
        "                        \"industry\": industry,\n",
        "                        \"job_url\": driver_jobtopgun.current_url,\n",
        "                        \"posted_time\": posted_time,\n",
        "                        \"experience\": experience,\n",
        "                        \"salary\": salary,\n",
        "                        \"education\": education,\n",
        "                        \"location\": location,\n",
        "                        \"responsibility\": responsibility,\n",
        "                        \"requirements\": requirements,\n",
        "                        \"welfare_and_benefits\": welfare_and_benefits\n",
        "                    }\n",
        "                    jobtopgun_data_firstpage.append(job_info)\n",
        "                    print(f\"Scraped data for job [{i}]: {job_info}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to scrape data for job [{i}]: {e}\")\n",
        "                \n",
        "                driver_jobtopgun.close()\n",
        "                driver_jobtopgun.switch_to.window(original_window)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to handle element a[{i}]: {e}\")\n",
        "                break  # Exit the loop if element is not found or not clickable\n",
        "\n",
        "            i += 1  # Move to the next job listing\n",
        "\n",
        "        # If no jobs are found, assume there are no more pages to scrape\n",
        "        if not jobtopgun_data_firstpage:\n",
        "            print(f\"No data found on page {page_number}. Stopping.\")\n",
        "            break\n",
        "\n",
        "        # Append the current page's data to the overall data list\n",
        "        jobtopgun_jobs_data.extend(jobtopgun_data_firstpage)\n",
        "\n",
        "        # Increment page number to move to the next page\n",
        "        page_number += 1\n",
        "\n",
        "    except Exception as main_exception:\n",
        "        print(f\"Error while navigating to page {page_number}: {main_exception}\")\n",
        "        break\n",
        "\n",
        "driver_jobtopgun.quit()\n",
        "\n",
        "print(f\"Scraping complete. Total jobs scraped: {len(jobtopgun_jobs_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "ea92ad32",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobtopgun_jobs_data = pd.DataFrame(jobtopgun_jobs_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "317f3e99",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company_name</th>\n",
              "      <th>industry</th>\n",
              "      <th>job_url</th>\n",
              "      <th>posted_time</th>\n",
              "      <th>experience</th>\n",
              "      <th>salary</th>\n",
              "      <th>education</th>\n",
              "      <th>location</th>\n",
              "      <th>responsibility</th>\n",
              "      <th>requirements</th>\n",
              "      <th>welfare_and_benefits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Analysis</td>\n",
              "      <td>PA&amp;CA RECRUITMENT CO.,LTD.</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/246/14334</td>\n",
              "      <td>Today</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>25,000 - 40,000 baht/month</td>\n",
              "      <td>PT24082111\\n\\nType of Business: Trading &amp; ware...</td>\n",
              "      <td>Requirements\\n- Thai Nationality, Male/Female,...</td>\n",
              "      <td>Welfare and Benefits\\nFull Attendane\\nProviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>SGS (Thailand) Limited</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/4387/1555</td>\n",
              "      <td>Today</td>\n",
              "      <td>3 - 5 Year</td>\n",
              "      <td>3 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>• To complete data quality check and manage co...</td>\n",
              "      <td>Requirements\\n• Bachelor’s degree in Science S...</td>\n",
              "      <td>Welfare and Benefits\\nDental insurance\\nGratui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>เจ้าหน้าที่ควบคุมระบบบริหารคุณภาพและข้อมูลอาวุโส</td>\n",
              "      <td>Amnuay Silpa School</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/9956/60</td>\n",
              "      <td>Today</td>\n",
              "      <td>2 - 10 Year</td>\n",
              "      <td>2 - 10 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Depend on qualifications and experience</td>\n",
              "      <td>สนับสนุนในการเตรียมเอกสารที่เกี่ยวข้องกับการตร...</td>\n",
              "      <td>Requirements\\nจบการศึกษาในระดับปริญญาทุกสาขา\\n...</td>\n",
              "      <td>Welfare and Benefits\\nLife insurance\\nMedical ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>K Stone Corporation Co., Ltd.</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/19114/95</td>\n",
              "      <td>Today</td>\n",
              "      <td>3 - 5 Year</td>\n",
              "      <td>3 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Depend on qualifications and experience</td>\n",
              "      <td>Be a strong advocate for a culture of process ...</td>\n",
              "      <td>Requirements\\nStrong experience in Big data de...</td>\n",
              "      <td>Welfare and Benefits\\nStaff training and devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business Analyst/Data Analyst</td>\n",
              "      <td>SPS Medical Co., Ltd</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/20756/27</td>\n",
              "      <td>Today</td>\n",
              "      <td>0 - 5 Year</td>\n",
              "      <td>0 - 5 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>1. ทำงานสัมพันธ์กับทีมงานในองค์กรตลอดจนผู้มีส่...</td>\n",
              "      <td>Requirements\\nคุณสมบัติ\\n- ปริญญาตรีขึ้นไป สาข...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nStaff tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>K Stone Corporation Co., Ltd.</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/19114/92</td>\n",
              "      <td>Today</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Depend on qualifications and experience</td>\n",
              "      <td>Collaborate with various stakeholders to under...</td>\n",
              "      <td>Requirements\\nA Bachelor’s degree in computer ...</td>\n",
              "      <td>Welfare and Benefits\\nStaff training and devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>K Stone Corporation Co., Ltd.</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/19114/93</td>\n",
              "      <td>Today</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Depend on qualifications and experience</td>\n",
              "      <td>Understand requirements and business use cases...</td>\n",
              "      <td>Requirements\\nA bachelor’s degree in computer ...</td>\n",
              "      <td>Welfare and Benefits\\nStaff training and devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Engineer (Insurance Broker)</td>\n",
              "      <td>Ngern Tid Lor Public Company Limited</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/21417/550</td>\n",
              "      <td>Today</td>\n",
              "      <td>3 - 7 Year</td>\n",
              "      <td>3 - 7 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>พัฒนาและปรับปรุงระบบ Coding ให้มีประสิทธภาพโดย...</td>\n",
              "      <td>Requirements\\nจบปริญญาตรีขึ้นไปในสาขา Data Ana...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nStaff tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>บริษัท เริ่มใหม่ จำกัด</td>\n",
              "      <td>Retail/Wholesale</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/248818/51</td>\n",
              "      <td>Retail/Wholesale</td>\n",
              "      <td>1 - 5 Year</td>\n",
              "      <td>1 - 5 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>20,000 - 50,000 baht/month</td>\n",
              "      <td>- รวบรวมและวิเคราะห์ข้อมูล สถิติ คู่แข่ง เพื่อ...</td>\n",
              "      <td>Requirements\\n• ไม่จำกัดเพศ\\n• อายุ 23 - 35 ปี...</td>\n",
              "      <td>Welfare and Benefits\\nStaff training and devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Process Optimization &amp; Data Analyst Lead (Mana...</td>\n",
              "      <td>ECCO (Thailand) Co., Ltd</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/27408/161</td>\n",
              "      <td>Today</td>\n",
              "      <td>5 - 10 Year</td>\n",
              "      <td>5 - 10 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>Job Summary:\\nThe Process Optimization &amp; Data ...</td>\n",
              "      <td>Requirements\\n- Master degree in Engineering/ ...</td>\n",
              "      <td>Welfare and Benefits\\nLong Service Award\\nProv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>IT Senior Data Engineer</td>\n",
              "      <td>Magnecomp Precision Technology Public Company ...</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/19886/878</td>\n",
              "      <td>Today</td>\n",
              "      <td>2 - 4 Year</td>\n",
              "      <td>2 - 4 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>JOB SUMMARY:\\n\\nThe Data Engineer is responsib...</td>\n",
              "      <td>Requirements\\nEducation Required: Bachelor’s d...</td>\n",
              "      <td>Welfare and Benefits\\nAnnual Bonus\\nAnnual Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>IT Associate Data Engineer</td>\n",
              "      <td>Magnecomp Precision Technology Public Company ...</td>\n",
              "      <td>Yesterday</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/19886/879</td>\n",
              "      <td>Yesterday</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>JOB SUMMARY:\\n\\nUnder general supervision, the...</td>\n",
              "      <td>Requirements\\nEducation Required: Bachelor’s d...</td>\n",
              "      <td>Welfare and Benefits\\nAnnual Bonus\\nAnnual Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Engineering Data Officer</td>\n",
              "      <td>ISUZU Technical Center of Asia Co., Ltd.</td>\n",
              "      <td>Automobile &amp; Parts, Machinery</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/1126/115</td>\n",
              "      <td>Automobile &amp; Parts, Machinery</td>\n",
              "      <td>0 - 3 Year</td>\n",
              "      <td>0 - 3 Year</td>\n",
              "      <td>Certificate of Vocational Education or Diploma...</td>\n",
              "      <td>12,000 - 20,000 baht/month</td>\n",
              "      <td>Input and verify engineering data including dr...</td>\n",
              "      <td>Requirements\\nDiploma or equivalent; degree re...</td>\n",
              "      <td>Welfare and Benefits\\nCommuting or Accommodati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Engineer (MES)</td>\n",
              "      <td>TPV Technology (Thailand) Co., Ltd.</td>\n",
              "      <td>Yesterday</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/245793/75</td>\n",
              "      <td>Yesterday</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>20,000 - 30,000 baht/month</td>\n",
              "      <td>1. Training SFIS system to line workers\\n2. SF...</td>\n",
              "      <td>Requirements\\n1. Bachelor's degree in IT, Elec...</td>\n",
              "      <td>Welfare and Benefits\\nStaff training and devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Center Operation-Shift Lead (Samut Prakan)</td>\n",
              "      <td>Gulf Energy Development Public Company Limited</td>\n",
              "      <td>Yesterday</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/17668/946</td>\n",
              "      <td>Yesterday</td>\n",
              "      <td>8 - 9 Year</td>\n",
              "      <td>8 - 9 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>On duty and take responsibility when absence D...</td>\n",
              "      <td>Requirements\\nFamiliar with Microsoft Suite, B...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\n5-day wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>วิศวกรจัดการข้อมูลผลิตภัณฑ์</td>\n",
              "      <td>Rockworth Public Co., Ltd.</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/4153/221</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>0 - 1 Year</td>\n",
              "      <td>0 - 1 Year</td>\n",
              "      <td>Diploma of Vocational Education or higher</td>\n",
              "      <td>18,000 - 25,000 baht/month</td>\n",
              "      <td>1. ปฏิบัติงานให้สอดคล้องกับนโยบายและข้อกำหนด ร...</td>\n",
              "      <td>Requirements\\nเพศหญิง อายุระหว่าง 22-30 ปี\\nวุ...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nStaff tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Data Analyst (Production engineer Division)</td>\n",
              "      <td>Sony Device Technology (Thailand) Co.,Ltd</td>\n",
              "      <td>Electronic</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/28575/193</td>\n",
              "      <td>Electronic</td>\n",
              "      <td>0 - 2 Year</td>\n",
              "      <td>0 - 2 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Depend on qualifications and experience</td>\n",
              "      <td>Job Description:\\nAs a Data Analyst in the Pro...</td>\n",
              "      <td>Requirements\\nBachelor's degree in Computer En...</td>\n",
              "      <td>Welfare and Benefits\\nDiscount for Sony produc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>เจ้าหน้าที่วิเคราะห์ข้อมูล</td>\n",
              "      <td>F - Plus Co., Ltd.</td>\n",
              "      <td>Beverages/Food/Restaurant</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/21518/173</td>\n",
              "      <td>Beverages/Food/Restaurant</td>\n",
              "      <td>2 - 3 Year</td>\n",
              "      <td>2 - 3 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>30,000 - 40,000 baht/month</td>\n",
              "      <td>จัดทำ Template สำหรับการนำเสนอข้อมูลให้เหมาะสม...</td>\n",
              "      <td>Requirements\\nเพศชาย-หญิง อายุ 26-28 ปี \\nวุฒิ...</td>\n",
              "      <td>Welfare and Benefits\\nAccommodation allowance\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A Data Protection Officer (DPO)</td>\n",
              "      <td>Sri Trang Agro-Industry Public Co., Ltd.</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/4084/505</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>Master's Degree</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>1. Ensure Compliance: Monitor and ensure the o...</td>\n",
              "      <td>Requirements\\nBachelor's or Master's degree in...</td>\n",
              "      <td>Welfare and Benefits\\nMedical insurance\\nProvi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Data Governance and Data Analytic Specialist</td>\n",
              "      <td>Isuzu Motors (Thailand) Co.,Ltd.</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/1309/274</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>10 - 20 Year</td>\n",
              "      <td>10 - 20 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>Key Responsibilities\\n• Management and promote...</td>\n",
              "      <td>Requirements\\nProfile &amp; Qualifications Require...</td>\n",
              "      <td>Welfare and Benefits\\nAnnual leave maximum 14 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data analysis officer</td>\n",
              "      <td>Isuzu Motors (Thailand) Co.,Ltd.</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/1309/273</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>0 - 3 Year</td>\n",
              "      <td>0 - 3 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>Key Responsibilities\\n• Data analysis\\n- Analy...</td>\n",
              "      <td>Requirements\\nProfile &amp; Qualifications Require...</td>\n",
              "      <td>Welfare and Benefits\\nAnnual leave maximum 14 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>เจ้าหน้าที่ Data Support / Data Mining</td>\n",
              "      <td>Advice IT Infinite PCL</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/20196/92</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>1 Year</td>\n",
              "      <td>1 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>18,000 - 20,000 baht/month + Commission</td>\n",
              "      <td>- Maintenance ดูแลฐานข้อมูล\\n- Validate ตรวจสอ...</td>\n",
              "      <td>Requirements\\n- ไม่จำกัดเพศ อายุ 22-30 ปี\\n- ว...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nStaff tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>Advice IT Infinite PCL</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/20196/94</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>1 - 3 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>18,000 - 20,000 baht/month + Commission</td>\n",
              "      <td>- ออกแบบ สร้าง ดูแลระบบการจัดเก็บข้อมูล การประ...</td>\n",
              "      <td>Requirements\\n- ไม่จำกัดเพศ อายุ 23 - 30 ปี\\n-...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nStaff tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Ngern Tid Lor Public Company Limited</td>\n",
              "      <td>Financial/Banking/Securities, I.T. - Software/...</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/21417/587</td>\n",
              "      <td>Financial/Banking/Securities, I.T. - Software/...</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>2 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>Develop and implement databases, data analytic...</td>\n",
              "      <td>Requirements\\nStrong in analytical and interpe...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nStaff tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>Kiatnakin Phatra Financial Group</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/5440/391</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>1 - 5 Year</td>\n",
              "      <td>1 - 5 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>Role and Responsibilities \\n· Create and maint...</td>\n",
              "      <td>Requirements\\nQualifications \\n· 5 years of ex...</td>\n",
              "      <td>Welfare and Benefits\\nBirthday Leave\\nDental i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>เจ้าหน้าที่อาวุโสวิเคราะห์ข้อมูล</td>\n",
              "      <td>Thailand Privilege Card Co., Ltd.</td>\n",
              "      <td>Travel</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/22999/137</td>\n",
              "      <td>Travel</td>\n",
              "      <td>1 - 8 Year</td>\n",
              "      <td>1 - 8 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>30,000 - 80,000 baht/month</td>\n",
              "      <td>1. จัดทำรายงานสรุปข้อมูลด้านการลงทุนรายเดือน ร...</td>\n",
              "      <td>Requirements\\n• ได้รับปริญญาตรีหรือคุณวุฒิอย่า...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\n5-day wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>เจ้าหน้าที่วิเคราะห์ข้อมูล</td>\n",
              "      <td>Better World Green Public Co.,Ltd</td>\n",
              "      <td>Business Service</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/20134/89</td>\n",
              "      <td>Business Service</td>\n",
              "      <td>0 - 3 Year</td>\n",
              "      <td>0 - 3 Year</td>\n",
              "      <td>Bachelor's Degree or Higher</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>1.รวบรวมข้อมูลการดำเนินงานขนส่งต่างๆที่ได้รับม...</td>\n",
              "      <td>Requirements\\n- เพศหญิง อายุ 22-35 ปี\\n- วุฒิก...</td>\n",
              "      <td>Welfare and Benefits\\nProvident Fund\\nกองทุนเง...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>พนักงานตรวจสอบข้อมูล (ภาษาญี่ปุ่น)</td>\n",
              "      <td>Masterpiece group (Thailand) Co.,Ltd.</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/255019/12</td>\n",
              "      <td>04/09/2024</td>\n",
              "      <td>0 - 2 Year</td>\n",
              "      <td>0 - 2 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>18,000 - 25,000 baht/month</td>\n",
              "      <td>①　Data Check (Japanese)\\nเนื้อหางาน ：本人確認：ตรวจ...</td>\n",
              "      <td>Requirements\\n1. JLPT N3~\\n2. สามารถเข้าใจ วิเ...</td>\n",
              "      <td>Welfare and Benefits\\nOvertime\\nFuel/transport...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Data Management</td>\n",
              "      <td>Thai Smile Bus Co.,Ltd.</td>\n",
              "      <td>Transportation/Logistic</td>\n",
              "      <td>https://www.jobtopgun.com/en/job/252263/16</td>\n",
              "      <td>Transportation/Logistic</td>\n",
              "      <td>0 - 5 Year</td>\n",
              "      <td>0 - 5 Year</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Negotiable</td>\n",
              "      <td>ทำหน้าที่ออกแบบระบบ Database ให้เหมาะสมกับการใ...</td>\n",
              "      <td>Requirements\\nอายุไม่เกิน 30 ปี\\nระดับการศึกษา...</td>\n",
              "      <td>Welfare and Benefits\\nชุดยูนิฟอร์ม\\n5-day work...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            job_title  \\\n",
              "0                                       Data Analysis   \n",
              "1                                        Data Analyst   \n",
              "2    เจ้าหน้าที่ควบคุมระบบบริหารคุณภาพและข้อมูลอาวุโส   \n",
              "3                                       Data Engineer   \n",
              "4                       Business Analyst/Data Analyst   \n",
              "5                                      Data Scientist   \n",
              "6                                        Data Analyst   \n",
              "7                    Data Engineer (Insurance Broker)   \n",
              "8                                        Data Analyst   \n",
              "9   Process Optimization & Data Analyst Lead (Mana...   \n",
              "10                            IT Senior Data Engineer   \n",
              "11                         IT Associate Data Engineer   \n",
              "12                           Engineering Data Officer   \n",
              "13                                Data Engineer (MES)   \n",
              "14    Data Center Operation-Shift Lead (Samut Prakan)   \n",
              "15                        วิศวกรจัดการข้อมูลผลิตภัณฑ์   \n",
              "16        Data Analyst (Production engineer Division)   \n",
              "17                         เจ้าหน้าที่วิเคราะห์ข้อมูล   \n",
              "18                    A Data Protection Officer (DPO)   \n",
              "19       Data Governance and Data Analytic Specialist   \n",
              "20                              Data analysis officer   \n",
              "21             เจ้าหน้าที่ Data Support / Data Mining   \n",
              "22                                      Data Engineer   \n",
              "23                                       Data Analyst   \n",
              "24                                      Data Engineer   \n",
              "25                   เจ้าหน้าที่อาวุโสวิเคราะห์ข้อมูล   \n",
              "26                         เจ้าหน้าที่วิเคราะห์ข้อมูล   \n",
              "27                 พนักงานตรวจสอบข้อมูล (ภาษาญี่ปุ่น)   \n",
              "28                                    Data Management   \n",
              "\n",
              "                                         company_name  \\\n",
              "0                          PA&CA RECRUITMENT CO.,LTD.   \n",
              "1                              SGS (Thailand) Limited   \n",
              "2                                 Amnuay Silpa School   \n",
              "3                       K Stone Corporation Co., Ltd.   \n",
              "4                                SPS Medical Co., Ltd   \n",
              "5                       K Stone Corporation Co., Ltd.   \n",
              "6                       K Stone Corporation Co., Ltd.   \n",
              "7                Ngern Tid Lor Public Company Limited   \n",
              "8                              บริษัท เริ่มใหม่ จำกัด   \n",
              "9                            ECCO (Thailand) Co., Ltd   \n",
              "10  Magnecomp Precision Technology Public Company ...   \n",
              "11  Magnecomp Precision Technology Public Company ...   \n",
              "12           ISUZU Technical Center of Asia Co., Ltd.   \n",
              "13                TPV Technology (Thailand) Co., Ltd.   \n",
              "14     Gulf Energy Development Public Company Limited   \n",
              "15                         Rockworth Public Co., Ltd.   \n",
              "16          Sony Device Technology (Thailand) Co.,Ltd   \n",
              "17                                 F - Plus Co., Ltd.   \n",
              "18           Sri Trang Agro-Industry Public Co., Ltd.   \n",
              "19                   Isuzu Motors (Thailand) Co.,Ltd.   \n",
              "20                   Isuzu Motors (Thailand) Co.,Ltd.   \n",
              "21                             Advice IT Infinite PCL   \n",
              "22                             Advice IT Infinite PCL   \n",
              "23               Ngern Tid Lor Public Company Limited   \n",
              "24                   Kiatnakin Phatra Financial Group   \n",
              "25                  Thailand Privilege Card Co., Ltd.   \n",
              "26                  Better World Green Public Co.,Ltd   \n",
              "27              Masterpiece group (Thailand) Co.,Ltd.   \n",
              "28                            Thai Smile Bus Co.,Ltd.   \n",
              "\n",
              "                                             industry  \\\n",
              "0                                               Today   \n",
              "1                                               Today   \n",
              "2                                               Today   \n",
              "3                                               Today   \n",
              "4                                               Today   \n",
              "5                                               Today   \n",
              "6                                               Today   \n",
              "7                                               Today   \n",
              "8                                    Retail/Wholesale   \n",
              "9                                               Today   \n",
              "10                                              Today   \n",
              "11                                          Yesterday   \n",
              "12                      Automobile & Parts, Machinery   \n",
              "13                                          Yesterday   \n",
              "14                                          Yesterday   \n",
              "15                                          Furniture   \n",
              "16                                         Electronic   \n",
              "17                          Beverages/Food/Restaurant   \n",
              "18                                         04/09/2024   \n",
              "19                                         04/09/2024   \n",
              "20                                         04/09/2024   \n",
              "21                                         04/09/2024   \n",
              "22                                         04/09/2024   \n",
              "23  Financial/Banking/Securities, I.T. - Software/...   \n",
              "24                                         04/09/2024   \n",
              "25                                             Travel   \n",
              "26                                   Business Service   \n",
              "27                                         04/09/2024   \n",
              "28                            Transportation/Logistic   \n",
              "\n",
              "                                       job_url  \\\n",
              "0   https://www.jobtopgun.com/en/job/246/14334   \n",
              "1   https://www.jobtopgun.com/en/job/4387/1555   \n",
              "2     https://www.jobtopgun.com/en/job/9956/60   \n",
              "3    https://www.jobtopgun.com/en/job/19114/95   \n",
              "4    https://www.jobtopgun.com/en/job/20756/27   \n",
              "5    https://www.jobtopgun.com/en/job/19114/92   \n",
              "6    https://www.jobtopgun.com/en/job/19114/93   \n",
              "7   https://www.jobtopgun.com/en/job/21417/550   \n",
              "8   https://www.jobtopgun.com/en/job/248818/51   \n",
              "9   https://www.jobtopgun.com/en/job/27408/161   \n",
              "10  https://www.jobtopgun.com/en/job/19886/878   \n",
              "11  https://www.jobtopgun.com/en/job/19886/879   \n",
              "12   https://www.jobtopgun.com/en/job/1126/115   \n",
              "13  https://www.jobtopgun.com/en/job/245793/75   \n",
              "14  https://www.jobtopgun.com/en/job/17668/946   \n",
              "15   https://www.jobtopgun.com/en/job/4153/221   \n",
              "16  https://www.jobtopgun.com/en/job/28575/193   \n",
              "17  https://www.jobtopgun.com/en/job/21518/173   \n",
              "18   https://www.jobtopgun.com/en/job/4084/505   \n",
              "19   https://www.jobtopgun.com/en/job/1309/274   \n",
              "20   https://www.jobtopgun.com/en/job/1309/273   \n",
              "21   https://www.jobtopgun.com/en/job/20196/92   \n",
              "22   https://www.jobtopgun.com/en/job/20196/94   \n",
              "23  https://www.jobtopgun.com/en/job/21417/587   \n",
              "24   https://www.jobtopgun.com/en/job/5440/391   \n",
              "25  https://www.jobtopgun.com/en/job/22999/137   \n",
              "26   https://www.jobtopgun.com/en/job/20134/89   \n",
              "27  https://www.jobtopgun.com/en/job/255019/12   \n",
              "28  https://www.jobtopgun.com/en/job/252263/16   \n",
              "\n",
              "                                          posted_time    experience  \\\n",
              "0                                               Today    2 - 5 Year   \n",
              "1                                               Today    3 - 5 Year   \n",
              "2                                               Today   2 - 10 Year   \n",
              "3                                               Today    3 - 5 Year   \n",
              "4                                               Today    0 - 5 Year   \n",
              "5                                               Today    2 - 5 Year   \n",
              "6                                               Today    2 - 5 Year   \n",
              "7                                               Today    3 - 7 Year   \n",
              "8                                    Retail/Wholesale    1 - 5 Year   \n",
              "9                                               Today   5 - 10 Year   \n",
              "10                                              Today    2 - 4 Year   \n",
              "11                                          Yesterday    1 - 3 Year   \n",
              "12                      Automobile & Parts, Machinery    0 - 3 Year   \n",
              "13                                          Yesterday    1 - 3 Year   \n",
              "14                                          Yesterday    8 - 9 Year   \n",
              "15                                          Furniture    0 - 1 Year   \n",
              "16                                         Electronic    0 - 2 Year   \n",
              "17                          Beverages/Food/Restaurant    2 - 3 Year   \n",
              "18                                         04/09/2024    1 - 3 Year   \n",
              "19                                         04/09/2024  10 - 20 Year   \n",
              "20                                         04/09/2024    0 - 3 Year   \n",
              "21                                         04/09/2024        1 Year   \n",
              "22                                         04/09/2024    1 - 3 Year   \n",
              "23  Financial/Banking/Securities, I.T. - Software/...    2 - 5 Year   \n",
              "24                                         04/09/2024    1 - 5 Year   \n",
              "25                                             Travel    1 - 8 Year   \n",
              "26                                   Business Service    0 - 3 Year   \n",
              "27                                         04/09/2024    0 - 2 Year   \n",
              "28                            Transportation/Logistic    0 - 5 Year   \n",
              "\n",
              "          salary                                          education  \\\n",
              "0     2 - 5 Year                        Bachelor's Degree or Higher   \n",
              "1     3 - 5 Year                        Bachelor's Degree or Higher   \n",
              "2    2 - 10 Year                        Bachelor's Degree or Higher   \n",
              "3     3 - 5 Year                        Bachelor's Degree or Higher   \n",
              "4     0 - 5 Year                                  Bachelor's Degree   \n",
              "5     2 - 5 Year                        Bachelor's Degree or Higher   \n",
              "6     2 - 5 Year                        Bachelor's Degree or Higher   \n",
              "7     3 - 7 Year                        Bachelor's Degree or Higher   \n",
              "8     1 - 5 Year                                  Bachelor's Degree   \n",
              "9    5 - 10 Year                        Bachelor's Degree or Higher   \n",
              "10    2 - 4 Year                                  Bachelor's Degree   \n",
              "11    1 - 3 Year                                  Bachelor's Degree   \n",
              "12    0 - 3 Year  Certificate of Vocational Education or Diploma...   \n",
              "13    1 - 3 Year                        Bachelor's Degree or Higher   \n",
              "14    8 - 9 Year                        Bachelor's Degree or Higher   \n",
              "15    0 - 1 Year          Diploma of Vocational Education or higher   \n",
              "16    0 - 2 Year                                  Bachelor's Degree   \n",
              "17    2 - 3 Year                        Bachelor's Degree or Higher   \n",
              "18    1 - 3 Year                                    Master's Degree   \n",
              "19  10 - 20 Year                        Bachelor's Degree or Higher   \n",
              "20    0 - 3 Year                                  Bachelor's Degree   \n",
              "21        1 Year                                  Bachelor's Degree   \n",
              "22    1 - 3 Year                                  Bachelor's Degree   \n",
              "23    2 - 5 Year                        Bachelor's Degree or Higher   \n",
              "24    1 - 5 Year                        Bachelor's Degree or Higher   \n",
              "25    1 - 8 Year                        Bachelor's Degree or Higher   \n",
              "26    0 - 3 Year                        Bachelor's Degree or Higher   \n",
              "27    0 - 2 Year                                  Bachelor's Degree   \n",
              "28    0 - 5 Year                                  Bachelor's Degree   \n",
              "\n",
              "                                   location  \\\n",
              "0                25,000 - 40,000 baht/month   \n",
              "1                                Negotiable   \n",
              "2   Depend on qualifications and experience   \n",
              "3   Depend on qualifications and experience   \n",
              "4                                Negotiable   \n",
              "5   Depend on qualifications and experience   \n",
              "6   Depend on qualifications and experience   \n",
              "7                                Negotiable   \n",
              "8                20,000 - 50,000 baht/month   \n",
              "9                                Negotiable   \n",
              "10                               Negotiable   \n",
              "11                               Negotiable   \n",
              "12               12,000 - 20,000 baht/month   \n",
              "13               20,000 - 30,000 baht/month   \n",
              "14                               Negotiable   \n",
              "15               18,000 - 25,000 baht/month   \n",
              "16  Depend on qualifications and experience   \n",
              "17               30,000 - 40,000 baht/month   \n",
              "18                               Negotiable   \n",
              "19                               Negotiable   \n",
              "20                               Negotiable   \n",
              "21  18,000 - 20,000 baht/month + Commission   \n",
              "22  18,000 - 20,000 baht/month + Commission   \n",
              "23                               Negotiable   \n",
              "24                               Negotiable   \n",
              "25               30,000 - 80,000 baht/month   \n",
              "26                               Negotiable   \n",
              "27               18,000 - 25,000 baht/month   \n",
              "28                               Negotiable   \n",
              "\n",
              "                                       responsibility  \\\n",
              "0   PT24082111\\n\\nType of Business: Trading & ware...   \n",
              "1   • To complete data quality check and manage co...   \n",
              "2   สนับสนุนในการเตรียมเอกสารที่เกี่ยวข้องกับการตร...   \n",
              "3   Be a strong advocate for a culture of process ...   \n",
              "4   1. ทำงานสัมพันธ์กับทีมงานในองค์กรตลอดจนผู้มีส่...   \n",
              "5   Collaborate with various stakeholders to under...   \n",
              "6   Understand requirements and business use cases...   \n",
              "7   พัฒนาและปรับปรุงระบบ Coding ให้มีประสิทธภาพโดย...   \n",
              "8   - รวบรวมและวิเคราะห์ข้อมูล สถิติ คู่แข่ง เพื่อ...   \n",
              "9   Job Summary:\\nThe Process Optimization & Data ...   \n",
              "10  JOB SUMMARY:\\n\\nThe Data Engineer is responsib...   \n",
              "11  JOB SUMMARY:\\n\\nUnder general supervision, the...   \n",
              "12  Input and verify engineering data including dr...   \n",
              "13  1. Training SFIS system to line workers\\n2. SF...   \n",
              "14  On duty and take responsibility when absence D...   \n",
              "15  1. ปฏิบัติงานให้สอดคล้องกับนโยบายและข้อกำหนด ร...   \n",
              "16  Job Description:\\nAs a Data Analyst in the Pro...   \n",
              "17  จัดทำ Template สำหรับการนำเสนอข้อมูลให้เหมาะสม...   \n",
              "18  1. Ensure Compliance: Monitor and ensure the o...   \n",
              "19  Key Responsibilities\\n• Management and promote...   \n",
              "20  Key Responsibilities\\n• Data analysis\\n- Analy...   \n",
              "21  - Maintenance ดูแลฐานข้อมูล\\n- Validate ตรวจสอ...   \n",
              "22  - ออกแบบ สร้าง ดูแลระบบการจัดเก็บข้อมูล การประ...   \n",
              "23  Develop and implement databases, data analytic...   \n",
              "24  Role and Responsibilities \\n· Create and maint...   \n",
              "25  1. จัดทำรายงานสรุปข้อมูลด้านการลงทุนรายเดือน ร...   \n",
              "26  1.รวบรวมข้อมูลการดำเนินงานขนส่งต่างๆที่ได้รับม...   \n",
              "27  ①　Data Check (Japanese)\\nเนื้อหางาน ：本人確認：ตรวจ...   \n",
              "28  ทำหน้าที่ออกแบบระบบ Database ให้เหมาะสมกับการใ...   \n",
              "\n",
              "                                         requirements  \\\n",
              "0   Requirements\\n- Thai Nationality, Male/Female,...   \n",
              "1   Requirements\\n• Bachelor’s degree in Science S...   \n",
              "2   Requirements\\nจบการศึกษาในระดับปริญญาทุกสาขา\\n...   \n",
              "3   Requirements\\nStrong experience in Big data de...   \n",
              "4   Requirements\\nคุณสมบัติ\\n- ปริญญาตรีขึ้นไป สาข...   \n",
              "5   Requirements\\nA Bachelor’s degree in computer ...   \n",
              "6   Requirements\\nA bachelor’s degree in computer ...   \n",
              "7   Requirements\\nจบปริญญาตรีขึ้นไปในสาขา Data Ana...   \n",
              "8   Requirements\\n• ไม่จำกัดเพศ\\n• อายุ 23 - 35 ปี...   \n",
              "9   Requirements\\n- Master degree in Engineering/ ...   \n",
              "10  Requirements\\nEducation Required: Bachelor’s d...   \n",
              "11  Requirements\\nEducation Required: Bachelor’s d...   \n",
              "12  Requirements\\nDiploma or equivalent; degree re...   \n",
              "13  Requirements\\n1. Bachelor's degree in IT, Elec...   \n",
              "14  Requirements\\nFamiliar with Microsoft Suite, B...   \n",
              "15  Requirements\\nเพศหญิง อายุระหว่าง 22-30 ปี\\nวุ...   \n",
              "16  Requirements\\nBachelor's degree in Computer En...   \n",
              "17  Requirements\\nเพศชาย-หญิง อายุ 26-28 ปี \\nวุฒิ...   \n",
              "18  Requirements\\nBachelor's or Master's degree in...   \n",
              "19  Requirements\\nProfile & Qualifications Require...   \n",
              "20  Requirements\\nProfile & Qualifications Require...   \n",
              "21  Requirements\\n- ไม่จำกัดเพศ อายุ 22-30 ปี\\n- ว...   \n",
              "22  Requirements\\n- ไม่จำกัดเพศ อายุ 23 - 30 ปี\\n-...   \n",
              "23  Requirements\\nStrong in analytical and interpe...   \n",
              "24  Requirements\\nQualifications \\n· 5 years of ex...   \n",
              "25  Requirements\\n• ได้รับปริญญาตรีหรือคุณวุฒิอย่า...   \n",
              "26  Requirements\\n- เพศหญิง อายุ 22-35 ปี\\n- วุฒิก...   \n",
              "27  Requirements\\n1. JLPT N3~\\n2. สามารถเข้าใจ วิเ...   \n",
              "28  Requirements\\nอายุไม่เกิน 30 ปี\\nระดับการศึกษา...   \n",
              "\n",
              "                                 welfare_and_benefits  \n",
              "0   Welfare and Benefits\\nFull Attendane\\nProviden...  \n",
              "1   Welfare and Benefits\\nDental insurance\\nGratui...  \n",
              "2   Welfare and Benefits\\nLife insurance\\nMedical ...  \n",
              "3   Welfare and Benefits\\nStaff training and devel...  \n",
              "4   Welfare and Benefits\\nProvident Fund\\nStaff tr...  \n",
              "5   Welfare and Benefits\\nStaff training and devel...  \n",
              "6   Welfare and Benefits\\nStaff training and devel...  \n",
              "7   Welfare and Benefits\\nProvident Fund\\nStaff tr...  \n",
              "8   Welfare and Benefits\\nStaff training and devel...  \n",
              "9   Welfare and Benefits\\nLong Service Award\\nProv...  \n",
              "10  Welfare and Benefits\\nAnnual Bonus\\nAnnual Per...  \n",
              "11  Welfare and Benefits\\nAnnual Bonus\\nAnnual Per...  \n",
              "12  Welfare and Benefits\\nCommuting or Accommodati...  \n",
              "13  Welfare and Benefits\\nStaff training and devel...  \n",
              "14  Welfare and Benefits\\nProvident Fund\\n5-day wo...  \n",
              "15  Welfare and Benefits\\nProvident Fund\\nStaff tr...  \n",
              "16  Welfare and Benefits\\nDiscount for Sony produc...  \n",
              "17  Welfare and Benefits\\nAccommodation allowance\\...  \n",
              "18  Welfare and Benefits\\nMedical insurance\\nProvi...  \n",
              "19  Welfare and Benefits\\nAnnual leave maximum 14 ...  \n",
              "20  Welfare and Benefits\\nAnnual leave maximum 14 ...  \n",
              "21  Welfare and Benefits\\nProvident Fund\\nStaff tr...  \n",
              "22  Welfare and Benefits\\nProvident Fund\\nStaff tr...  \n",
              "23  Welfare and Benefits\\nProvident Fund\\nStaff tr...  \n",
              "24  Welfare and Benefits\\nBirthday Leave\\nDental i...  \n",
              "25  Welfare and Benefits\\nProvident Fund\\n5-day wo...  \n",
              "26  Welfare and Benefits\\nProvident Fund\\nกองทุนเง...  \n",
              "27  Welfare and Benefits\\nOvertime\\nFuel/transport...  \n",
              "28  Welfare and Benefits\\nชุดยูนิฟอร์ม\\n5-day work...  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jobtopgun_jobs_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b749b78a",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d8b31e54",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e9dce255",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "756e5c95",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "53f2978a",
      "metadata": {},
      "source": [
        "## Job Bkk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "562bee2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "search_word = 'data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "beb6d21b",
      "metadata": {},
      "outputs": [],
      "source": [
        "driver_jobbkk = webdriver.Chrome()  \n",
        "jobbkk_jobs_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "81281287",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'job_title': 'Data Engineer รับสมัครด่วน', 'company_name': 'บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด', 'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที', 'salary': 'เงินเดือน(บาท) : 25,000 - 40,000', 'fulltime': 'รูปแบบงาน : งานประจำ', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)', 'workday': 'วันทำงาน : จันทร์-ศุกร์', 'dayoff': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'workhour': 'เวลาทำงาน : 09:00 - 18:00', 'responsibility': 'รับผิดชอบงาน Data Integration, Data Pipeline Management\\nออกแบบ Data Architecture ติดตั้ง Big Data Platform และเครื่องมือที่เกี่ยวข้อง\\nออกแบบโครงสร้างการจัดเก็บและแนวทางการจัดเก็บข้อมูลบน Data Platform\\nศึกษาและค้นคว้าเทคโนโลยีที่เหมาะสมเพื่อพัฒนาสินค้าของเราให้มีคุณภาพที่ดีขึ้น และพัฒนาผลิตภัณฑ์ให้เป็นไปตามเป้าหมายของบริษัท', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 26 - 35', 'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป', 'experience': 'ประสบการณ์(ปี) : 3 - 5', 'job_requirement': 'มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\nเชี่ยวชาญ SQL, NoSQL และเขียน Python ได้\\nหากเคยมีประสบการณ์เหล่านี้จะพิจารณาพิเศษ ได้แก่ ETL Tools, Airflow, NiFi, Streaming Real Time Data, Kafka\\nใช้ Linux Command, Linux Container ได้\\nหากมีประสบการณ์ติดตั้งหรือใช้งาน Hadoop, Hive, MongoDB, Kafka, Elasticsearch อย่างใดอย่างหนึ่งจะพิจารณาเป็นพิเศษ\\nชอบเรียนรู้ และเรียนรู้ทักษะใหม่ๆได้เร็ว ชอบศึกษา และแบ่งปันความรู้\\nมีทัศนคติในการทำงานในองค์กรที่ดี รักในงานที่ทำ มีวินัย และความรับผิดชอบสูง', 'job_requirement2': 'ยินดีรับนักศึกษาจบใหม่', 'welfare_and_benefits': 'ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภาพ\\nเงินโบนัสตามผลงาน\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits2': 'สวัสดิการ\\n- Birthday Party\\n- วันหยุดพักผ่อน 10 วัน*\\n- ลากิจ\\n- ฝึกอบรม\\n- ท่องเที่ยวประจำปี\\n- ตรวจสุขภาพ\\n- กองทุนสำรองเลี้ยงชีพ*\\n- Incentive ตามผลงาน, ตามเงื่อนไขบริษัทฯ\\n- เงินช่วยเหลือต่างๆ ตามเงื่อนไขบริษัทฯ', 'company_contact': 'ชื่อผู้ติดต่อ : ศิวกรณ์ โนรันต์\\nเบอร์ผู้ติดต่อ : 022454942\\nอีเมล : siwakorn@softnix.co.th', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/180396/1270026'}\n",
            "Done scraping\n"
          ]
        }
      ],
      "source": [
        "# WebDriver\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "wait = WebDriverWait(driver_jobbkk, 10)  \n",
        "\n",
        "try:\n",
        "    # Open the main URL\n",
        "    driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "\n",
        "    # Click the element to open a new tab\n",
        "    element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/section[7]/article/section/div[1]/div[6]/div/div[3]/div/ul/li[3]/a')))\n",
        "    driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "    # Switch to the new tab\n",
        "    WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "    original_window = driver_jobbkk.current_window_handle\n",
        "    new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "    driver_jobbkk.switch_to.window(new_window)\n",
        "    \n",
        "    # Get page source and parse it with BeautifulSoup\n",
        "    page_source = driver_jobbkk.page_source\n",
        "    soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "    # Scrape data from the new tab\n",
        "    try:\n",
        "        job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "        company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text\n",
        "        industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "        salary = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[7]').text\n",
        "        fulltime = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[4]').text\n",
        "        location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "        work_day = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[8]').text\n",
        "        dayoff = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[9]').text\n",
        "        workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "        responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "        gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "        age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "        education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "        experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "        job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "        job_requirement2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[7]/div').text\n",
        "        welfare_and_benefits = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[8]/div').text\n",
        "        welfare_and_benefits2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[9]/div').text\n",
        "        company_contact = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[10]/div').text\n",
        "        job_url = driver_jobbkk.current_url\n",
        "        \n",
        "        jobbkk_info = {\n",
        "            'job_title': job_title,\n",
        "            'company_name': company_name,\n",
        "            'industry': industry,\n",
        "            'salary': salary,\n",
        "            'fulltime': fulltime,\n",
        "            'location': location,\n",
        "            'workday': work_day,\n",
        "            'dayoff': dayoff,\n",
        "            'workhour': workhour,\n",
        "            'responsibility': responsibility,\n",
        "            'gender': gender,\n",
        "            'age': age,\n",
        "            'education': education,\n",
        "            'experience': experience,\n",
        "            'job_requirement': job_requirement,\n",
        "            'job_requirement2': job_requirement2,\n",
        "            'welfare_and_benefits': welfare_and_benefits,\n",
        "            'welfare_and_benefits2': welfare_and_benefits2,\n",
        "            'company_contact': company_contact,\n",
        "            'job_url': job_url\n",
        "        }\n",
        "        print(jobbkk_info)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping data: {e}\")\n",
        "\n",
        "    # Close the new tab and switch back \n",
        "    driver_jobbkk.close()\n",
        "    driver_jobbkk.switch_to.window(original_window)\n",
        "\n",
        "finally:\n",
        "    print('Done scraping')\n",
        "    driver_jobbkk.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "3d7a01bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done scraping\n"
          ]
        }
      ],
      "source": [
        "# Scrape mainpage\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "wait = WebDriverWait(driver_jobbkk, 10)  # Adjust the timeout as needed\n",
        "\n",
        "try:\n",
        "    # Open the main URL\n",
        "    driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "        \n",
        "    # Get the page source\n",
        "    page_source = driver_jobbkk.page_source\n",
        "    soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "    # Scrape multiple elements from the main page\n",
        "    try:\n",
        "        # Example of scraping multiple elements\n",
        "        posted_times = soup_bkk.find_all('a', class_='hover-work')\n",
        "        salaries = soup_bkk.find_all('div', class_='col-md-12 col-sm-12 col-xs-12 list-company-salary')\n",
        "        \n",
        "        # Extract text for each found element\n",
        "        posted_times_text = [pt.text.strip() for pt in posted_times]\n",
        "        salaries_text = [s.text.strip() for s in salaries]\n",
        "\n",
        "        # Dataframe\n",
        "        first_page_data = pd.DataFrame({\n",
        "                'salary': salaries_text,\n",
        "                'posted_time': posted_times_text[1::3],\n",
        "                            })\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping data: {e}\")\n",
        "\n",
        "finally:\n",
        "    print('Done scraping')\n",
        "    driver_jobbkk.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "9b0ae339",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>salary</th>\n",
              "      <th>posted_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>เงินเดือน(บาท) : 25,000 - 40,000\\nกรุงเทพมหานค...</td>\n",
              "      <td>1 วันที่แล้ว</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>เงินเดือน(บาท) : 30,000 - 59,000\\nกรุงเทพมหานค...</td>\n",
              "      <td>2 วันที่แล้ว</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>เงินเดือน(บาท) : ตามตกลง\\nกรุงเทพมหานคร ทุกเขต</td>\n",
              "      <td>2 วันที่แล้ว</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              salary   posted_time\n",
              "0  เงินเดือน(บาท) : 25,000 - 40,000\\nกรุงเทพมหานค...  1 วันที่แล้ว\n",
              "1  เงินเดือน(บาท) : 30,000 - 59,000\\nกรุงเทพมหานค...  2 วันที่แล้ว\n",
              "2     เงินเดือน(บาท) : ตามตกลง\\nกรุงเทพมหานคร ทุกเขต  2 วันที่แล้ว"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_page_data = pd.DataFrame({\n",
        "                'salary': salaries_text,\n",
        "                'posted_time': posted_times_text[1::3],\n",
        "                            })\n",
        "first_page_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "5da782ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "/html/body/section[7]/article/section/div[1]/div[18]/div"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc1c5a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "/html/body/section[7]/article/section/div[1]/div[20]/div"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ec9a3507",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully scrape Section 1 job [1]\n",
            "Successfully scrape Section 1 job [2]\n",
            "Successfully scrape Section 1 job [3]\n",
            "Successfully scrape Section 1 job [4]\n",
            "Successfully scrape Section 1 job [5]\n",
            "Successfully scrape Section 1 job [6]\n",
            "Error scraping data: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p\"}\n",
            "  (Session info: chrome=128.0.6613.115); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655FBEFD7]\n",
            "\t(No symbol) [0x00007FF655FBF22C]\n",
            "\t(No symbol) [0x00007FF6560097F7]\n",
            "\t(No symbol) [0x00007FF655FE672F]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Successfully scrape Section 1 job [7]\n",
            "Successfully scrape Section 2 job [9]\n",
            "Successfully scrape Section 2 job [10]\n",
            "Successfully scrape Section 2 job [11]\n",
            "Successfully scrape Section 2 job [12]\n",
            "Successfully scrape Section 2 job [13]\n",
            "Successfully scrape Section 2 job [14]\n",
            "Successfully scrape Section 2 job [15]\n",
            "Error scraping data: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p\"}\n",
            "  (Session info: chrome=128.0.6613.115); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655FBEFD7]\n",
            "\t(No symbol) [0x00007FF655FBF22C]\n",
            "\t(No symbol) [0x00007FF6560097F7]\n",
            "\t(No symbol) [0x00007FF655FE672F]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Successfully scrape Section 3 job [16]\n",
            "Successfully scrape Section 3 job [17]\n",
            "Error scraping data: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p\"}\n",
            "  (Session info: chrome=128.0.6613.115); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655FBEFD7]\n",
            "\t(No symbol) [0x00007FF655FBF22C]\n",
            "\t(No symbol) [0x00007FF6560097F7]\n",
            "\t(No symbol) [0x00007FF655FE672F]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Error scraping data: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p\"}\n",
            "  (Session info: chrome=128.0.6613.115); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655FBEFD7]\n",
            "\t(No symbol) [0x00007FF655FBF22C]\n",
            "\t(No symbol) [0x00007FF6560097F7]\n",
            "\t(No symbol) [0x00007FF655FE672F]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Successfully scrape Section 3 job [18]\n",
            "Successfully scrape Section 3 job [19]\n",
            "Successfully scrape Section 3 job [20]\n",
            "Successfully scrape Section 3 job [21]\n",
            "Successfully scrape Section 3 job [22]\n",
            "Done scraping\n"
          ]
        }
      ],
      "source": [
        "\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "wait = WebDriverWait(driver_jobbkk, 10)  # Adjust the timeout as needed\n",
        "\n",
        "all_jobs = []\n",
        "try:\n",
        "    # Open the main URL\n",
        "    driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "    \n",
        "    page_source = driver_jobbkk.page_source\n",
        "    soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "    # Example of scraping multiple elements\n",
        "    posted_times = soup_bkk.find_all('a', class_='hover-work')\n",
        "    salaries = soup_bkk.find_all('div', class_='col-md-12 col-sm-12 col-xs-12 list-company-salary')\n",
        "        \n",
        "    # Extract text for each found element\n",
        "    posted_times_text = [pt.text.strip() for pt in posted_times]\n",
        "    salaries_text = [s.text.strip() for s in salaries]\n",
        "\n",
        "    # Dataframe\n",
        "    first_page_data = pd.DataFrame({\n",
        "                            'salary': salaries_text,\n",
        "                            'posted_time': posted_times_text[1::3],\n",
        "                                        })\n",
        "    section_1_counter = 1\n",
        "    section_2_counter = 9\n",
        "    section_3_counter = 17\n",
        "    \n",
        "    # Loop through elements starting from index 6, with a step of 2\n",
        "    for x in range(6, 26, 2):# section 1\n",
        "        try:\n",
        "            xpath = f'/html/body/section[7]/article/section/div[1]/div[{x}]/div/div[3]/div/ul/li[3]/a'\n",
        "            element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
        "            driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "            # Switch to the new tab\n",
        "            WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "            original_window = driver_jobbkk.current_window_handle\n",
        "            new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "            driver_jobbkk.switch_to.window(new_window)\n",
        "\n",
        "            page_source = driver_jobbkk.page_source\n",
        "            soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "            \n",
        "            # Scrape data from the new tab\n",
        "            try:\n",
        "                job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "                company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text\n",
        "                industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "                location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "                workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "                responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "                gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "                age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "                education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "                experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "                job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "                job_url = driver_jobbkk.current_url\n",
        "                \n",
        "                jobbkk_info = {\n",
        "                    'job_title': job_title,\n",
        "                    'company_name': company_name,\n",
        "                    'industry': industry,'location': location,\n",
        "                    'workhour': workhour,\n",
        "                    'responsibility': responsibility,\n",
        "                    'gender': gender,\n",
        "                    'age': age,\n",
        "                    'education': education,\n",
        "                    'experience': experience,\n",
        "                    'job_requirement': job_requirement,\n",
        "                    'job_url': job_url\n",
        "                }\n",
        "                print(f\"Successfully scrape Section 1 job [{(section_1_counter)}]\")\n",
        "                section_1_counter += 1\n",
        "                all_jobs.append(jobbkk_info)\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping data: {e}\")\n",
        "            time.sleep(2)\n",
        "            # Close the new tab and switch back\n",
        "            driver_jobbkk.close()\n",
        "            driver_jobbkk.switch_to.window(original_window)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Unable to scrape Section 1 job {section_1_counter}: {e}\")\n",
        "    for x in range(24, 40, 2): # section 2\n",
        "        try:\n",
        "            xpath = f'/html/body/section[7]/article/section/div[1]/div[{x}]/div/div[3]/div/ul/li[3]/a'\n",
        "            element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
        "            driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "            # Switch to the new tab\n",
        "            WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "            original_window = driver_jobbkk.current_window_handle\n",
        "            new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "            driver_jobbkk.switch_to.window(new_window)\n",
        "\n",
        "            page_source = driver_jobbkk.page_source\n",
        "            soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "            \n",
        "            # Scrape data from the new tab\n",
        "            try:\n",
        "                job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "                company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text\n",
        "                industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "                location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "                workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "                responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "                gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "                age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "                education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "                experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "                job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "                job_url = driver_jobbkk.current_url\n",
        "                \n",
        "                jobbkk_info = {\n",
        "                    'job_title': job_title,\n",
        "                    'company_name': company_name,\n",
        "                    'industry': industry,\n",
        "                    'location': location,\n",
        "                    'workhour': workhour,\n",
        "                    'responsibility': responsibility,\n",
        "                    'gender': gender,\n",
        "                    'age': age,\n",
        "                    'education': education,\n",
        "                    'experience': experience,\n",
        "                    'job_requirement': job_requirement,\n",
        "                    'job_url': job_url\n",
        "                }\n",
        "                \n",
        "                print(f\"Successfully scrape Section 2 job [{(section_2_counter)}]\")\n",
        "                section_2_counter += 1\n",
        "                all_jobs.append(jobbkk_info)\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping data: {e}\")\n",
        "            time.sleep(2)\n",
        "            # Close the new tab and switch back\n",
        "            driver_jobbkk.close()\n",
        "            driver_jobbkk.switch_to.window(original_window)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Unable to scrape Section 2 job {section_2_counter}: {e}\")\n",
        "    for x in range(42, 60 , 2): # section 3\n",
        "        try:\n",
        "            xpath = f'/html/body/section[7]/article/section/div[1]/div[{x}]/div/div[3]/div/ul/li[3]/a'\n",
        "            element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
        "            driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "            # Switch to the new tab\n",
        "            WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "            original_window = driver_jobbkk.current_window_handle\n",
        "            new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "            driver_jobbkk.switch_to.window(new_window)\n",
        "\n",
        "            page_source = driver_jobbkk.page_source\n",
        "            soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "            \n",
        "            # Scrape data from the new tab\n",
        "            try:\n",
        "                job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "                company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text\n",
        "                industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "                location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "                workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "                responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "                gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "                age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "                education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "                experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "                job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "                job_url = driver_jobbkk.current_url\n",
        "                \n",
        "                jobbkk_info = {\n",
        "                    'job_title': job_title,\n",
        "                    'company_name': company_name,\n",
        "                    'industry': industry,\n",
        "                    'location': location,\n",
        "                    'workhour': workhour,\n",
        "                    'responsibility': responsibility,\n",
        "                    'gender': gender,\n",
        "                    'age': age,\n",
        "                    'education': education,\n",
        "                    'experience': experience,\n",
        "                    'job_requirement': job_requirement,\n",
        "                    'job_url': job_url\n",
        "                }\n",
        "                \n",
        "                print(f\"Successfully scrape Section 3 job [{(section_2_counter)}]\")\n",
        "                section_2_counter += 1\n",
        "                all_jobs.append(jobbkk_info)\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping data: {e}\")\n",
        "            time.sleep(2)\n",
        "            # Close the new tab and switch back\n",
        "            driver_jobbkk.close()\n",
        "            driver_jobbkk.switch_to.window(original_window)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Unable to scrape Section 3 job {section_3_counter}: {e}\")\n",
        "finally:\n",
        "    print('Done scraping')\n",
        "    driver_jobbkk.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31c1aef",
      "metadata": {},
      "outputs": [],
      "source": [
        "/html/body/section[7]/article/section/div[1]/div[20]/div/div[3]/div/ul/li[3]/a\n",
        "/html/body/section[7]/article/section/div[1]/div[24]/div/div[3]/div/ul/li[3]/a\n",
        "/html/body/section[7]/article/section/div[1]/div[38]/div/div[3]/div/ul/li[3]/a\n",
        "/html/body/section[7]/article/section/div[1]/div[42]/div/div[3]/div/ul/li[3]/a\n",
        "/html/body/section[7]/article/section/div[1]/div[58]/div/div[3]/div/ul/li[3]/a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "6df1d383",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Engineer รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)',\n",
              "  'workhour': 'เวลาทำงาน : 09:00 - 18:00',\n",
              "  'responsibility': 'รับผิดชอบงาน Data Integration, Data Pipeline Management\\nออกแบบ Data Architecture ติดตั้ง Big Data Platform และเครื่องมือที่เกี่ยวข้อง\\nออกแบบโครงสร้างการจัดเก็บและแนวทางการจัดเก็บข้อมูลบน Data Platform\\nศึกษาและค้นคว้าเทคโนโลยีที่เหมาะสมเพื่อพัฒนาสินค้าของเราให้มีคุณภาพที่ดีขึ้น และพัฒนาผลิตภัณฑ์ให้เป็นไปตามเป้าหมายของบริษัท',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 26 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 5',\n",
              "  'job_requirement': 'มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\nเชี่ยวชาญ SQL, NoSQL และเขียน Python ได้\\nหากเคยมีประสบการณ์เหล่านี้จะพิจารณาพิเศษ ได้แก่ ETL Tools, Airflow, NiFi, Streaming Real Time Data, Kafka\\nใช้ Linux Command, Linux Container ได้\\nหากมีประสบการณ์ติดตั้งหรือใช้งาน Hadoop, Hive, MongoDB, Kafka, Elasticsearch อย่างใดอย่างหนึ่งจะพิจารณาเป็นพิเศษ\\nชอบเรียนรู้ และเรียนรู้ทักษะใหม่ๆได้เร็ว ชอบศึกษา และแบ่งปันความรู้\\nมีทัศนคติในการทำงานในองค์กรที่ดี รักในงานที่ทำ มีวินัย และความรับผิดชอบสูง',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/180396/1270026'},\n",
              " {'job_title': 'Data Engineer รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท เอพพิค คอนซัลติ้ง จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เขตพญาไท,เขตห้วยขวาง)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'Big Data technology, Hadoop Cloudera Hadoop, Cloudera CDSW, Cloud MS Azure\\nExperience using data frameworks, Hadoop Platform, Spark for big data processing and Kafka.\\nProficient in programming languages, Python for data engineering.\\nKnowledge and skills in using Cloudera, SQL.',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 23 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี - ปริญญาโท',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 10',\n",
              "  'job_requirement': 'Excellent with database or data warehouse or ETL tools (Extract Transform and Load) technique and framework.\\nAbility to design the shell script. Understanding of big data architecture.\\nAbility to work with Data Scientist in Advanced Analytics for preparing or discovering business insights on focus the business strategies.\\nSoft skill in analytical, decision making and communication skills\\nSkills & Experiences: At least 3 years’ experience in BigData technology, BI/DWH ETL developmentdata analyst and system development.\\nHave an experience of unstructured data for Business Intelligence or computer science would be advantage.\\nTechnical skill in Oracle, SQL, UNIX and Shell Script, BI Reporting Tool, R Programming, Python, Hadoop, Excel, etc.\\nFamiliarity with ETL tools, BI Tools and data modeling.\\nBasic understanding of database concepts and SQL.',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/184598/1151675'},\n",
              " {'job_title': 'Data Engineer รับสมัครด่วน',\n",
              "  'company_name': 'R Systems Consulting Services (Thailand) Co., Ltd.',\n",
              "  'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': '- Data Engineer, Data Information - Programming in SQL, UNIX and Shell Script, Python, R Programming etc. - Skills: Talend, ETL, Hadoop, AWS, Cloud',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 22 - 55',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 2 - 7',\n",
              "  'job_requirement': 'ไม่ระบุ',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/215463/1194142'},\n",
              " {'job_title': 'Data Business รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท ไวท์ฟร้อนท์ จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : ธุรกิจอื่นๆ',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางนา,เขตประเวศ,เขตพระโขนง,เขตสวนหลวง)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมูล\\nรวบรวมข้อมูลที่จะใช้ในการวิเคราะห์\\nการจัดหาข้อมูลที่ขาดหายไป\\nกำหนด ตั้งค่า โครงสร้างพื้นฐาน\\nสร้าง Insight จากข้อมูล และระบุแนวโน้มที่เกิดขึ้นได้\\nสร้าง รายงาน สร้าง Dashboard / Automated Dashboard สำหรับผู้บริหาร และ ทีมงาน\\nมีความเข้าใจในธุรกิจ และวิเคราะห์ข้อมูลเพื่อตอบโจทย์ในทางธุรกิจได้',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 22 ปีขึ้นไป',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 2ปีขึ้นไป',\n",
              "  'job_requirement': 'มีทักษะด้านคณิตศาสตร์ และตัวเลข\\nเข้าใจเรื่องสถิติ มีประสบการณ์ในการสรุปผล เช่น\\nสามารถใช้งานเครื่องมือในการสร้างรายงาน สร้างDashboard\\nมีทักษะการวิเคราะห์ข้อมูลเชิงลึก เช่น การสรุปผล การดูแนวโน้ม ดู Pattern ข้อมูล\\nมีทักษะการนำเสนอ สามารถในการอธิบายโดยสามารถนำความคิดที่ซับซ้อนมาทำให้เป็นรูปแบบที่เข้าใจง่าย\\nมีทักษะการแก้ปัญหา\\nมีทักษะด้านการสื่อสาร มนุษสัมพันธ์ที่ดีต่อเพื่อนร่วมงาน',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/202470/1184164'},\n",
              " {'job_title': 'Data Analyst รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท พีซีซี อินเทอร์เนชันนัล จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : บริการ',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตยานนาวา)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': '1. ดูแลจัดการข้อมูลและรักษา Master Data ให้พร้อมใช้งาน 2. พัฒนา ออกแบบ และสร้างรายงานให้เหมาะสมกับข้อมูล และลักษณะของโปรเจคที่ได้รับมอบหมาย 3. รวบรวม ติดตาม จัดเก็บ และวิเคราะห์ข้อมูลการดำเนินงานประจำสัปดาห์/เดือน เพื่อนำมาวิเคราะห์ 4. วิเคราะห์ข้อมูลเชิงลึกของลูกค้าเป็น Dashboard และ Report เพื่อสนับสนุนการใช้งานทางธุรกิจ 5. ทำงานร่วมกับทีมเพื่อพัฒนาระบบการวิเคราะห์ข้อมูลที่ใช้ในการกำหนดกลยุทธ์ 6. ดูแล Support งานอื่นๆ ที่เกี่ยวข้อง 7. ทำงานจันทร์ - ศุกร์ เวลา 08.30-17.30 น. 8. สถานที่ทำงาน อาคาร MS Siam พระราม 3',\n",
              "  'gender': 'เพศ : ชาย , หญิง',\n",
              "  'age': 'อายุ(ปี) : 23 ปีขึ้นไป',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 1ปีขึ้นไป',\n",
              "  'job_requirement': '1. วุฒิปริญญาตรี สาขาบัญชี / สาขาวิทยาศาสตร์ข้อมูลและการวิเคราะห์ / สถิติประยุกต์ หรือสาขาที่เกี่ยวข้อง 2. มีทักษะด้านการใช้โปรแกรมคอมพิวเตอร์อย่างดี Microsoft Office (Word, Excel Advance, PowerPoint) หรือ SQL Queryได้ 3. มีความสามารถในการสื่อสาร การเจรจา มีไหวพริบ สามารถแก้ไขปัญหาเฉพาะหน้าได้เป็นอย่างดี และมี Growth Mindset 4. มีประสบการณ์งานด้านวิเคราะห์ข้อมูลมากกว่า 1 ปีขึ้นไป 5. สามารถสร้างรายงานผ่าน Power BI ได้ (จะพิจารณาเป็นพิเศษ)',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/20745/1242306'},\n",
              " {'job_title': 'Data Modeler รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท เอพพิค คอนซัลติ้ง จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เขตดินแดง,เขตพญาไท,เขตห้วยขวาง)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'Education - Minimum degree and major required : (i.e. High Vocational, Bachelor, Master, Ph.D.)\\nBachelor Degree in IT Related\\nExperience - Minimum work experiences required : (specified field/area and no. of years)\\nIT Application Development & Support at least 5 years.\\nExperience on DWH Project and/or Data Model Design are preferable.\\nSkill & Knowledge – Specific skills or certificates required :\\nDWH Design, Reporting Tools, Oracle DB, Unix Shellscirpt, PL/SQL, Datamodel Development Tools (Erwin, Rational Rose, etc.)',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 23 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี - ปริญญาโท',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 10',\n",
              "  'job_requirement': 'Analysis business requirements & data sources and design DB model on DWH\\nStructuring, and maintaining data model, data dictionary for DWH\\nPerform impact analysis whenever there is any change or new projects on data sources for DWH\\nDeliver Data Model to development & reporting team, arrange session for verification and validation design model\\nProblem Analysis, coordinate and work with reporting and/or development team for data quality assurance and for long term solution to reduce issues related to data quality and/or program bugs',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/184598/1095503'},\n",
              " {'job_title': 'Data Engineer รับสมัครด่วน',\n",
              "  'company_name': 'K.STONE CORPORATION LTD.',\n",
              "  'industry': 'ประเภทธุรกิจ : ที่ปรึกษา',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'ออกแบบ สร้าง บริหาร และปรับขนาดกระบวนการประมวลผลข้อมูล (batch/streaming) จากstructured/semi-structure/unstructured (เช่น CSV, JSON, Parquet, ตาราง, Kafka และอื่นๆ)\\nปรับปรุงความสามารถในการปรับขนาด ความเสถียร ความแม่นยำ ความเร็ว และประสิทธิภาพของระบบข้อมูล\\nรับผิดชอบในการออกแบบ สร้าง ทดสอบ และปรับใช้ new libraries, frameworks สำหรับระบบหลักด้วยมาตรฐานคุณภาพสูง',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 25 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 5',\n",
              "  'job_requirement': 'มีความรู้ความเข้าใจ Big data development เป็นอย่างดี\\nมีประสบการณ์ในการพัฒนา Automated software, Data pipeline และ deployment flow (CI/CD)\\nสามารถโค้ด Apache Spark, Python/PySpark, SQL ได้\\nเข้าใจด้าน Data Management concept\\nมีความรู้ความเข้าใจ Data และ analytics tools เช่น key-value data stores, in-memory data stores, real-time analytics databases, etc.\\nมีความรู้ด้าน Azure cloud\\nมีความรู้ด้าน Scala programming',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/47932/1261273'},\n",
              " {'job_title': 'Data Entry รับสมัครด่วน',\n",
              "  'company_name': 'Salmonenterprise',\n",
              "  'industry': 'ประเภทธุรกิจ : ค้าปลีก',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตพระโขนง,เขตประเวศ,เขตสวนหลวง)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : **วันเสาร์กลางเดือน WFH ครึ่งวันบ่าย**',\n",
              "  'responsibility': 'คีย์ข้อมูลต่างๆ\\nทำ report สนับสนุนข้อมูลภายในฝ่ายการตลาด\\nสามารถใช้งาน Compute โปรแกรม MS.Office ได้เป็นอย่างดี\\nExcel ระดับดี สามารถใช้ Vlookup,Pivot ได้\\nสามารถใช้งาน Fanpage Karma',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 23 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 0 - 2',\n",
              "  'job_requirement': 'เพศ : ชาย หญิง และ LGBT\\nอายุ(ปี) : อายุ 23 – 35 ปี\\nระดับการศึกษา : ป.ตรี (ไม่จำกัดคณะ) **หากจบคณะ สถิติ/วิจัย พิจารณาเป็นพิเศษ**',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/198750/1270127'},\n",
              " {'job_title': 'Data Analyst รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท เพชรดี นวัตกรรม จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : การเกษตร',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : นครปฐม(กำแพงแสน,ดอนตูม,นครชัยศรี,บางเลน,เมืองนครปฐม)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ทำงาน จันทร์ ถึง เสาร์ (วันเสาร์ทำงานเวลา 08.00-12.00 น.)',\n",
              "  'responsibility': 'วิเคราะห์ ออกแบบ และจัดทำฐานข้อมูลต่างๆ ที่ได้รับมอบหมาย เช่น ข้อมูลสินค้า ข้อมูลการขาย ยอดขาย พื้นที่ พืช สภาพอากาศ และค่าใช้จ่าย เป็นต้น เพื่อสนับสนุนให้ยอดขายเติบโต\\nจัดเก็บข้อมูล สังเกตข้อมูลที่ได้รับทุกมิติ และจัดทำฐานการเตรียมข้อมูลสำหรับการวิเคราะห์\\nประเมินผล และติดตามผลจากฝ่ายตนเอง และฝ่ายที่เกี่ยวข้อง รวบรวมทำเป็น รายสัปดาห์ / รายเดือน / รายไตรมาส / รายปี พร้อม Update ข้อมูลเป็นปัจจุบันอย่างสม่ำเสมอ\\nสรุปผลวิเคราะห์ ทำข้อมูลเชิงลึก นำเสนอ และสื่อสารผู้บริหาร ในรูปแบบต่างๆ ที่เหมาะสมเข้าใจง่ายเพื่อใช้ในการตัดสินใจทางธุรกิจ\\nศึกษาวิธี และกระบวนการทำงานของโปรแกรมแอพพลิเคชัน อุปกรณ์ต่างๆ ที่ได้รับมอบหมาย หรือเทคโนโลยีใหม่ๆ สม่ำเสมอ เพื่อประยุกต์ใช้หรือออกแบบงาน วางแผนงานร่วมกับฝ่ายที่เกี่ยวข้องได้\\nงานอื่นๆ ที่ได้รับมอบหมาย',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 22 - 29',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 1 - 3',\n",
              "  'job_requirement': 'วุฒิการศึกษา ป.ตรี สาขาวิทยาศาสตร์คอมพิวเตอร์, วิทยาการคอมพิวเตอร์, เทคโนโลยีคอมพิวเตอร์, วิศวกรรมคอมพิวเตอร์, คอมพิวเตอร์คณิตศาสตร์ หรือสาขาอื่นที่เกี่ยวข้อง\\nประสบการณ์ 1-3 ปี ในสายงานที่เกี่ยวข้องกับ Database / กรณีมีความรู้ด้านการวิเคราะห์ข้อมูลทางสถิติเชิงการตลาดจะได้รับการพิจารณาเป็นพิเศษ\\nมีความสามารถในการใช้ Excel ขั้นสูง, Power BI หรือโปรแกรมวิเคราะห์ข้อมูลอื่นๆ (สามารถนำเสนอได้)\\nเคยใช้โปรแกรมด้านสารสนเทศภูมิศาสตร์(GIS) เช่น ArcGIS, QGIS จะได้รับการพิจารณาเป็นพิเศษ\\nมีความละเอียดรอบคอบ มีไหวพริบ มีมนุษย์สัมพันธ์ดี Mindset ดี มีความคล่องแคล่ว\\nมีความสามารถในการสื่อสารข้อมูลที่ซับซ้อนได้ดี สามารถทำงานเป็นทีมได้ มีความรับผิดชอบ ซื่อสัตย์ ตรงต่อเวลา มีความทุ่มเท ในงานที่ได้รับมอบหมาย\\nมีใบอนุญาตขับขี่รถยนต์มีรถยนต์หรือขับขี่รถยนต์ที่สามารถเดินทางได้',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/201003/1261415'},\n",
              " {'job_title': 'Data Analysis รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท บาร์เกน พ้อยท์ จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : กิจกรรมทางกฎหมาย',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตคลองสามวา,เขตดอนเมือง,เขตบางเขน,เขตสายไหม,เขตหลักสี่)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : วันเสาร์เวลา 09.00 - 16.00 น. (ทำงาน 2 เสาร์/เดือน)',\n",
              "  'responsibility': 'วิเคราะห์ข้อมูลเชิงลึก\\nการสรุปผล การดูแนวโน้ม ข้อมูล เป็นต้น\\nนำเสนอแนวคิด แก้ปัญหา',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 24 - 30',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 2 - 3',\n",
              "  'job_requirement': '1.มีทักษะด้านคณิตศาสตร์ และตัวเลข ในระดับดี\\n2.เข้าใจเรื่องสถิติ มีประสบการณ์ในการสรุปผล\\n3.เข้าใจฐานข้อมูล\\n4.เข้าใจเรื่องสคริปต์และเว็บไซต์\\n5.สามารถใช้งานเครื่องมือในการสร้างรายงาน สร้างDashboard\\n6.ทักษะการวิเคราะห์ข้อมูลเชิงลึก เช่น การสรุปผล การดูแนวโน้ม ดู Pattern ข้อมูล เป็นต้น\\n7.ทักษะการนำเสนอ กาแก้ปัญหา และ การสื่อสาร',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/48492/1198008'},\n",
              " {'job_title': 'Data Analyst รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท แมส ช้อยส์ คอร์ปอเรชั่น จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : ส่งออก-นำเข้า',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตตลิ่งชัน,เขตบางพลัด,เขตบางแค,เขตทวีวัฒนา,เขตบางกอกน้อย)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : 08.15-17.45 น.',\n",
              "  'responsibility': 'สร้างระบบฐานข้อมูลสำคัญ ๆ ต่าง ๆ ขององค์กร โดยนำเสนอ Software/Application ที่เหมาะสมกับความต้องการใช้งานขององค์กร\\nมีความรู้ ความสามารถที่ดีเกี่ยวกับข้อมูลทางธุรกิจ และเข้าใจตรรกกะของความต้องการใช้ข้อมูลในรูปแบบที่เข้าใจง่าย และใช้งานง่าย เพื่อให้ users ได้ใช้งาน database ได้อย่างคล่องตัว และเกิดประโยชน์สูงสุดในการใช้งาน\\nสามารถวิเคราะห์ ข้อมูลต่าง ๆ ให้มีความหมายในเชิงธุรกิจ และสามารถสื่อสารกับเพื่อนร่วมงาน ผู้บริหาร ได้อย่างมีทักษะในการสื่อสารให้เข้าใจได้ง่าย ไม่ซับซ้อน และนำเสนอข้อมูลต่าง ๆ ในรูปแบบที่ง่ายต่อการเข้าใจ ไม่ซับซ้อน\\nมีความเฉลียวฉลาดในการแก้ปัญหาเฉพาะหน้า และปัญหาทางธุรกิจ สามารถตีโจทย์ออก โดยไม่จำเป็นต้องมีหัวหน้างานมาคอยบอกทุกรายละเอียด\\nมีสปิริตของความเป็นเจ้าของงานที่จะผลักดันงานให้สำเร็จตามเป้าหมายที่กำหนดไว้ให้ชัดเจน\\nมีมนุษยสัมพันธ์ที่ดีต่อผู้ที่ต้องติดต่อด้วย เพื่อให้งานได้รับการสนับสนุนได้อย่างลื่นไหล สำเร็จอย่างรวดเร็ว',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 25 - 32',\n",
              "  'education': 'ระดับการศึกษา : ปวส. - ปริญญาตรี',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 6',\n",
              "  'job_requirement': 'ใช้ software/application เพื่อบริหารจัดการ database ได้อย่างคล่องแคล่ว มีประสิทธิภาพ\\nใช้ Microsoft Excel ได้อย่างคล่อง ในระดับอย่างต่ำปานกลาง ต้องใช้เพื่อจัดการผูกสูตรที่มีความซับซ้อนได้ สามารถออกแบบ spreadsheet เพื่อรองรับโจทย์ทางธุรกิจเพื่อเป็นตัวหาคำตอบหรือบริหารข้อมูลทางธุรกิจได้อย่างมีระบบ ระเบียบ ถูกต้อง แม่นยำ ประมวลผลออกมาได้รวดเร็ว\\nหากมีความรู้ ประสพการณ์ เกี่ยวกับ software/application ที่จะใช้เพื่อบริหารจัดการระบบฐานข้อมูล ลูกค้า, suppliers, sales, purchasing และงานแอดมินในองค์กร จะได้รับการพิจารณาเป็นพิเศษ',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/43586/1268035'},\n",
              " {'job_title': 'Data Analyst (DA) รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท ไทเกอร์ จิลเวลรี่ แมนูแฟคเทอริ่ง (ประเทศไทย) จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : การผลิตเครื่องประดับจากอัญมณีและโลหะมีค่า',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตคลองสาน,เขตจอมทอง,เขตธนบุรี,เขตบางกอกน้อย,เขตภาษีเจริญ)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมูล\\nรวบรวมข้อมูลที่จะใช้ในการวิเคราะห์\\nการจัดหาข้อมูลที่ขาดหายไป\\nกำหนด ตั้งค่า โครงสร้างพื้นฐาน\\nสร้าง Insight จากข้อมูล และระบุแนวโน้มที่เกิดขึ้นได้\\nสร้าง รายงาน สร้าง Dashboard / Automated Dashboard สำหรับผู้บริหาร และ ทีมงาน\\nสร้าง Data Visualization จากข้อมูลได้',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 22 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี',\n",
              "  'experience': 'ประสบการณ์(ปี) : 0ปีขึ้นไป',\n",
              "  'job_requirement': 'ทักษะการนำเสนอ สามารถในการอธิบายโดยสามารถนำความคิดที่ซับซ้อนมาทำให้เป็นรูปแบบที่เข้าใจง่าย\\nทักษะการแก้ปัญหา\\nทักษะด้านการสื่อสาร\\nมีความเข้าใจในธุรกิจ และวิเคราะห์ข้อมูลเพื่อตอบโจทย์ในทางธุรกิจได้',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/49947/1018415'},\n",
              " {'job_title': 'Data Center staff รับสมัครด่วน',\n",
              "  'company_name': 'MANGO GLOBAL TECHNOLOGIES CO. LTD',\n",
              "  'industry': 'ประเภทธุรกิจ : ที่ปรึกษาจัดหางาน',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตห้วยขวาง)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ทำงานที่อาคารศูนย์บริหารทางพิเศษของการทางพิเศษแห่งประเทศไทย แบ่งออกเป็น: - เช้า 07.00 - 16.00 น. 1 ท่าน - ช่วงบ่าย เวลา 15.00 - 24.00 น. 1 ท่าน - กลางคืน 23.00 - 08.00 น. 1 ท่าน',\n",
              "  'responsibility': 'การดำเนินการตามแผนปฏิบัติการคอมพิวเตอร์และหลัก แผนการบำรุงรักษาระบบคอมพิวเตอร์ศูนย์ข้อมูล ให้บริการซ่อมแซมเบื้องต้น หรือป้องกัน ความเสียหายตามที่รายงาน ซ่อมแซม และบำรุงรักษาระบบคอมพิวเตอร์และอุปกรณ์ที่เกี่ยวข้อง ให้อยู่ในสภาพที่ดีและพร้อมใช้งานตลอดเวลา\\nแจ้งปัญหา อุปสรรคและแนวทางการดำเนินงานของการทางพิเศษแห่งประเทศไทย\\nทบทวน และ ฝึกการแก้ปัญหาในกรณีฉุกเฉินเร่งด่วน ควบคุมการทำงานของบริการภายนอก ผู้ให้บริการที่มาซ่อมแซมและบำรุงรักษาระบบคอมพิวเตอร์และอุปกรณ์ที่เกี่ยวข้อง บันทึกและสรุปการทำงานประจำวันและรายงานให้ กทพ. ทราบเพื่อให้สามารถดำเนินการได้\\nสรุปเป็นรายงานประจำเดือนและปฏิบัติตามขั้นตอนและกฎเกณฑ์การทำงานแล ข้อบังคับของ กทพ.',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 21 - 45',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี',\n",
              "  'experience': 'ประสบการณ์(ปี) : 2 - 6',\n",
              "  'job_requirement': 'วุฒิการศึกษาไม่ต่ำกว่าปริญญาตรี สาขาวิทยาการคอมพิวเตอร์ เทคโนโลยีสารสนเทศ วิศวกรรมคอมพิวเตอร์ วิศวกรรมโทรคมนาคม หรืออื่นๆ สาขาที่เกี่ยวข้อง\\nมีประสบการณ์การทำงานอย่างน้อย 2 ปี และมีใบรับรองประสบการณ์ในการบำรุงรักษา, ตรวจสอบและแก้ไขปัญหาระบบคอมพิวเตอร์และอุปกรณ์ต่อพ่วงที่เกี่ยวข้อง\\nสามารถทำงานเป็นกะได้',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/223449/1270113'},\n",
              " {'job_title': 'Data Analysis ( Training Officer) รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท ไทยฮะจิบัง จำกัด ',\n",
              "  'industry': 'ประเภทธุรกิจ : อาหาร-เครื่องดื่ม',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตพระนคร)',\n",
              "  'workhour': 'เวลาทำงาน : 08:30 - 17:30',\n",
              "  'responsibility': 'ดำเนินการจัดส่งและติดตามแบบฟอร์มการสอนงานของพนักงานใหม่พร้อมบันทึกประวัติให้เป็นปัจจุบัน\\nติดตามการสอบเลื่อนตำแหน่งของพนักงานให้เป็นไปตามระยะเวลาที่กำหนด\\nจัดทำรายงานผลความคืบหน้าในการสอบเลื่อนตำแหน่งเพื่อส่งผู้บริหารสาขาประจำทุกเดือน\\nบันทึกประวัติการอบรมของพนักงานให้เป็นปัจจุบัน รวบรวมข้อมูล ประมวลผล วิเคราะห์ สรุปผลประจำเดือน\\nจัดทำรายงานการฝึกอบรมประจำเดือนเพื่อรายงานผู้บริหารสาขาและสรุปผู้เข้าอบรมประจำเดือนให้กับ HR\\nประสานงานและดำเนินการจัดฝึกอบรมทั้งภายในและภายนอกบริษัท กรุงเทพปริมณฑลและต่างจังหวัด\\nจัดเตรียมอุปกรณ์การเรียนการสอน คู่มือ สถานที่อบรมให้พร้อมใช้งาน\\nรับเรื่องติดต่อประสานงานให้ความช่วยเหลือสาขา กรณีมีคำถามเกี่ยวกับการฝึกอบรมพนักงานหรือขั้นตอนการปฏิับัติงานรวมถึงคุู่มืือการปฏิบัติงาน\\nงานอื่นๆที่ได้รับมอบหมาย',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 28 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3ปีขึ้นไป',\n",
              "  'job_requirement': 'จัดการด้านข้อมูล วิเคราะห์ข้อมูลเชิงสถิติของส่วนงาน Training เพื่อใช้ประกอบในการวางแผนติดตามและวางกลยุทธ์ที่เกี่ยวข้องกับการฝึกอบรม\\nสามารถจัดทำรายงานการฝึกอบรมด้านประวัติการอบรมพนักงานทั้งหมดของบริษัท ข้อมูลการเลื่อนตำแหน่งและติดตามการพัฒนาพนักงาน\\nประสานงานกับทีมงานและดำเนินการด้านต่างๆที่เกี่ยวข้องกับการพัฒนาบุคลากรได้อย่างครบถ้วน\\nสามารถใช้โปรแกรม CANVA หรืออื่นๆได้เพื่อจัดทำข้อมูลและ Presentation ได้ดี\\nสามารถใช้ Power BI ในการวิเคราะห์ข้อมูลและจัดทำสถิตได้อย่างดี\\nสามารถใช้ Microsoft Office โปรแกรม Excel ได้ในระดับดีมาก',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/212545/1264646'},\n",
              " {'job_title': 'Data Analyst / Business Development Officer รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท ศรัณย์การแพทย์ จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : กิจกรรมโรงพยาบาล',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางคอแหลม)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'ดึง Data มาสร้างเป็น Business Report เพื่อนำมาช่วยในการวางกลยุทธและแผนงานธุรกิจ\\nจัดทำ Presentation เพื่อนำเสนอ Management\\nวิเคราะห์หา Insight ที่น่าสนใจจากข้อมูล\\nนำ Data มาวิเคราะห์เพื่อตอบโจทย์ทางธุรกิจของฝั่ง Business\\nศึกษาหาข้อมูลเพิ่มเติมจากลูกค้า แผนกอื่นในองค์กร และนำข้อมูลมาวิเคราะห์เพื่อวางกลยุทธ์และแผนพัฒนาธุรกิจ\\nมีส่วนร่วมในการวางโครงสร้างข้อมูลเพื่อให้การนำข้อมูลมาวิเคราะห์เป็นไปได้อย่างถูกต้อง\\nร่วมวางแผนแนวทางด้านธุรกิจให้กับบริษัท ทั้งในส่วนของการรักษาฐานลูกค้าเดิมที่มีอยู่ ตลอดไปจนถึงการพัฒนาค้นหาสิ่งใหม่ๆ เพื่อเดินหน้าขยายตลาด หรือหาลูกค้ารายใหม่ให้แก่องค์กร\\nงานอื่นๆตามที่ได้รับมอบหมาย',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 22 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี - ปริญญาเอก',\n",
              "  'experience': 'ประสบการณ์(ปี) : 0 - 10 ปีขึ้นไป',\n",
              "  'job_requirement': 'ป.ตรี สาขาด้านวิทยาศาสตร์คอมพิวเตอร์ สาขาสถิติ หรือสาขาที่เกี่ยวข้อง\\nประสบการณ์ 0-2 ปี ด้านงาน วิเคราะห์ข้อมูล / กรณีมีความรู้ด้าน Power BI /SSRS Report และ ระบบ SAP จะได้รับพิจารณาเป็นพิเศษ\\nมีทักษะด้านการใช้ คอมพิวเตอร์ Microsoft Office (Word, Excel Advance, PowerPoint) และ โปรแกรมทางสถิติ (จะได้รับการพิจารณาเป็นพิเศษ)\\nมีความรู้ ทักษะ ในการวิเคราะห์ข้อมูล\\nมีความสามารถในการสื่อสารสามารถทำงานเป็นทีมได้',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/196232/1268547'},\n",
              " {'job_title': 'Database Administrator รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท โทลล์เทค จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางกะปิ,เขตประเวศ,เขตลาดพร้าว)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'Working cross-functionally with our engineers and analytics professionals to optimize queries, fix performance bottlenecks, improve existing schemas and design new ones\\nCreating and maintaining change control and testing processes, reviewing and approving database modifications\\nConducting research and making recommendations on data-related products, services, protocols, and standards; planning for future growth of our data asset\\nReviewing development and deployment processes related to databases and identifying areas of improvement (such as online schema changes)\\nCreating and maintaining documentation, troubleshooting playbooks, testing failover and recovery plans\\nImproving database expertise company-wide.\\nEnsure data security and integrity, including implementation of access controls, backups, and recovery plans.\\nExecute disaster recovery plans and procedures to ensure database availability during system outages or dysfunction.\\nDesign/Install/Configure/Manage/Monitoring/Maintain /Tuning/Backup/Security/Troubleshooting for both Oracle and Postgresql database based on Solaris/Linux.\\nSQL Query performance tuning',\n",
              "  'gender': 'เพศ : ชาย',\n",
              "  'age': 'อายุ(ปี) : 25 - 32',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 5',\n",
              "  'job_requirement': 'Education: Bachelor or higher in Computer Science, Computer Engineer, Information Systems or related technical degree; or equivalent combination of education and experience\\nExperience: 3-5 years of database management and engineering experience.\\nExperience: 3-5 years of Oracle/PostgreSQL and engineering experience\\nStrong knowledge of database administration, Software Development Life Cycle (SDLC), and systems analysis procedures\\nExperience architecting large-scale production database platforms.\\nFamiliarity with system-level metrics and practical use of common Linux utilities\\nUnderstanding of virtualization and clustered environments.\\nGreat communication skills and a passion for both teaching and learning.\\nHighly responsible, diligent, patient, and creative thinker.\\nHave a positive attitude towards work and can work under pressure.',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/194906/1255525'},\n",
              " {'job_title': 'เจ้าหน้าที่ Data Support / Data Mining รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท แอดไวซ์ ไอที อินฟินิท จำกัด (มหาชน)',\n",
              "  'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : นนทบุรี(ปากเกร็ด)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : บางตำแหน่งจะเป็นการทำงานแบบวันเสาร์ เว้นวันเสาร์',\n",
              "  'responsibility': 'Maintenance ดูแลฐานข้อมูล\\nValidate ตรวจสอบความถูกต้อง\\nตรวจและแก้ไขตาม Requirement Job\\nMonitor ดูแลระบบ\\nทำข้อมูลสรุปรายงาน\\nBackup สำรองข้อมูล\\nจัดการทรัพยากร Database',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 22 - 30',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี',\n",
              "  'experience': 'ประสบการณ์(ปี) : 0ปีขึ้นไป',\n",
              "  'job_requirement': 'วุฒิการศึกษาปริญญาตรี สาขาวิศวกรรม/วิทยาศาสตร์คอมพิวเตอร์, เทคโนโลยีสารสนเทศ และสาขาอื่นๆที่เกี่ยวข้อง\\nสามารถใช้โปรแกรม Microsoft Office ได้ดี\\nมีความรู้เกี่ยวกับระบบฐานข้อมูลเช่น Mysql , SQL Server , Postgre หรืออิ่น ๆ\\nมีความรู้เกี่ยวกับ SQL Language',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/48282/1226174'},\n",
              " {'job_title': 'DATA ANALYSIS รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท ลีโอ เมดดิคอล จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : พาณิชย์',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตตลิ่งชัน,เขตทวีวัฒนา,เขตบางแค,เขตภาษีเจริญ,เขตหนองแขม)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': '1.ตรวจสอบแก้ไขปัญหาและซ่อมแซมระบบ Hardware, Software , Network\\n2.มีความรู้ระบบ LAN WAN Wireless และ Network ต่างๆ\\n3.มีความรู้เรื่อง CCTV และระบบเครือข่ายโทรศัพท์\\n4.มีความเข้าใจงานเทคโนโลยีสารสนเทศ\\n5.มีความเข้าใจในระบบคอมพิวเตอร์ PC เป็นอย่างดีทั้ง HARDWARE และ SOFTWARE',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 25 - 40',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี',\n",
              "  'experience': 'ประสบการณ์(ปี) : 2 - 5',\n",
              "  'job_requirement': '1. ชาย / หญิง อายุ 25-40ปี\\n2. วุฒิ ปวส.-ป.ตรี สาขาคอมพิวเตอร์หรือที่เกี่ยวข้อง เพื่อให้ความช่วยเหลือในการแก้ไขปัญหา ต่าง ๆ ด้านระบบเทคโนโลยีสารสนเทศให้สามารถใช้งานได้เป็นปกติ\\n3. มีประสบการณ์ในการทำงาน เกี่ยวกับ IT Support หรือ Network Support และสามารถใช้งานระบบ ERP,IT Security, Microsoft Office (Excel, Power Point ,Access\\n4.มนุษยสัมพันธ์ดี ขยัน มีความรับผิดชอบ มีทักษะในเรื่องการประสานงานและการเจรจา',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/14277/1113075'},\n",
              " {'job_title': 'Automotive Data Analyst รับสมัครด่วน',\n",
              "  'company_name': 'บริษัท พระนคร ยนตรการ จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : อุตสาหกรรมยานพาหนะ',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'Data Collection and Management : Collect, process, and validate from various sources including sales, service , market research , and customer feedback. / Maintain databases and ensure data integrity and accuracy. / Implement and manage data collection systems and other strategies that optimize statistical efficiency and data quality.\\nData Analysis and Interpretation : Analyze data using statistical techniques and provide reports on key findings . / Interpret data, identify trends, and make recommendations based on analysis . / Develop and implement data analysis, data collection systems, and other strategies that optimize statistical efficiency and quality.\\nReporting and Visualization : Create detailed reports and dashboards to communicate findings to stakeholders . / Use data visualization tools to present complex data in an understandable and actionable manner . / Prepare and present insights and recommendations to senior management.\\nMarket and Customer Insights : Conduct market analysis to identify trends, opportunities, and competitive landscape . / Analyze customer data to identify patterns in behavior and preferences . / Provide actionable insights insights to inform marketing strategies, product development, and customer service improvements.\\nPerformance Monitoring : Monitor and evaluate the performance of various business functions using data . / Identify areas of improvement and provide data-driven recommendations . / Track key performance indicators (KPls) and report on performance metrics.\\nCollaboration : Work closely with cross-functional teams including marketing, sales, product development, and customer service . / Collaborate with IT to ensure data collection and analysis processes are aligned with business needs . / Support business initiatives with data-driven insights and analysis.\\nData Governance and Compliance : Ensure compliance with data governance and privacy policies . / Implement data quality assurance processes . / Stay updated with industry best practices and emerging trends in data analytics.',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 35 ปีขึ้นไป',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป',\n",
              "  'experience': 'ประสบการณ์(ปี) : 5ปีขึ้นไป',\n",
              "  'job_requirement': 'The Automotive Data Analyst is responsible for collecting , analyzing , and interpreting data related to automotive operation , market trends , and customer behavior. This role involves leveraging data to provide insights that drive business decision , improve operational efficiency, and enhance customer experience. The ideal candidate will have strong analytical skills , experience with data analysis tools , and a background in the automotive industry.',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/177160/1261718'},\n",
              " {'job_title': 'Senior Data Analysis รับสมัครด่วน',\n",
              "  'company_name': 'รักษาความปลอดภัย โพรเกรส กันภัย',\n",
              "  'industry': 'ประเภทธุรกิจ : ขนส่ง',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : นนทบุรี(ปากเกร็ด)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'Collecting and interpreting data Analysing results Reporting the results back to the relevant members of the business Identifying patterns and trends in data sets Working alongside teams within the business or the management team to establish business needs Defining new data collection and analysis processes',\n",
              "  'gender': 'เพศ : ชาย , หญิง',\n",
              "  'age': 'อายุ(ปี) : ทุกช่วงอายุ',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี - ปริญญาโท',\n",
              "  'experience': 'ประสบการณ์(ปี) : 3 - 5',\n",
              "  'job_requirement': 'High proficiency in Mocrosoft Office programs, especially Excel and PowerPoint Positive work attitude and comfortable working in multi-task and tight requirements',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/174062/988561'},\n",
              " {'job_title': 'Network Data Analysis รับสมัครด่วน',\n",
              "  'company_name': 'เจอีดี เอ็กซ์เพรส จำกัด',\n",
              "  'industry': 'ประเภทธุรกิจ : ขนส่ง',\n",
              "  'location': 'สถานที่ปฏิบัติงาน : สงขลา(หาดใหญ่)',\n",
              "  'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ',\n",
              "  'responsibility': 'เรียนรู้การทำงานของหน้างานสาขาต่าง ๆ\\nสรุปผลข้อมูลการนำส่งพัสดุของสาขา\\nวิเคราะห์ข้อมูลจัดทำรายงานผลการปฏิบัติงาน\\nวางแผนแก้ปัญหาของหน้าร้านสาขา\\nดูแลประสิทธิภาพด้านการขนส่ง',\n",
              "  'gender': 'เพศ : ไม่ระบุ',\n",
              "  'age': 'อายุ(ปี) : 25 - 35',\n",
              "  'education': 'ระดับการศึกษา : ปริญญาตรี',\n",
              "  'experience': 'ประสบการณ์(ปี) : 2ปีขึ้นไป',\n",
              "  'job_requirement': 'เพศหญิง-ชาย อายุ 25 ปี ขึ้นไป\\nวุฒิการศึกษาปริญญาตรี\\nสามารถใช้โปรแกรม Microsoft Excel ได้เป็นอย่างดี\\nมีทักษะการติดต่อประสานงานที่ดี\\nมีความรับผิดชอบ แก้ไขปัญหาเฉพาะหน้าได้ดี\\nหากมีประสบการณ์ทำงานด้านการขนส่ง,โลจิสติกส์หรือคลังสินค้าจะพิจารณาเป็นพิเศษ\\nสัมภาษณ์ที่ J&T สำนักงานใหญ่ (หาดใหญ่)',\n",
              "  'job_url': 'https://www.jobbkk.com/jobs/detailurgent/202266/1271224'}]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ff64ffa0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(first_page_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5704024",
      "metadata": {},
      "outputs": [],
      "source": [
        "/html/body/section[7]/article/section/div[1]/div[8]/div/div[2]/div[2]/div/div[1]/a/div/div/p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4581bd5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobbkk_job_data = pd.DataFrame(all_jobs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fc6e215d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company_name</th>\n",
              "      <th>industry</th>\n",
              "      <th>location</th>\n",
              "      <th>workhour</th>\n",
              "      <th>responsibility</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>experience</th>\n",
              "      <th>job_requirement</th>\n",
              "      <th>welfare_and_benefits</th>\n",
              "      <th>job_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Engineer รับสมัครด่วน</td>\n",
              "      <td>บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)</td>\n",
              "      <td>เวลาทำงาน : 09:00 - 18:00</td>\n",
              "      <td>รับผิดชอบงาน Data Integration, Data Pipeline M...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 26 - 35</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 3 - 5</td>\n",
              "      <td>มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\n...</td>\n",
              "      <td>ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภา...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/18039...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Engineer รับสมัครด่วน</td>\n",
              "      <td>บริษัท เอพพิค คอนซัลติ้ง จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>Big Data technology, Hadoop Cloudera Hadoop, C...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 23 - 35</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี - ปริญญาโท</td>\n",
              "      <td>ประสบการณ์(ปี) : 3 - 10</td>\n",
              "      <td>Excellent with database or data warehouse or E...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\n\\nเบอร์ผู้...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/18459...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Engineer รับสมัครด่วน</td>\n",
              "      <td>R Systems Consulting Services (Thailand) Co., ...</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>- Data Engineer, Data Information - Programmin...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 22 - 55</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 2 - 7</td>\n",
              "      <td>ไม่ระบุ</td>\n",
              "      <td>ชื่อผู้ติดต่อ : Arpaporn Mekloy\\n\\nเบอร์ผู้ติด...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/21546...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Business รับสมัครด่วน</td>\n",
              "      <td>บริษัท ไวท์ฟร้อนท์ จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : ธุรกิจอื่นๆ</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางนา,เขต...</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมู...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 22 ปีขึ้นไป</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 2ปีขึ้นไป</td>\n",
              "      <td>มีทักษะด้านคณิตศาสตร์ และตัวเลข\\nเข้าใจเรื่องส...</td>\n",
              "      <td>ค่าทำงานล่วงเวลา\\nประกันสังคม\\nตามข้อตกลงของบร...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/20247...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Analyst รับสมัครด่วน</td>\n",
              "      <td>บริษัท พีซีซี อินเทอร์เนชันนัล จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : บริการ</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตยานนาวา)</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>1. ดูแลจัดการข้อมูลและรักษา Master Data ให้พร้...</td>\n",
              "      <td>เพศ : ชาย , หญิง</td>\n",
              "      <td>อายุ(ปี) : 23 ปีขึ้นไป</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 1ปีขึ้นไป</td>\n",
              "      <td>1. วุฒิปริญญาตรี สาขาบัญชี / สาขาวิทยาศาสตร์ข้...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : ชุติญา ไสยพร\\n\\nเบอร์ผู้ติดต่อ...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/20745...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Modeler รับสมัครด่วน</td>\n",
              "      <td>บริษัท เอพพิค คอนซัลติ้ง จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>Education - Minimum degree and major required ...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 23 - 35</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี - ปริญญาโท</td>\n",
              "      <td>ประสบการณ์(ปี) : 3 - 10</td>\n",
              "      <td>Analysis business requirements &amp; data sources ...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\n\\nเบอร์ผู้...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/18459...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    job_title  \\\n",
              "0  Data Engineer รับสมัครด่วน   \n",
              "1  Data Engineer รับสมัครด่วน   \n",
              "2  Data Engineer รับสมัครด่วน   \n",
              "3  Data Business รับสมัครด่วน   \n",
              "4   Data Analyst รับสมัครด่วน   \n",
              "5   Data Modeler รับสมัครด่วน   \n",
              "\n",
              "                                        company_name  \\\n",
              "0                  บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด   \n",
              "1                     บริษัท เอพพิค คอนซัลติ้ง จำกัด   \n",
              "2  R Systems Consulting Services (Thailand) Co., ...   \n",
              "3                           บริษัท ไวท์ฟร้อนท์ จำกัด   \n",
              "4               บริษัท พีซีซี อินเทอร์เนชันนัล จำกัด   \n",
              "5                     บริษัท เอพพิค คอนซัลติ้ง จำกัด   \n",
              "\n",
              "                          industry  \\\n",
              "0  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที   \n",
              "1  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที   \n",
              "2  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที   \n",
              "3       ประเภทธุรกิจ : ธุรกิจอื่นๆ   \n",
              "4            ประเภทธุรกิจ : บริการ   \n",
              "5  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที   \n",
              "\n",
              "                                            location  \\\n",
              "0       สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)   \n",
              "1  สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...   \n",
              "2          สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)   \n",
              "3  สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางนา,เขต...   \n",
              "4      สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตยานนาวา)   \n",
              "5  สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...   \n",
              "\n",
              "                    workhour  \\\n",
              "0  เวลาทำงาน : 09:00 - 18:00   \n",
              "1   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "2   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "3   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "4   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "5   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "\n",
              "                                      responsibility            gender  \\\n",
              "0  รับผิดชอบงาน Data Integration, Data Pipeline M...     เพศ : ไม่ระบุ   \n",
              "1  Big Data technology, Hadoop Cloudera Hadoop, C...     เพศ : ไม่ระบุ   \n",
              "2  - Data Engineer, Data Information - Programmin...     เพศ : ไม่ระบุ   \n",
              "3  กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมู...     เพศ : ไม่ระบุ   \n",
              "4  1. ดูแลจัดการข้อมูลและรักษา Master Data ให้พร้...  เพศ : ชาย , หญิง   \n",
              "5  Education - Minimum degree and major required ...     เพศ : ไม่ระบุ   \n",
              "\n",
              "                      age                             education  \\\n",
              "0      อายุ(ปี) : 26 - 35      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "1      อายุ(ปี) : 23 - 35  ระดับการศึกษา : ปริญญาตรี - ปริญญาโท   \n",
              "2      อายุ(ปี) : 22 - 55      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "3  อายุ(ปี) : 22 ปีขึ้นไป      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "4  อายุ(ปี) : 23 ปีขึ้นไป      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "5      อายุ(ปี) : 23 - 35  ระดับการศึกษา : ปริญญาตรี - ปริญญาโท   \n",
              "\n",
              "                   experience  \\\n",
              "0      ประสบการณ์(ปี) : 3 - 5   \n",
              "1     ประสบการณ์(ปี) : 3 - 10   \n",
              "2      ประสบการณ์(ปี) : 2 - 7   \n",
              "3  ประสบการณ์(ปี) : 2ปีขึ้นไป   \n",
              "4  ประสบการณ์(ปี) : 1ปีขึ้นไป   \n",
              "5     ประสบการณ์(ปี) : 3 - 10   \n",
              "\n",
              "                                     job_requirement  \\\n",
              "0  มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\n...   \n",
              "1  Excellent with database or data warehouse or E...   \n",
              "2                                            ไม่ระบุ   \n",
              "3  มีทักษะด้านคณิตศาสตร์ และตัวเลข\\nเข้าใจเรื่องส...   \n",
              "4  1. วุฒิปริญญาตรี สาขาบัญชี / สาขาวิทยาศาสตร์ข้...   \n",
              "5  Analysis business requirements & data sources ...   \n",
              "\n",
              "                                welfare_and_benefits  \\\n",
              "0  ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภา...   \n",
              "1  ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\n\\nเบอร์ผู้...   \n",
              "2  ชื่อผู้ติดต่อ : Arpaporn Mekloy\\n\\nเบอร์ผู้ติด...   \n",
              "3  ค่าทำงานล่วงเวลา\\nประกันสังคม\\nตามข้อตกลงของบร...   \n",
              "4  ชื่อผู้ติดต่อ : ชุติญา ไสยพร\\n\\nเบอร์ผู้ติดต่อ...   \n",
              "5  ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\n\\nเบอร์ผู้...   \n",
              "\n",
              "                                             job_url  \n",
              "0  https://www.jobbkk.com/jobs/detailurgent/18039...  \n",
              "1  https://www.jobbkk.com/jobs/detailurgent/18459...  \n",
              "2  https://www.jobbkk.com/jobs/detailurgent/21546...  \n",
              "3  https://www.jobbkk.com/jobs/detailurgent/20247...  \n",
              "4  https://www.jobbkk.com/jobs/detailurgent/20745...  \n",
              "5  https://www.jobbkk.com/jobs/detailurgent/18459...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jobbkk_job_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "372a2143",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76360d9d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5b96fc",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72e26ea8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "7d72efeb",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Length of values (6) does not match length of index (25)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jobbkk_job_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfirst_page_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:859\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m         dtype,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[1;32m--> 859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    868\u001b[0m         data,\n\u001b[0;32m    869\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    873\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    874\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:630\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    627\u001b[0m         val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    629\u001b[0m     val \u001b[38;5;241m=\u001b[39m sanitize_array(val, index, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 630\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m     refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    633\u001b[0m homogenized\u001b[38;5;241m.\u001b[39mappend(val)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Length of values (6) does not match length of index (25)"
          ]
        }
      ],
      "source": [
        "jobbkk_job_data = pd.DataFrame(all_jobs,first_page_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "3f679936",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error scraping data: Message: javascript error: Unexpected token ':'\n",
            "  (Session info: chrome=128.0.6613.115)\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655F71CD3]\n",
            "\t(No symbol) [0x00007FF655F74398]\n",
            "\t(No symbol) [0x00007FF65600775C]\n",
            "\t(No symbol) [0x00007FF655FE66EA]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Error scraping data: Message: javascript error: Unexpected token ':'\n",
            "  (Session info: chrome=128.0.6613.115)\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF65613B5D2+29090]\n",
            "\t(No symbol) [0x00007FF6560AE689]\n",
            "\t(No symbol) [0x00007FF655F6B1CA]\n",
            "\t(No symbol) [0x00007FF655F71CD3]\n",
            "\t(No symbol) [0x00007FF655F74398]\n",
            "\t(No symbol) [0x00007FF65600775C]\n",
            "\t(No symbol) [0x00007FF655FE66EA]\n",
            "\t(No symbol) [0x00007FF6560065D9]\n",
            "\t(No symbol) [0x00007FF655FE6493]\n",
            "\t(No symbol) [0x00007FF655FB09B1]\n",
            "\t(No symbol) [0x00007FF655FB1B11]\n",
            "\tGetHandleVerifier [0x00007FF656458C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF6564A4843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF65649A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF6561F6EB6+797318]\n",
            "\t(No symbol) [0x00007FF6560B980F]\n",
            "\t(No symbol) [0x00007FF6560B53F4]\n",
            "\t(No symbol) [0x00007FF6560B5580]\n",
            "\t(No symbol) [0x00007FF6560A4A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "wait = WebDriverWait(driver_jobbkk, 10)  # Adjust the timeout as needed\n",
        "\n",
        "all_jobs = []\n",
        "try:\n",
        "    # Open the main URL\n",
        "    driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "    \n",
        "    # Loop through elements starting from index 6, with a step of 2\n",
        "    for x in range(6, 20, 2):\n",
        "        try:\n",
        "            xpath = f'/html/body/section[7]/article/section/div[1]/div[{x}]/div/div[3]/div/ul/li[3]/a'\n",
        "            element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
        "            driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "            # Switch to the new tab\n",
        "            WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "            original_window = driver_jobbkk.current_window_handle\n",
        "            new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "            driver_jobbkk.switch_to.window(new_window)\n",
        "\n",
        "            page_source = driver_jobbkk.page_source\n",
        "            soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "            \n",
        "            # Scrape data from the new tab\n",
        "            try:\n",
        "                job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "                company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text.strip()\n",
        "                industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "                # fulltime = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[4]').text\n",
        "                location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "                work_day = driver_jobbkk.execute_script(\"body > section.container > article > div > article > section:nth-child(2) > article:nth-child(1) > div > div:nth-child(6) > p:nth-child(8) > span\")\n",
        "                dayoff = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[9]').text\n",
        "                workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "                responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "                gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "                age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "                education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "                experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "                job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "                job_requirement2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[7]/div').text\n",
        "                welfare_and_benefits = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[8]/div').text\n",
        "                welfare_and_benefits2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[9]/div').text\n",
        "                company_contact = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[10]/div').text\n",
        "                job_url = driver_jobbkk.current_url\n",
        "                \n",
        "                jobbkk_info = {\n",
        "                    'job_title': job_title,\n",
        "                    'company_name': company_name,\n",
        "                    'industry': industry,\n",
        "                    #'salary': salary,  # Scraped from main page\n",
        "                    #'posted_time': posted_time,  # Scraped from main page\n",
        "                    #'fulltime': fulltime,\n",
        "                    'location': location,\n",
        "                    'workday': work_day,\n",
        "                    #'dayoff': dayoff,\n",
        "                    'workhour': workhour,\n",
        "                    'responsibility': responsibility,\n",
        "                    'gender': gender,\n",
        "                    'age': age,\n",
        "                    'education': education,\n",
        "                    'experience': experience,\n",
        "                    'job_requirement': job_requirement,\n",
        "                    'job_requirement2': job_requirement2,\n",
        "                    'welfare_and_benefits': welfare_and_benefits,\n",
        "                    'welfare_and_benefits2': welfare_and_benefits2,\n",
        "                    'company_contact': company_contact,\n",
        "                    'job_url': job_url\n",
        "                }\n",
        "                print(jobbkk_info)\n",
        "                all_jobs.append(jobbkk_info)\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping data: {e}\")\n",
        "            time.sleep(2)\n",
        "            # Close the new tab and switch back\n",
        "            driver_jobbkk.close()\n",
        "            driver_jobbkk.switch_to.window(original_window)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred for element with index {x}: {e}\")\n",
        "\n",
        "finally:\n",
        "    print('Done scraping')\n",
        "    driver_jobbkk.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "bb632086",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "วันทำงาน :\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# Initialize the WebDriver (assuming you're using Chrome)\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "\n",
        "# Open the target webpage\n",
        "driver_jobbkk.get(\"https://www.jobbkk.com/jobs/detailurgent/180396/1270026\")\n",
        "\n",
        "# Wait for the page to fully load (optional)\n",
        "driver_jobbkk.implicitly_wait(10)\n",
        "\n",
        "# Use Selenium to find the element by its CSS selector\n",
        "work_day_element = driver_jobbkk.find_element(By.CSS_SELECTOR,\n",
        "    \"body > section.container > article > div > article > section:nth-child(2) > article:nth-child(1) > div > div:nth-child(6) > p:nth-child(8) > span\"\n",
        ")\n",
        "\n",
        "# Extract the text from the element\n",
        "work_day_text = work_day_element.text\n",
        "\n",
        "# Print the text\n",
        "print(work_day_text)\n",
        "\n",
        "# Close the browser\n",
        "driver_jobbkk.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d25e13ec",
      "metadata": {},
      "outputs": [
        {
          "ename": "MaxRetryError",
          "evalue": "HTTPConnectionPool(host='localhost', port=64343): Max retries exceeded with url: /session/e3ed2fcd8b2ad6faddb7904a342272e5/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000014A9707BD70>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
            "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1520.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1520.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1520.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
            "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000014A9707BD70>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdriver_jobbkk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://www.jobbkk.com/jobs/lists/1/\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mAB\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB2\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%87%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB2\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m99,data,\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%97%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%81%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%88%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB1\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%87%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mAB\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mA7\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB1\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m94,\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%97%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB1\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;132;43;01m%87%\u001b[39;49;00m\u001b[38;5;124;43mE0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mAB\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mA1\u001b[39;49m\u001b[38;5;132;43;01m%E\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB8\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m94.html?keyword_type=3&member_user_id=1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:363\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    137\u001b[0m         method,\n\u001b[0;32m    138\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    872\u001b[0m     )\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    892\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    872\u001b[0m     )\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    892\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    872\u001b[0m     )\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    892\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
            "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=64343): Max retries exceeded with url: /session/e3ed2fcd8b2ad6faddb7904a342272e5/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000014A9707BD70>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
          ]
        }
      ],
      "source": [
        "driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3463f0f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
