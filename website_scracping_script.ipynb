{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "246e7be2",
      "metadata": {},
      "source": [
        "# Collect Data by Scraping using Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a697931",
      "metadata": {
        "id": "9a697931"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import bs4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3feecee",
      "metadata": {},
      "source": [
        "## Selenium setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b4ca2d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "driver_path = r'C:\\Program Files (x86)\\chromedriver-win64\\chromedriver.exe'\n",
        "\n",
        "def create_driver():\n",
        "    options = Options()\n",
        "    options.add_argument(\"--start-maximized\")  # Start the browser maximized\n",
        "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
        "    return driver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ea4914",
      "metadata": {},
      "source": [
        "# Scraping Data from Jobsdb Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c5b078",
      "metadata": {
        "id": "27c5b078"
      },
      "outputs": [],
      "source": [
        "# Define the base URL and the page URL\n",
        "base_url = 'https://th.jobsdb.com'\n",
        "search_data = '/data-jobs'\n",
        "sec_page_url = '?page=2'\n",
        "\n",
        "# Fetch the webpage content\n",
        "page1 = requests.get(urljoin(base_url, search_data))\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(page1.content, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8958675d",
      "metadata": {
        "id": "8958675d"
      },
      "outputs": [],
      "source": [
        "box = soup.find('div',{'class':'_1decxdv0 _110qf3s4y _110qf3s4w'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238d64a7",
      "metadata": {
        "id": "238d64a7"
      },
      "outputs": [],
      "source": [
        "company_name = soup.find('a', {'data-automation': 'jobCompany'})\n",
        "position = soup.find('a', {'data-automation':'jobTitle'})\n",
        "location = soup.find('a', {'data-automation': 'jobLocation'})\n",
        "industry = soup.find('a',{'data-automation':'jobClassification'})\n",
        "date = soup.find('span',{'data-automation':'jobListingDate'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4aba37",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4371d03f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4371d03f",
        "outputId": "ca683a47-6aa1-4766-bded-a874dee31553"
      },
      "outputs": [],
      "source": [
        "company_name.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b025d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "40b025d9",
        "outputId": "acc3c84a-2699-4c66-969b-2f7b492023ad"
      },
      "outputs": [],
      "source": [
        "position.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d6eda8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "47d6eda8",
        "outputId": "55677ee4-a60e-4857-fa0f-bb3d0ad9b024"
      },
      "outputs": [],
      "source": [
        "location.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f66d7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "61f66d7f",
        "outputId": "82062bad-a69e-4503-a4f6-ffff2c7743f7"
      },
      "outputs": [],
      "source": [
        "industry.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94593386",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "94593386",
        "outputId": "3abbbe99-8301-47a2-c78c-31cc23683cb2"
      },
      "outputs": [],
      "source": [
        "date.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d89348d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d89348d",
        "outputId": "9b335cd1-8180-4ac8-8b41-2c5bde58f962"
      },
      "outputs": [],
      "source": [
        "print(company_name.text)\n",
        "print(position.text)\n",
        "print(location.text)\n",
        "print(industry.text)\n",
        "print(date.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4048dba7",
      "metadata": {
        "id": "4048dba7"
      },
      "outputs": [],
      "source": [
        "company_name_list = []\n",
        "position_list = []\n",
        "location_list = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddca0070",
      "metadata": {
        "id": "ddca0070"
      },
      "source": [
        "## Scrap one page to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e045f4f3",
      "metadata": {
        "id": "e045f4f3"
      },
      "outputs": [],
      "source": [
        "# Extract job titles\n",
        "job_title_elements = soup.find_all('a', {'data-automation':'jobTitle'})\n",
        "job_titles = [div.get_text(strip=True) for div in job_title_elements]\n",
        "\n",
        "# Extract company names\n",
        "company_name_elements = soup.find_all('a', {'data-automation': 'jobCompany'})\n",
        "company_names = [a.get_text(strip=True) for a in company_name_elements]\n",
        "\n",
        "# Extract Locations\n",
        "location_elements = soup.find_all('a', {'data-automation': 'jobLocation'})\n",
        "location = [a.get_text(strip=True) for a in location_elements]\n",
        "\n",
        "# Extract industry\n",
        "industry_elements = soup.find_all('a',{'data-automation':'jobClassification'})\n",
        "industry = [a.get_text(strip=True) for a in industry_elements]\n",
        "\n",
        "# Extract time\n",
        "time_elements = soup.find_all('span',{'data-automation':'jobListingDate'})\n",
        "time = [a.get_text(strip=True) for a in time_elements]\n",
        "\n",
        "# Combine job titles and company names into a list of tuples\n",
        "data = list(zip(job_titles, company_names, location, industry,time))\n",
        "\n",
        "# Create DataFrame\n",
        "data_jobs = pd.DataFrame(data, columns=['job_title', 'company_name','location','industry','time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bf4ba1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "41bf4ba1",
        "outputId": "557dc4b8-ba6f-4512-8660-badc727afc1b"
      },
      "outputs": [],
      "source": [
        "data_jobs.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa488f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1aa488f5",
        "outputId": "5552c08c-d019-4c1c-9417-99176d921d95"
      },
      "outputs": [],
      "source": [
        "all_jobs = []\n",
        "\n",
        "page_number = 1\n",
        "previous_content = \"\"\n",
        "\n",
        "while True:\n",
        "    url = f\"https://th.jobsdb.com/data-jobs?page={page_number}\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to retrieve page\")\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract job titles\n",
        "    job_title_elements = soup.find_all('a', {'data-automation':'jobTitle'})\n",
        "    job_titles = [div.get_text(strip=True) for div in job_title_elements]\n",
        "\n",
        "    # Extract company names\n",
        "    company_name_elements = soup.find_all('a', {'data-automation': 'jobCompany'})\n",
        "    company_names = [a.get_text(strip=True) for a in company_name_elements]\n",
        "\n",
        "    # Extract locations\n",
        "    location_elements = soup.find_all('a', {'data-automation': 'jobLocation'})\n",
        "    locations = [a.get_text(strip=True) for a in location_elements]\n",
        "\n",
        "    # Extract industry\n",
        "    industry_elements = soup.find_all('a',{'data-automation':'jobClassification'})\n",
        "    industries = [a.get_text(strip=True) for a in industry_elements]\n",
        "\n",
        "    # Extract time (job posting date)\n",
        "    time_elements = soup.find_all('span',{'data-automation':'jobListingDate'})\n",
        "    times = [a.get_text(strip=True) for a in time_elements]\n",
        "\n",
        "    # Check if extraction was successful\n",
        "    if len(job_titles) == 0 or len(company_names) == 0 or len(locations) == 0 or len(industries) == 0 or len(times) == 0:\n",
        "        print(f\"No new jobs found on page {page_number}, stopping.\")\n",
        "        break\n",
        "        \n",
        "    page_data = list(zip(job_titles, company_names, locations, industries, times))\n",
        "    all_jobs.extend(page_data)\n",
        "\n",
        "    # Compare content to determine if the page is the same\n",
        "    current_content = \"\".join(job_titles)\n",
        "    if current_content == previous_content:\n",
        "        print(f\"No new content found on page {page_number}, stopping the loop.\")\n",
        "        break\n",
        "\n",
        "    # Success Message\n",
        "    print(f\"Successfully scraped page {page_number}\")\n",
        "\n",
        "    previous_content = current_content\n",
        "    page_number += 1\n",
        "\n",
        "# Scraped dataframe name 'jobsdb_data'\n",
        "jobsdb_data = pd.DataFrame(all_jobs, columns=['job_title', 'company_name', 'location', 'industry', 'time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd5311f",
      "metadata": {
        "id": "1fd5311f",
        "outputId": "d053d018-17de-4914-999b-6c030d5fd877"
      },
      "outputs": [],
      "source": [
        "jobsdb_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425dac07",
      "metadata": {
        "id": "425dac07",
        "outputId": "fbb59079-2d89-4aed-b3f3-5647ca49aa65"
      },
      "outputs": [],
      "source": [
        "jobsdb_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca214cd",
      "metadata": {
        "id": "5ca214cd",
        "outputId": "4136bbb6-f92b-4cb8-ebfa-ad556f4ad33d"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['company_name'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2cd669",
      "metadata": {
        "id": "9d2cd669",
        "outputId": "02dd7c68-e1ed-4c3d-d675-8499d035974a"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['location'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f85326",
      "metadata": {
        "id": "81f85326",
        "outputId": "de0d6c80-0053-41f7-80da-65b83a1e909b"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['location'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676b963c",
      "metadata": {
        "id": "676b963c",
        "outputId": "751e8db0-8505-46d1-ffa9-13da85c7cf97"
      },
      "outputs": [],
      "source": [
        "jobsdb_data['location'].unique().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c82d16",
      "metadata": {
        "id": "81c82d16"
      },
      "source": [
        "## Jobtopgun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27be6372",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobtopgun_data_1st = 'https://www.jobtopgun.com/en/jobs?keywords=data'\n",
        "jobtopgun_data_morepages = '&page=2'\n",
        "jobtopgun_data_secondp = jobtopgun_data_1st + jobtopgun_data_morepages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86445d43",
      "metadata": {},
      "outputs": [],
      "source": [
        "driver_jobtopgun = webdriver.Chrome()  \n",
        "jobtopgun_jobs_data = []\n",
        "\n",
        "# Starting page number\n",
        "page_number = 1\n",
        "\n",
        "while True:\n",
        "    # Construct URL with the current page number\n",
        "    url = f'https://www.jobtopgun.com/en/jobs?keywords=data&page={page_number}'\n",
        "    print(f\"Navigating to jobtopgun 'data' search page number: {page_number}\")\n",
        "    \n",
        "    try:\n",
        "        # Navigate to the webpage\n",
        "        driver_jobtopgun.get(url)\n",
        "        wait = WebDriverWait(driver_jobtopgun, 10)\n",
        "        original_window = driver_jobtopgun.current_window_handle  # Hold Current windows\n",
        "\n",
        "        jobtopgun_data_firstpage = []\n",
        "        i = 1  # Start with the first job listing\n",
        "\n",
        "        while True:\n",
        "            xpath = f'//*[@id=\"scrollable-job-cards-container\"]/a[{i}]/div[1]'\n",
        "            try:\n",
        "                # Wait for the element to be clickable\n",
        "                element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
        "                element.click()\n",
        "\n",
        "                # Wait for the new window/tab to open and switch to it\n",
        "                wait.until(EC.number_of_windows_to_be(2))\n",
        "                new_window = [window for window in driver_jobtopgun.window_handles if window != original_window][0]\n",
        "                driver_jobtopgun.switch_to.window(new_window)\n",
        "\n",
        "                # Scrape data from the job detail page\n",
        "                try:\n",
        "                    # Details to scrape data\n",
        "                    job_title = driver_jobtopgun.find_element(By.XPATH, '//h1[@class=\"font-medium text-sub-primary text-lg\"]').text\n",
        "                    company_name = driver_jobtopgun.find_element(By.XPATH, '//span[@class=\"flex-1 font-medium text-lg\"]').text\n",
        "                    industry = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[1]/div/div[1]/div[1]/section/div[1]/span').text\n",
        "                    posted_time = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[1]/div/div[1]/div[1]/section/div/span').text\n",
        "                    experience = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[2]/span').text\n",
        "                    salary = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[2]/span').text\n",
        "                    education = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[4]/span').text\n",
        "                    location = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[1]/div/div[5]/span').text\n",
        "                    responsibility = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[2]/div').text\n",
        "                    requirements = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[3]').text\n",
        "                    welfare_and_benefits = driver_jobtopgun.find_element(By.XPATH, '//*[@id=\"job-details\"]/div[2]/section[4]').text\n",
        "                    \n",
        "                    job_info = {\n",
        "                        \"job_title\": job_title,\n",
        "                        \"company_name\": company_name,\n",
        "                        \"industry\": industry,\n",
        "                        \"job_url\": driver_jobtopgun.current_url,\n",
        "                        \"posted_time\": posted_time,\n",
        "                        \"experience\": experience,\n",
        "                        \"salary\": salary,\n",
        "                        \"education\": education,\n",
        "                        \"location\": location,\n",
        "                        \"responsibility\": responsibility,\n",
        "                        \"requirements\": requirements,\n",
        "                        \"welfare_and_benefits\": welfare_and_benefits\n",
        "                    }\n",
        "                    jobtopgun_data_firstpage.append(job_info)\n",
        "                    print(f\"Scraped data for job [{i}]: {job_info}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to scrape data for job [{i}]: {e}\")\n",
        "                \n",
        "                driver_jobtopgun.close()\n",
        "                driver_jobtopgun.switch_to.window(original_window)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to handle element a[{i}]: {e}\")\n",
        "                break  # Exit the loop if element is not found or not clickable\n",
        "\n",
        "            i += 1  # Move to the next job listing\n",
        "\n",
        "        # If no jobs are found, assume there are no more pages to scrape\n",
        "        if not jobtopgun_data_firstpage:\n",
        "            print(f\"No data found on page {page_number}. Stopping.\")\n",
        "            break\n",
        "\n",
        "        # Append the current page's data to the overall data list\n",
        "        jobtopgun_jobs_data.extend(jobtopgun_data_firstpage)\n",
        "\n",
        "        # Increment page number to move to the next page\n",
        "        page_number += 1\n",
        "\n",
        "    except Exception as main_exception:\n",
        "        print(f\"Error while navigating to page {page_number}: {main_exception}\")\n",
        "        break\n",
        "\n",
        "driver_jobtopgun.quit()\n",
        "\n",
        "print(f\"Scraping complete. Total jobs scraped: {len(jobtopgun_jobs_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea92ad32",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobtopgun_jobs_data = pd.DataFrame(jobtopgun_jobs_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317f3e99",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobtopgun_jobs_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b749b78a",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d8b31e54",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e9dce255",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "756e5c95",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "53f2978a",
      "metadata": {},
      "source": [
        "## Job Bkk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "562bee2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "search_word = 'data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "beb6d21b",
      "metadata": {},
      "outputs": [],
      "source": [
        "driver_jobbkk = webdriver.Chrome()  \n",
        "jobbkk_jobs_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "81281287",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'job_title': 'Data Engineer รับสมัครด่วน', 'company_name': 'บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด', 'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที', 'salary': 'เงินเดือน(บาท) : 25,000 - 40,000', 'fulltime': 'รูปแบบงาน : งานประจำ', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)', 'workday': 'วันทำงาน : จันทร์-ศุกร์', 'dayoff': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'workhour': 'เวลาทำงาน : 09:00 - 18:00', 'responsibility': 'รับผิดชอบงาน Data Integration, Data Pipeline Management\\nออกแบบ Data Architecture ติดตั้ง Big Data Platform และเครื่องมือที่เกี่ยวข้อง\\nออกแบบโครงสร้างการจัดเก็บและแนวทางการจัดเก็บข้อมูลบน Data Platform\\nศึกษาและค้นคว้าเทคโนโลยีที่เหมาะสมเพื่อพัฒนาสินค้าของเราให้มีคุณภาพที่ดีขึ้น และพัฒนาผลิตภัณฑ์ให้เป็นไปตามเป้าหมายของบริษัท', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 26 - 35', 'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป', 'experience': 'ประสบการณ์(ปี) : 3 - 5', 'job_requirement': 'มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\nเชี่ยวชาญ SQL, NoSQL และเขียน Python ได้\\nหากเคยมีประสบการณ์เหล่านี้จะพิจารณาพิเศษ ได้แก่ ETL Tools, Airflow, NiFi, Streaming Real Time Data, Kafka\\nใช้ Linux Command, Linux Container ได้\\nหากมีประสบการณ์ติดตั้งหรือใช้งาน Hadoop, Hive, MongoDB, Kafka, Elasticsearch อย่างใดอย่างหนึ่งจะพิจารณาเป็นพิเศษ\\nชอบเรียนรู้ และเรียนรู้ทักษะใหม่ๆได้เร็ว ชอบศึกษา และแบ่งปันความรู้\\nมีทัศนคติในการทำงานในองค์กรที่ดี รักในงานที่ทำ มีวินัย และความรับผิดชอบสูง', 'job_requirement2': 'ยินดีรับนักศึกษาจบใหม่', 'welfare_and_benefits': 'ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภาพ\\nเงินโบนัสตามผลงาน\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits2': 'สวัสดิการ\\n- Birthday Party\\n- วันหยุดพักผ่อน 10 วัน*\\n- ลากิจ\\n- ฝึกอบรม\\n- ท่องเที่ยวประจำปี\\n- ตรวจสุขภาพ\\n- กองทุนสำรองเลี้ยงชีพ*\\n- Incentive ตามผลงาน, ตามเงื่อนไขบริษัทฯ\\n- เงินช่วยเหลือต่างๆ ตามเงื่อนไขบริษัทฯ', 'company_contact': 'ชื่อผู้ติดต่อ : ศิวกรณ์ โนรันต์\\nเบอร์ผู้ติดต่อ : 022454942\\nอีเมล : siwakorn@softnix.co.th', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/180396/1270026'}\n",
            "Done scraping\n"
          ]
        }
      ],
      "source": [
        "# WebDriver\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "wait = WebDriverWait(driver_jobbkk, 10)  \n",
        "\n",
        "try:\n",
        "    # Open the main URL\n",
        "    driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "\n",
        "    # Click the element to open a new tab\n",
        "    element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/section[7]/article/section/div[1]/div[6]/div/div[3]/div/ul/li[3]/a')))\n",
        "    driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "    # Switch to the new tab\n",
        "    WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "    original_window = driver_jobbkk.current_window_handle\n",
        "    new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "    driver_jobbkk.switch_to.window(new_window)\n",
        "    \n",
        "    # Get page source and parse it with BeautifulSoup\n",
        "    page_source = driver_jobbkk.page_source\n",
        "    soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "    # Scrape data from the new tab\n",
        "    try:\n",
        "        job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "        company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text\n",
        "        industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "        salary = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[7]').text\n",
        "        fulltime = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[4]').text\n",
        "        location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "        work_day = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[8]').text\n",
        "        dayoff = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[9]').text\n",
        "        workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "        responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "        gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "        age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "        education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "        experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "        job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "        job_requirement2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[7]/div').text\n",
        "        welfare_and_benefits = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[8]/div').text\n",
        "        welfare_and_benefits2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[9]/div').text\n",
        "        company_contact = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[10]/div').text\n",
        "        job_url = driver_jobbkk.current_url\n",
        "        \n",
        "        jobbkk_info = {\n",
        "            'job_title': job_title,\n",
        "            'company_name': company_name,\n",
        "            'industry': industry,\n",
        "            'salary': salary,\n",
        "            'fulltime': fulltime,\n",
        "            'location': location,\n",
        "            'workday': work_day,\n",
        "            'dayoff': dayoff,\n",
        "            'workhour': workhour,\n",
        "            'responsibility': responsibility,\n",
        "            'gender': gender,\n",
        "            'age': age,\n",
        "            'education': education,\n",
        "            'experience': experience,\n",
        "            'job_requirement': job_requirement,\n",
        "            'job_requirement2': job_requirement2,\n",
        "            'welfare_and_benefits': welfare_and_benefits,\n",
        "            'welfare_and_benefits2': welfare_and_benefits2,\n",
        "            'company_contact': company_contact,\n",
        "            'job_url': job_url\n",
        "        }\n",
        "        print(jobbkk_info)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping data: {e}\")\n",
        "\n",
        "    # Close the new tab and switch back \n",
        "    driver_jobbkk.close()\n",
        "    driver_jobbkk.switch_to.window(original_window)\n",
        "\n",
        "finally:\n",
        "    print('Done scraping')\n",
        "    driver_jobbkk.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86cca9e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b0ae339",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobbkk_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ec9a3507",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'job_title': 'Data Engineer รับสมัครด่วน', 'company_name': 'บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด', 'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที', 'salary': 'เงินเดือน(บาท) : 25,000 - 40,000', 'fulltime': 'รูปแบบงาน : งานประจำ', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)', 'workday': 'วันทำงาน : จันทร์-ศุกร์', 'dayoff': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'workhour': 'เวลาทำงาน : 09:00 - 18:00', 'responsibility': 'รับผิดชอบงาน Data Integration, Data Pipeline Management\\nออกแบบ Data Architecture ติดตั้ง Big Data Platform และเครื่องมือที่เกี่ยวข้อง\\nออกแบบโครงสร้างการจัดเก็บและแนวทางการจัดเก็บข้อมูลบน Data Platform\\nศึกษาและค้นคว้าเทคโนโลยีที่เหมาะสมเพื่อพัฒนาสินค้าของเราให้มีคุณภาพที่ดีขึ้น และพัฒนาผลิตภัณฑ์ให้เป็นไปตามเป้าหมายของบริษัท', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 26 - 35', 'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป', 'experience': 'ประสบการณ์(ปี) : 3 - 5', 'job_requirement': 'มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\nเชี่ยวชาญ SQL, NoSQL และเขียน Python ได้\\nหากเคยมีประสบการณ์เหล่านี้จะพิจารณาพิเศษ ได้แก่ ETL Tools, Airflow, NiFi, Streaming Real Time Data, Kafka\\nใช้ Linux Command, Linux Container ได้\\nหากมีประสบการณ์ติดตั้งหรือใช้งาน Hadoop, Hive, MongoDB, Kafka, Elasticsearch อย่างใดอย่างหนึ่งจะพิจารณาเป็นพิเศษ\\nชอบเรียนรู้ และเรียนรู้ทักษะใหม่ๆได้เร็ว ชอบศึกษา และแบ่งปันความรู้\\nมีทัศนคติในการทำงานในองค์กรที่ดี รักในงานที่ทำ มีวินัย และความรับผิดชอบสูง', 'job_requirement2': 'ยินดีรับนักศึกษาจบใหม่', 'welfare_and_benefits': 'ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภาพ\\nเงินโบนัสตามผลงาน\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits2': 'สวัสดิการ\\n- Birthday Party\\n- วันหยุดพักผ่อน 10 วัน*\\n- ลากิจ\\n- ฝึกอบรม\\n- ท่องเที่ยวประจำปี\\n- ตรวจสุขภาพ\\n- กองทุนสำรองเลี้ยงชีพ*\\n- Incentive ตามผลงาน, ตามเงื่อนไขบริษัทฯ\\n- เงินช่วยเหลือต่างๆ ตามเงื่อนไขบริษัทฯ', 'company_contact': 'ชื่อผู้ติดต่อ : ศิวกรณ์ โนรันต์\\nเบอร์ผู้ติดต่อ : 022454942\\nอีเมล : siwakorn@softnix.co.th', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/180396/1270026'}\n",
            "{'job_title': 'Data Engineer รับสมัครด่วน', 'company_name': 'บริษัท เอพพิค คอนซัลติ้ง จำกัด', 'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที', 'salary': 'วันทำงาน : จันทร์-ศุกร์', 'fulltime': 'ระดับตำแหน่งงาน : เจ้าหน้าที่', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เขตพญาไท,เขตห้วยขวาง)', 'workday': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'dayoff': 'เวลาทำงาน : 08:30 - 17:30', 'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ', 'responsibility': 'Big Data technology, Hadoop Cloudera Hadoop, Cloudera CDSW, Cloud MS Azure\\nExperience using data frameworks, Hadoop Platform, Spark for big data processing and Kafka.\\nProficient in programming languages, Python for data engineering.\\nKnowledge and skills in using Cloudera, SQL.', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 23 - 35', 'education': 'ระดับการศึกษา : ปริญญาตรี - ปริญญาโท', 'experience': 'ประสบการณ์(ปี) : 3 - 10', 'job_requirement': 'Excellent with database or data warehouse or ETL tools (Extract Transform and Load) technique and framework.\\nAbility to design the shell script. Understanding of big data architecture.\\nAbility to work with Data Scientist in Advanced Analytics for preparing or discovering business insights on focus the business strategies.\\nSoft skill in analytical, decision making and communication skills\\nSkills & Experiences: At least 3 years’ experience in BigData technology, BI/DWH ETL developmentdata analyst and system development.\\nHave an experience of unstructured data for Business Intelligence or computer science would be advantage.\\nTechnical skill in Oracle, SQL, UNIX and Shell Script, BI Reporting Tool, R Programming, Python, Hadoop, Excel, etc.\\nFamiliarity with ETL tools, BI Tools and data modeling.\\nBasic understanding of database concepts and SQL.', 'job_requirement2': 'ทำงานสัปดาห์ละ 5 วัน\\nมีเวลาการทำงานที่ยืดหยุ่น\\nประกันชีวิต\\nประกันสุขภาพ\\nค่าทำงานล่วงเวลา\\nเงินโบนัสตามผลงาน\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits': 'ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\nเบอร์ผู้ติดต่อ : 063-665-1656\\nอีเมล : suthatdao.p@epic-consulting.net', 'welfare_and_benefits2': '408/48 Phaholyothin Place 11th Fl., แขวงพญาไท เขตพญาไท จังหวัดกรุงเทพมหานคร 10400 ประเทศไทย', 'company_contact': 'ไม่มี\\n\\nหมอชิต สะพานควาย สนามเป้า อนุสาวรีย์ชัยสมรภูมิ\\n\\nพระราม 9 ศูนย์วัฒนธรรมแห่งประเทศไทย\\n\\nไม่มี\\n\\nไม่มี', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/184598/1151675'}\n",
            "{'job_title': 'Data Engineer รับสมัครด่วน', 'company_name': 'R Systems Consulting Services (Thailand) Co., Ltd.', 'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที', 'salary': 'วันทำงาน : ไม่ระบุ', 'fulltime': 'ระดับตำแหน่งงาน : เจ้าหน้าที่', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)', 'workday': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'dayoff': 'เวลาทำงาน : 08:30 - 17:30', 'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ', 'responsibility': '- Data Engineer, Data Information - Programming in SQL, UNIX and Shell Script, Python, R Programming etc. - Skills: Talend, ETL, Hadoop, AWS, Cloud', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 22 - 55', 'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป', 'experience': 'ประสบการณ์(ปี) : 2 - 7', 'job_requirement': 'ไม่ระบุ', 'job_requirement2': 'ทำงานสัปดาห์ละ 5 วัน\\nประกันสุขภาพ\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits': 'ชื่อผู้ติดต่อ : Arpaporn Mekloy\\nเบอร์ผู้ติดต่อ : +66850555454\\nอีเมล : resourcing-thailand@ecnet.com', 'welfare_and_benefits2': '2/3 หมู่14 อาคารบางนาทาวเวอร์ เอ ถนนบางนา-ตราด ตำบลบางแก้ว อำเภอบางพลี จังหวัดสมุทรปราการ 10540 ประเทศไทย', 'company_contact': 'ไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/215463/1194142'}\n",
            "{'job_title': 'Data Business รับสมัครด่วน', 'company_name': 'บริษัท ไวท์ฟร้อนท์ จำกัด', 'industry': 'ประเภทธุรกิจ : ธุรกิจอื่นๆ', 'salary': 'วันทำงาน : จันทร์-เสาร์', 'fulltime': 'ระดับตำแหน่งงาน : เจ้าหน้าที่', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางนา,เขตประเวศ,เขตพระโขนง,เขตสวนหลวง)', 'workday': 'วันหยุด : วันอาทิตย์', 'dayoff': 'เวลาทำงาน : 08:30 - 17:30', 'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ', 'responsibility': 'กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมูล\\nรวบรวมข้อมูลที่จะใช้ในการวิเคราะห์\\nการจัดหาข้อมูลที่ขาดหายไป\\nกำหนด ตั้งค่า โครงสร้างพื้นฐาน\\nสร้าง Insight จากข้อมูล และระบุแนวโน้มที่เกิดขึ้นได้\\nสร้าง รายงาน สร้าง Dashboard / Automated Dashboard สำหรับผู้บริหาร และ ทีมงาน\\nมีความเข้าใจในธุรกิจ และวิเคราะห์ข้อมูลเพื่อตอบโจทย์ในทางธุรกิจได้', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 22 ปีขึ้นไป', 'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป', 'experience': 'ประสบการณ์(ปี) : 2ปีขึ้นไป', 'job_requirement': 'มีทักษะด้านคณิตศาสตร์ และตัวเลข\\nเข้าใจเรื่องสถิติ มีประสบการณ์ในการสรุปผล เช่น\\nสามารถใช้งานเครื่องมือในการสร้างรายงาน สร้างDashboard\\nมีทักษะการวิเคราะห์ข้อมูลเชิงลึก เช่น การสรุปผล การดูแนวโน้ม ดู Pattern ข้อมูล\\nมีทักษะการนำเสนอ สามารถในการอธิบายโดยสามารถนำความคิดที่ซับซ้อนมาทำให้เป็นรูปแบบที่เข้าใจง่าย\\nมีทักษะการแก้ปัญหา\\nมีทักษะด้านการสื่อสาร มนุษสัมพันธ์ที่ดีต่อเพื่อนร่วมงาน', 'job_requirement2': 'ยินดีรับนักศึกษาจบใหม่', 'welfare_and_benefits': 'ค่าทำงานล่วงเวลา\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits2': 'ชื่อผู้ติดต่อ : คุณคิม\\nเบอร์ผู้ติดต่อ : 06155595551\\nอีเมล : yuiwhitefront@gmail.com', 'company_contact': '101/12 อาคาร SPACE101 แขวงบางจาก เขตพระโขนง จังหวัดกรุงเทพมหานคร 10260 ประเทศไทย', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/202470/1184164'}\n",
            "{'job_title': 'Data Analyst รับสมัครด่วน', 'company_name': 'บริษัท พีซีซี อินเทอร์เนชันนัล จำกัด', 'industry': 'ประเภทธุรกิจ : บริการ', 'salary': 'วันทำงาน : ไม่ระบุ', 'fulltime': 'ระดับตำแหน่งงาน : เจ้าหน้าที่', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตยานนาวา)', 'workday': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'dayoff': 'เวลาทำงาน : 08:30 - 17:30', 'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ', 'responsibility': '1. ดูแลจัดการข้อมูลและรักษา Master Data ให้พร้อมใช้งาน 2. พัฒนา ออกแบบ และสร้างรายงานให้เหมาะสมกับข้อมูล และลักษณะของโปรเจคที่ได้รับมอบหมาย 3. รวบรวม ติดตาม จัดเก็บ และวิเคราะห์ข้อมูลการดำเนินงานประจำสัปดาห์/เดือน เพื่อนำมาวิเคราะห์ 4. วิเคราะห์ข้อมูลเชิงลึกของลูกค้าเป็น Dashboard และ Report เพื่อสนับสนุนการใช้งานทางธุรกิจ 5. ทำงานร่วมกับทีมเพื่อพัฒนาระบบการวิเคราะห์ข้อมูลที่ใช้ในการกำหนดกลยุทธ์ 6. ดูแล Support งานอื่นๆ ที่เกี่ยวข้อง 7. ทำงานจันทร์ - ศุกร์ เวลา 08.30-17.30 น. 8. สถานที่ทำงาน อาคาร MS Siam พระราม 3', 'gender': 'เพศ : ชาย , หญิง', 'age': 'อายุ(ปี) : 23 ปีขึ้นไป', 'education': 'ระดับการศึกษา : ปริญญาตรี ขึ้นไป', 'experience': 'ประสบการณ์(ปี) : 1ปีขึ้นไป', 'job_requirement': '1. วุฒิปริญญาตรี สาขาบัญชี / สาขาวิทยาศาสตร์ข้อมูลและการวิเคราะห์ / สถิติประยุกต์ หรือสาขาที่เกี่ยวข้อง 2. มีทักษะด้านการใช้โปรแกรมคอมพิวเตอร์อย่างดี Microsoft Office (Word, Excel Advance, PowerPoint) หรือ SQL Queryได้ 3. มีความสามารถในการสื่อสาร การเจรจา มีไหวพริบ สามารถแก้ไขปัญหาเฉพาะหน้าได้เป็นอย่างดี และมี Growth Mindset 4. มีประสบการณ์งานด้านวิเคราะห์ข้อมูลมากกว่า 1 ปีขึ้นไป 5. สามารถสร้างรายงานผ่าน Power BI ได้ (จะพิจารณาเป็นพิเศษ)', 'job_requirement2': 'ทำงานสัปดาห์ละ 5 วัน\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits': 'ชื่อผู้ติดต่อ : ชุติญา ไสยพร\\nเบอร์ผู้ติดต่อ : 099-3363339\\nอีเมล : recruitment@pccinter.com', 'welfare_and_benefits2': '1023 อาคารเอ็มเอส สยาม ชั้น 9 ถ.พระราม 3 แขวงช่องนนทรี เขตยานนาวา จังหวัดกรุงเทพมหานคร 10120 ประเทศไทย', 'company_contact': '195,205\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/20745/1242306'}\n",
            "{'job_title': 'Data Modeler รับสมัครด่วน', 'company_name': 'บริษัท เอพพิค คอนซัลติ้ง จำกัด', 'industry': 'ประเภทธุรกิจ : คอมพิวเตอร์-ไอที', 'salary': 'วันทำงาน : จันทร์-ศุกร์', 'fulltime': 'ระดับตำแหน่งงาน : เจ้าหน้าที่', 'location': 'สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เขตดินแดง,เขตพญาไท,เขตห้วยขวาง)', 'workday': 'วันหยุด : วันเสาร์, วันอาทิตย์', 'dayoff': 'เวลาทำงาน : 08:30 - 17:30', 'workhour': 'เวลาทำงานอื่นๆ : ไม่ระบุ', 'responsibility': 'Education - Minimum degree and major required : (i.e. High Vocational, Bachelor, Master, Ph.D.)\\nBachelor Degree in IT Related\\nExperience - Minimum work experiences required : (specified field/area and no. of years)\\nIT Application Development & Support at least 5 years.\\nExperience on DWH Project and/or Data Model Design are preferable.\\nSkill & Knowledge – Specific skills or certificates required :\\nDWH Design, Reporting Tools, Oracle DB, Unix Shellscirpt, PL/SQL, Datamodel Development Tools (Erwin, Rational Rose, etc.)', 'gender': 'เพศ : ไม่ระบุ', 'age': 'อายุ(ปี) : 23 - 35', 'education': 'ระดับการศึกษา : ปริญญาตรี - ปริญญาโท', 'experience': 'ประสบการณ์(ปี) : 3 - 10', 'job_requirement': 'Analysis business requirements & data sources and design DB model on DWH\\nStructuring, and maintaining data model, data dictionary for DWH\\nPerform impact analysis whenever there is any change or new projects on data sources for DWH\\nDeliver Data Model to development & reporting team, arrange session for verification and validation design model\\nProblem Analysis, coordinate and work with reporting and/or development team for data quality assurance and for long term solution to reduce issues related to data quality and/or program bugs', 'job_requirement2': 'ทำงานสัปดาห์ละ 5 วัน\\nมีเวลาการทำงานที่ยืดหยุ่น\\nประกันชีวิต\\nประกันสุขภาพ\\nค่าทำงานล่วงเวลา\\nเงินโบนัสตามผลงาน\\nทำงานที่บ้าน\\nประกันสังคม\\nตามข้อตกลงของบริษัท', 'welfare_and_benefits': 'ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\nเบอร์ผู้ติดต่อ : 063-665-1656\\nอีเมล : suthatdao.p@epic-consulting.net', 'welfare_and_benefits2': '408/48 Phaholyothin Place 11th Fl., Phaholyothin Road, แขวงสามเสนใน เขตพญาไท จังหวัดกรุงเทพมหานคร 10400 ประเทศไทย', 'company_contact': 'ไม่มี\\n\\nสะพานควาย อารีย์ สนามเป้า\\n\\nพระราม 9 สุทธิสาร สวนจตุจักร\\n\\nไม่มี\\n\\nจตุจักร', 'job_url': 'https://www.jobbkk.com/jobs/detailurgent/184598/1095503'}\n",
            "Error scraping data: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p\"}\n",
            "  (Session info: chrome=128.0.6613.115); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00007FF7EBBCB5D2+29090]\n",
            "\t(No symbol) [0x00007FF7EBB3E689]\n",
            "\t(No symbol) [0x00007FF7EB9FB1CA]\n",
            "\t(No symbol) [0x00007FF7EBA4EFD7]\n",
            "\t(No symbol) [0x00007FF7EBA4F22C]\n",
            "\t(No symbol) [0x00007FF7EBA997F7]\n",
            "\t(No symbol) [0x00007FF7EBA7672F]\n",
            "\t(No symbol) [0x00007FF7EBA965D9]\n",
            "\t(No symbol) [0x00007FF7EBA76493]\n",
            "\t(No symbol) [0x00007FF7EBA409B1]\n",
            "\t(No symbol) [0x00007FF7EBA41B11]\n",
            "\tGetHandleVerifier [0x00007FF7EBEE8C5D+3295277]\n",
            "\tGetHandleVerifier [0x00007FF7EBF34843+3605523]\n",
            "\tGetHandleVerifier [0x00007FF7EBF2A707+3564247]\n",
            "\tGetHandleVerifier [0x00007FF7EBC86EB6+797318]\n",
            "\t(No symbol) [0x00007FF7EBB4980F]\n",
            "\t(No symbol) [0x00007FF7EBB453F4]\n",
            "\t(No symbol) [0x00007FF7EBB45580]\n",
            "\t(No symbol) [0x00007FF7EBB34A1F]\n",
            "\tBaseThreadInitThunk [0x00007FF9F95C7374+20]\n",
            "\tRtlUserThreadStart [0x00007FF9FA27CC91+33]\n",
            "\n",
            "Done scraping\n"
          ]
        }
      ],
      "source": [
        "\n",
        "driver_jobbkk = webdriver.Chrome()\n",
        "wait = WebDriverWait(driver_jobbkk, 10)  # Adjust the timeout as needed\n",
        "\n",
        "all_jobs = []\n",
        "try:\n",
        "    # Open the main URL\n",
        "    driver_jobbkk.get(\"https://www.jobbkk.com/jobs/lists/1/%E0%B8%AB%E0%B8%B2%E0%B8%87%E0%B8%B2%E0%B8%99,data,%E0%B8%97%E0%B8%B8%E0%B8%81%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94,%E0%B8%97%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A1%E0%B8%94.html?keyword_type=3&member_user_id=1\")\n",
        "    \n",
        "    # Loop through elements starting from index 6, with a step of 2\n",
        "    for x in range(6, 20, 2):\n",
        "        try:\n",
        "            xpath = f'/html/body/section[7]/article/section/div[1]/div[{x}]/div/div[3]/div/ul/li[3]/a'\n",
        "            element_to_open_new_tab = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
        "            driver_jobbkk.execute_script(\"window.open(arguments[0].href);\", element_to_open_new_tab)\n",
        "\n",
        "            # Switch to the new tab\n",
        "            WebDriverWait(driver_jobbkk, 10).until(lambda d: len(d.window_handles) == 2)  # Wait for the new tab to open\n",
        "            original_window = driver_jobbkk.current_window_handle\n",
        "            new_window = [window for window in driver_jobbkk.window_handles if window != original_window][0]\n",
        "            driver_jobbkk.switch_to.window(new_window)\n",
        "\n",
        "            page_source = driver_jobbkk.page_source\n",
        "            soup_bkk = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "            # Scrape data from the new tab\n",
        "            try:\n",
        "                job_title = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[2]/p').text\n",
        "                company_name = soup_bkk.find('p', class_='textRed fontSubHead font-DB-HeaventRounded-Bold').text\n",
        "                industry = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[1]/div/div/p[2]').text \n",
        "                salary = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[7]').text\n",
        "                fulltime = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[4]').text\n",
        "                location = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[1]').text\n",
        "                work_day = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[8]').text\n",
        "                dayoff = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[9]').text\n",
        "                workhour = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/div[3]/p[10]').text\n",
        "                responsibility = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[4]/div').text\n",
        "                gender = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[1]').text\n",
        "                age = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[2]').text\n",
        "                education = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[3]').text\n",
        "                experience = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[5]/div/p[4]').text\n",
        "                job_requirement = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[6]/div').text\n",
        "                job_requirement2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[7]/div').text\n",
        "                welfare_and_benefits = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[8]/div').text\n",
        "                welfare_and_benefits2 = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[9]/div').text\n",
        "                company_contact = driver_jobbkk.find_element(By.XPATH, '/html/body/section[5]/article/div/article/section[2]/article[1]/div/section[10]/div').text\n",
        "                job_url = driver_jobbkk.current_url\n",
        "                \n",
        "                jobbkk_info = {\n",
        "                    'job_title': job_title,\n",
        "                    'company_name': company_name,\n",
        "                    'industry': industry,\n",
        "                    'salary': salary,\n",
        "                    'fulltime': fulltime,\n",
        "                    'location': location,\n",
        "                    'workday': work_day,\n",
        "                    'dayoff': dayoff,\n",
        "                    'workhour': workhour,\n",
        "                    'responsibility': responsibility,\n",
        "                    'gender': gender,\n",
        "                    'age': age,\n",
        "                    'education': education,\n",
        "                    'experience': experience,\n",
        "                    'job_requirement': job_requirement,\n",
        "                    'job_requirement2': job_requirement2,\n",
        "                    'welfare_and_benefits': welfare_and_benefits,\n",
        "                    'welfare_and_benefits2': welfare_and_benefits2,\n",
        "                    'company_contact': company_contact,\n",
        "                    'job_url': job_url\n",
        "                }\n",
        "                print(jobbkk_info)\n",
        "                all_jobs.append(jobbkk_info)\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping data: {e}\")\n",
        "            time.sleep(2)\n",
        "            # Close the new tab and switch back\n",
        "            driver_jobbkk.close()\n",
        "            driver_jobbkk.switch_to.window(original_window)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred for element with index {x}: {e}\")\n",
        "\n",
        "finally:\n",
        "    print('Done scraping')\n",
        "    driver_jobbkk.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f3ade1d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "jobbkk_job_data = pd.DataFrame(all_jobs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "98b717ce",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company_name</th>\n",
              "      <th>industry</th>\n",
              "      <th>salary</th>\n",
              "      <th>fulltime</th>\n",
              "      <th>location</th>\n",
              "      <th>workday</th>\n",
              "      <th>dayoff</th>\n",
              "      <th>workhour</th>\n",
              "      <th>responsibility</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>experience</th>\n",
              "      <th>job_requirement</th>\n",
              "      <th>job_requirement2</th>\n",
              "      <th>welfare_and_benefits</th>\n",
              "      <th>welfare_and_benefits2</th>\n",
              "      <th>company_contact</th>\n",
              "      <th>job_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Engineer รับสมัครด่วน</td>\n",
              "      <td>บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>เงินเดือน(บาท) : 25,000 - 40,000</td>\n",
              "      <td>รูปแบบงาน : งานประจำ</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)</td>\n",
              "      <td>วันทำงาน : จันทร์-ศุกร์</td>\n",
              "      <td>วันหยุด : วันเสาร์, วันอาทิตย์</td>\n",
              "      <td>เวลาทำงาน : 09:00 - 18:00</td>\n",
              "      <td>รับผิดชอบงาน Data Integration, Data Pipeline M...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 26 - 35</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 3 - 5</td>\n",
              "      <td>มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\n...</td>\n",
              "      <td>ยินดีรับนักศึกษาจบใหม่</td>\n",
              "      <td>ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภา...</td>\n",
              "      <td>สวัสดิการ\\n- Birthday Party\\n- วันหยุดพักผ่อน ...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : ศิวกรณ์ โนรันต์\\nเบอร์ผู้ติดต่...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/18039...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Engineer รับสมัครด่วน</td>\n",
              "      <td>บริษัท เอพพิค คอนซัลติ้ง จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>วันทำงาน : จันทร์-ศุกร์</td>\n",
              "      <td>ระดับตำแหน่งงาน : เจ้าหน้าที่</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...</td>\n",
              "      <td>วันหยุด : วันเสาร์, วันอาทิตย์</td>\n",
              "      <td>เวลาทำงาน : 08:30 - 17:30</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>Big Data technology, Hadoop Cloudera Hadoop, C...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 23 - 35</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี - ปริญญาโท</td>\n",
              "      <td>ประสบการณ์(ปี) : 3 - 10</td>\n",
              "      <td>Excellent with database or data warehouse or E...</td>\n",
              "      <td>ทำงานสัปดาห์ละ 5 วัน\\nมีเวลาการทำงานที่ยืดหยุ่...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\nเบอร์ผู้ติ...</td>\n",
              "      <td>408/48 Phaholyothin Place 11th Fl., แขวงพญาไท ...</td>\n",
              "      <td>ไม่มี\\n\\nหมอชิต สะพานควาย สนามเป้า อนุสาวรีย์ช...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/18459...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Engineer รับสมัครด่วน</td>\n",
              "      <td>R Systems Consulting Services (Thailand) Co., ...</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>วันทำงาน : ไม่ระบุ</td>\n",
              "      <td>ระดับตำแหน่งงาน : เจ้าหน้าที่</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)</td>\n",
              "      <td>วันหยุด : วันเสาร์, วันอาทิตย์</td>\n",
              "      <td>เวลาทำงาน : 08:30 - 17:30</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>- Data Engineer, Data Information - Programmin...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 22 - 55</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 2 - 7</td>\n",
              "      <td>ไม่ระบุ</td>\n",
              "      <td>ทำงานสัปดาห์ละ 5 วัน\\nประกันสุขภาพ\\nประกันสังค...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : Arpaporn Mekloy\\nเบอร์ผู้ติดต่...</td>\n",
              "      <td>2/3 หมู่14 อาคารบางนาทาวเวอร์ เอ ถนนบางนา-ตราด...</td>\n",
              "      <td>ไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/21546...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Business รับสมัครด่วน</td>\n",
              "      <td>บริษัท ไวท์ฟร้อนท์ จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : ธุรกิจอื่นๆ</td>\n",
              "      <td>วันทำงาน : จันทร์-เสาร์</td>\n",
              "      <td>ระดับตำแหน่งงาน : เจ้าหน้าที่</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางนา,เขต...</td>\n",
              "      <td>วันหยุด : วันอาทิตย์</td>\n",
              "      <td>เวลาทำงาน : 08:30 - 17:30</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมู...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 22 ปีขึ้นไป</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 2ปีขึ้นไป</td>\n",
              "      <td>มีทักษะด้านคณิตศาสตร์ และตัวเลข\\nเข้าใจเรื่องส...</td>\n",
              "      <td>ยินดีรับนักศึกษาจบใหม่</td>\n",
              "      <td>ค่าทำงานล่วงเวลา\\nประกันสังคม\\nตามข้อตกลงของบร...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : คุณคิม\\nเบอร์ผู้ติดต่อ : 06155...</td>\n",
              "      <td>101/12 อาคาร SPACE101 แขวงบางจาก เขตพระโขนง จั...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/20247...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Analyst รับสมัครด่วน</td>\n",
              "      <td>บริษัท พีซีซี อินเทอร์เนชันนัล จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : บริการ</td>\n",
              "      <td>วันทำงาน : ไม่ระบุ</td>\n",
              "      <td>ระดับตำแหน่งงาน : เจ้าหน้าที่</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตยานนาวา)</td>\n",
              "      <td>วันหยุด : วันเสาร์, วันอาทิตย์</td>\n",
              "      <td>เวลาทำงาน : 08:30 - 17:30</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>1. ดูแลจัดการข้อมูลและรักษา Master Data ให้พร้...</td>\n",
              "      <td>เพศ : ชาย , หญิง</td>\n",
              "      <td>อายุ(ปี) : 23 ปีขึ้นไป</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี ขึ้นไป</td>\n",
              "      <td>ประสบการณ์(ปี) : 1ปีขึ้นไป</td>\n",
              "      <td>1. วุฒิปริญญาตรี สาขาบัญชี / สาขาวิทยาศาสตร์ข้...</td>\n",
              "      <td>ทำงานสัปดาห์ละ 5 วัน\\nประกันสังคม\\nตามข้อตกลงข...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : ชุติญา ไสยพร\\nเบอร์ผู้ติดต่อ :...</td>\n",
              "      <td>1023 อาคารเอ็มเอส สยาม ชั้น 9 ถ.พระราม 3 แขวงช...</td>\n",
              "      <td>195,205\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/20745...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Modeler รับสมัครด่วน</td>\n",
              "      <td>บริษัท เอพพิค คอนซัลติ้ง จำกัด</td>\n",
              "      <td>ประเภทธุรกิจ : คอมพิวเตอร์-ไอที</td>\n",
              "      <td>วันทำงาน : จันทร์-ศุกร์</td>\n",
              "      <td>ระดับตำแหน่งงาน : เจ้าหน้าที่</td>\n",
              "      <td>สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...</td>\n",
              "      <td>วันหยุด : วันเสาร์, วันอาทิตย์</td>\n",
              "      <td>เวลาทำงาน : 08:30 - 17:30</td>\n",
              "      <td>เวลาทำงานอื่นๆ : ไม่ระบุ</td>\n",
              "      <td>Education - Minimum degree and major required ...</td>\n",
              "      <td>เพศ : ไม่ระบุ</td>\n",
              "      <td>อายุ(ปี) : 23 - 35</td>\n",
              "      <td>ระดับการศึกษา : ปริญญาตรี - ปริญญาโท</td>\n",
              "      <td>ประสบการณ์(ปี) : 3 - 10</td>\n",
              "      <td>Analysis business requirements &amp; data sources ...</td>\n",
              "      <td>ทำงานสัปดาห์ละ 5 วัน\\nมีเวลาการทำงานที่ยืดหยุ่...</td>\n",
              "      <td>ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\nเบอร์ผู้ติ...</td>\n",
              "      <td>408/48 Phaholyothin Place 11th Fl., Phaholyoth...</td>\n",
              "      <td>ไม่มี\\n\\nสะพานควาย อารีย์ สนามเป้า\\n\\nพระราม 9...</td>\n",
              "      <td>https://www.jobbkk.com/jobs/detailurgent/18459...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    job_title  \\\n",
              "0  Data Engineer รับสมัครด่วน   \n",
              "1  Data Engineer รับสมัครด่วน   \n",
              "2  Data Engineer รับสมัครด่วน   \n",
              "3  Data Business รับสมัครด่วน   \n",
              "4   Data Analyst รับสมัครด่วน   \n",
              "5   Data Modeler รับสมัครด่วน   \n",
              "\n",
              "                                        company_name  \\\n",
              "0                  บริษัท ซอฟท์นิกซ์ เทคโนโลยี จำกัด   \n",
              "1                     บริษัท เอพพิค คอนซัลติ้ง จำกัด   \n",
              "2  R Systems Consulting Services (Thailand) Co., ...   \n",
              "3                           บริษัท ไวท์ฟร้อนท์ จำกัด   \n",
              "4               บริษัท พีซีซี อินเทอร์เนชันนัล จำกัด   \n",
              "5                     บริษัท เอพพิค คอนซัลติ้ง จำกัด   \n",
              "\n",
              "                          industry                            salary  \\\n",
              "0  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที  เงินเดือน(บาท) : 25,000 - 40,000   \n",
              "1  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที           วันทำงาน : จันทร์-ศุกร์   \n",
              "2  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที                วันทำงาน : ไม่ระบุ   \n",
              "3       ประเภทธุรกิจ : ธุรกิจอื่นๆ           วันทำงาน : จันทร์-เสาร์   \n",
              "4            ประเภทธุรกิจ : บริการ                วันทำงาน : ไม่ระบุ   \n",
              "5  ประเภทธุรกิจ : คอมพิวเตอร์-ไอที           วันทำงาน : จันทร์-ศุกร์   \n",
              "\n",
              "                        fulltime  \\\n",
              "0           รูปแบบงาน : งานประจำ   \n",
              "1  ระดับตำแหน่งงาน : เจ้าหน้าที่   \n",
              "2  ระดับตำแหน่งงาน : เจ้าหน้าที่   \n",
              "3  ระดับตำแหน่งงาน : เจ้าหน้าที่   \n",
              "4  ระดับตำแหน่งงาน : เจ้าหน้าที่   \n",
              "5  ระดับตำแหน่งงาน : เจ้าหน้าที่   \n",
              "\n",
              "                                            location  \\\n",
              "0       สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตดินแดง)   \n",
              "1  สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...   \n",
              "2          สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(ทุกเขต)   \n",
              "3  สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตบางนา,เขต...   \n",
              "4      สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตยานนาวา)   \n",
              "5  สถานที่ปฏิบัติงาน : กรุงเทพมหานคร(เขตจตุจักร,เ...   \n",
              "\n",
              "                          workday                          dayoff  \\\n",
              "0         วันทำงาน : จันทร์-ศุกร์  วันหยุด : วันเสาร์, วันอาทิตย์   \n",
              "1  วันหยุด : วันเสาร์, วันอาทิตย์       เวลาทำงาน : 08:30 - 17:30   \n",
              "2  วันหยุด : วันเสาร์, วันอาทิตย์       เวลาทำงาน : 08:30 - 17:30   \n",
              "3            วันหยุด : วันอาทิตย์       เวลาทำงาน : 08:30 - 17:30   \n",
              "4  วันหยุด : วันเสาร์, วันอาทิตย์       เวลาทำงาน : 08:30 - 17:30   \n",
              "5  วันหยุด : วันเสาร์, วันอาทิตย์       เวลาทำงาน : 08:30 - 17:30   \n",
              "\n",
              "                    workhour  \\\n",
              "0  เวลาทำงาน : 09:00 - 18:00   \n",
              "1   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "2   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "3   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "4   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "5   เวลาทำงานอื่นๆ : ไม่ระบุ   \n",
              "\n",
              "                                      responsibility            gender  \\\n",
              "0  รับผิดชอบงาน Data Integration, Data Pipeline M...     เพศ : ไม่ระบุ   \n",
              "1  Big Data technology, Hadoop Cloudera Hadoop, C...     เพศ : ไม่ระบุ   \n",
              "2  - Data Engineer, Data Information - Programmin...     เพศ : ไม่ระบุ   \n",
              "3  กำหนด Data Sources เพื่อใช้ในการวิเคราะห์ข้อมู...     เพศ : ไม่ระบุ   \n",
              "4  1. ดูแลจัดการข้อมูลและรักษา Master Data ให้พร้...  เพศ : ชาย , หญิง   \n",
              "5  Education - Minimum degree and major required ...     เพศ : ไม่ระบุ   \n",
              "\n",
              "                      age                             education  \\\n",
              "0      อายุ(ปี) : 26 - 35      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "1      อายุ(ปี) : 23 - 35  ระดับการศึกษา : ปริญญาตรี - ปริญญาโท   \n",
              "2      อายุ(ปี) : 22 - 55      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "3  อายุ(ปี) : 22 ปีขึ้นไป      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "4  อายุ(ปี) : 23 ปีขึ้นไป      ระดับการศึกษา : ปริญญาตรี ขึ้นไป   \n",
              "5      อายุ(ปี) : 23 - 35  ระดับการศึกษา : ปริญญาตรี - ปริญญาโท   \n",
              "\n",
              "                   experience  \\\n",
              "0      ประสบการณ์(ปี) : 3 - 5   \n",
              "1     ประสบการณ์(ปี) : 3 - 10   \n",
              "2      ประสบการณ์(ปี) : 2 - 7   \n",
              "3  ประสบการณ์(ปี) : 2ปีขึ้นไป   \n",
              "4  ประสบการณ์(ปี) : 1ปีขึ้นไป   \n",
              "5     ประสบการณ์(ปี) : 3 - 10   \n",
              "\n",
              "                                     job_requirement  \\\n",
              "0  มีประสบการณ์ด้านการทำงาน Data Warehouse, ETL\\n...   \n",
              "1  Excellent with database or data warehouse or E...   \n",
              "2                                            ไม่ระบุ   \n",
              "3  มีทักษะด้านคณิตศาสตร์ และตัวเลข\\nเข้าใจเรื่องส...   \n",
              "4  1. วุฒิปริญญาตรี สาขาบัญชี / สาขาวิทยาศาสตร์ข้...   \n",
              "5  Analysis business requirements & data sources ...   \n",
              "\n",
              "                                    job_requirement2  \\\n",
              "0                             ยินดีรับนักศึกษาจบใหม่   \n",
              "1  ทำงานสัปดาห์ละ 5 วัน\\nมีเวลาการทำงานที่ยืดหยุ่...   \n",
              "2  ทำงานสัปดาห์ละ 5 วัน\\nประกันสุขภาพ\\nประกันสังค...   \n",
              "3                             ยินดีรับนักศึกษาจบใหม่   \n",
              "4  ทำงานสัปดาห์ละ 5 วัน\\nประกันสังคม\\nตามข้อตกลงข...   \n",
              "5  ทำงานสัปดาห์ละ 5 วัน\\nมีเวลาการทำงานที่ยืดหยุ่...   \n",
              "\n",
              "                                welfare_and_benefits  \\\n",
              "0  ทำงานสัปดาห์ละ 5 วัน\\nประกันชีวิต\\nประกันสุขภา...   \n",
              "1  ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\nเบอร์ผู้ติ...   \n",
              "2  ชื่อผู้ติดต่อ : Arpaporn Mekloy\\nเบอร์ผู้ติดต่...   \n",
              "3  ค่าทำงานล่วงเวลา\\nประกันสังคม\\nตามข้อตกลงของบร...   \n",
              "4  ชื่อผู้ติดต่อ : ชุติญา ไสยพร\\nเบอร์ผู้ติดต่อ :...   \n",
              "5  ชื่อผู้ติดต่อ : สุทัดดาว พงษ์พานิช\\nเบอร์ผู้ติ...   \n",
              "\n",
              "                               welfare_and_benefits2  \\\n",
              "0  สวัสดิการ\\n- Birthday Party\\n- วันหยุดพักผ่อน ...   \n",
              "1  408/48 Phaholyothin Place 11th Fl., แขวงพญาไท ...   \n",
              "2  2/3 หมู่14 อาคารบางนาทาวเวอร์ เอ ถนนบางนา-ตราด...   \n",
              "3  ชื่อผู้ติดต่อ : คุณคิม\\nเบอร์ผู้ติดต่อ : 06155...   \n",
              "4  1023 อาคารเอ็มเอส สยาม ชั้น 9 ถ.พระราม 3 แขวงช...   \n",
              "5  408/48 Phaholyothin Place 11th Fl., Phaholyoth...   \n",
              "\n",
              "                                     company_contact  \\\n",
              "0  ชื่อผู้ติดต่อ : ศิวกรณ์ โนรันต์\\nเบอร์ผู้ติดต่...   \n",
              "1  ไม่มี\\n\\nหมอชิต สะพานควาย สนามเป้า อนุสาวรีย์ช...   \n",
              "2          ไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี   \n",
              "3  101/12 อาคาร SPACE101 แขวงบางจาก เขตพระโขนง จั...   \n",
              "4        195,205\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี\\n\\nไม่มี   \n",
              "5  ไม่มี\\n\\nสะพานควาย อารีย์ สนามเป้า\\n\\nพระราม 9...   \n",
              "\n",
              "                                             job_url  \n",
              "0  https://www.jobbkk.com/jobs/detailurgent/18039...  \n",
              "1  https://www.jobbkk.com/jobs/detailurgent/18459...  \n",
              "2  https://www.jobbkk.com/jobs/detailurgent/21546...  \n",
              "3  https://www.jobbkk.com/jobs/detailurgent/20247...  \n",
              "4  https://www.jobbkk.com/jobs/detailurgent/20745...  \n",
              "5  https://www.jobbkk.com/jobs/detailurgent/18459...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jobbkk_job_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abde4c5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
